<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>类别不平衡问题的方法汇总</title>
    <url>/class-imbalance/</url>
    <content><![CDATA[<h1 id="类别不平衡问题-class-imbalance-是什么"><a href="#类别不平衡问题-class-imbalance-是什么" class="headerlink" title="类别不平衡问题(class-imbalance)是什么"></a>类别不平衡问题(class-imbalance)是什么</h1><ul>
<li>指分类任务中不同类别的训练样例数目差别很大的情况</li>
<li>若不同类别的训练样例数目稍有差别，通常影响不大，但若差别很大，则会对学习过程造成困扰。例如有998个反例，但是正例只有2个，那么学习方法只需要返回一个永远将新样本预测为反例的学习器，就能达到99.8%的精度；然而这样的学习器往往没有价值，因为它不能预测出任何正例</li>
</ul>
<h1 id="上采样-过采样-Oversampling"><a href="#上采样-过采样-Oversampling" class="headerlink" title="上采样(过采样, Oversampling)"></a>上采样(过采样, Oversampling)</h1><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><ul>
<li>对训练集中的少数类进行“过采样”，即增加一些少数类样本使得正、反例数目接近，然后再进行学习</li>
</ul>
<h2 id="Random-Oversampling-随机上采样"><a href="#Random-Oversampling-随机上采样" class="headerlink" title="Random Oversampling(随机上采样)"></a>Random Oversampling(随机上采样)</h2><ul>
<li>简单复制样本的策略来增加少数类样本，容易产生模型过拟合的问题</li>
</ul>
<h2 id="SMOTE"><a href="#SMOTE" class="headerlink" title="SMOTE"></a>SMOTE</h2><ul>
<li>即合成少数类过采样技术(Synthetic Minority Oversampling Technique)，是基于随机采样算法的一种改进，其基本思想是对少数类样本进行分析并根据少数类样本人工合成新样本添加到数据集中</li>
</ul>
<h3 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h3><ul>
<li>1.对于少数类中每一个样本$x_i$，以欧氏距离为标准计算它到少数类样本集$S_{min}$中所有样本的距离，得到其k近邻</li>
<li>2.根据样本不平衡比例设置一个采样比例以确定采样倍率N，对于每一个少数类样本$x_i$，从其k近邻中随机选择若干个样本，假设选择的近邻为$\tilde{x}$。</li>
<li>3.对于每一个随机选出的近邻$\tilde{x}$，分别于原样本按照如下的公式构建新的样本</li>
<li>$$x_{n e w}=x+\operatorname{rand}(0,1) \times |\tilde{x}-x|$$</li>
<li><img src="http://anki190912.xuexihaike.com/20201019195529.png?imageView2/2/h/250"></li>
</ul>
<h3 id="SMOTE的问题"><a href="#SMOTE的问题" class="headerlink" title="SMOTE的问题"></a>SMOTE的问题</h3><ul>
<li>随机选取少数类样本用以合成新样本，而不考虑周边样本的情况<ul>
<li>1.如果选取的少数类样本周围都是少数类样本，则新合成的样本不会提供太多有用信息。就像SVM中远离margin的点对决策边界影响不大</li>
<li>2.如果选取的少数类样本周围都是多数类样本，这类的样本可能是噪声，则新合成的样本会与周围的多数类样本产生大部分重叠，导致分类困难</li>
</ul>
</li>
</ul>
<h2 id="Borderline-SMOTE"><a href="#Borderline-SMOTE" class="headerlink" title="Borderline-SMOTE"></a>Borderline-SMOTE</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><ul>
<li>由于原始SMOTE算法的对所有少数类样本都是一视同仁的，我们希望新合成的少数类样本能处于两个类别的边界附近，因为在实际建模过程中那些处于边界位置的样本更容易被错分，因此利用边界位置的样本信息产生新样本可以给模型带来更大的体征，能提供足够的信息用以分类，即Borderline SMOTE算法做的事情</li>
</ul>
<h3 id="算法流程-1"><a href="#算法流程-1" class="headerlink" title="算法流程"></a>算法流程</h3><ul>
<li>这个算法会先将所有的少数类样本分成三类，如图</li>
<li><img src="http://anki190912.xuexihaike.com/20201019140912.png"></li>
<li>“noise”：所有的k近邻个样本都属于多数类，可认为是噪声不能生成合成样本</li>
<li>“danger”：超过一半的k近邻样本属于多数类</li>
<li>“safe”：超过一半的k近邻样本属于少数类</li>
<li>borderline smote算法只会从处于”danger”状态的样本中随机选择，然后用SMOTE算法产生新的样本。处于”danger”状态的样本代表靠近”边界”附近的少数类样本往往更容易被误分类。因而Border-line SMOTE只对那些靠近”边界”的少数类样本进行人工合成样本，而SMOTE则对所有少数类样本一视同仁</li>
</ul>
<h3 id="危险集的判断流程"><a href="#危险集的判断流程" class="headerlink" title="危险集的判断流程"></a>危险集的判断流程</h3><ul>
<li>1.对于每个$x_{i} \subset S_{\min }$确定一系列K近邻样本集，称该数据集为$S_{i-kNN}$，且$S_{i-kNN} \subset S$</li>
<li>2.对每个样本$x_i$，判断出最近邻样本集中属于多数类样本的个数，即$\left|S_{i-k N N} \cap S_{m a j}\right|$</li>
<li>3.选择满足不等式$\frac{k}{2} \leq\left|S_{i-k N N} \cap S_{m a j}\right| \leq k$，将其加入危险集DANGER</li>
</ul>
<h3 id="Borderline-SMOTE分类两种："><a href="#Borderline-SMOTE分类两种：" class="headerlink" title="Borderline SMOTE分类两种："></a>Borderline SMOTE分类两种：</h3><ul>
<li>Borderline-1 SMOTE：在合成样本时所选的近邻是一个少数类样本</li>
<li>Borderline-2 SMOTE：在合成样本时所选的近邻是任意一个样本</li>
</ul>
<h2 id="ADASYN-Adaptive-Synthetic-Sampling，自适应合成采用"><a href="#ADASYN-Adaptive-Synthetic-Sampling，自适应合成采用" class="headerlink" title="ADASYN(Adaptive Synthetic Sampling，自适应合成采用)"></a>ADASYN(Adaptive Synthetic Sampling，自适应合成采用)</h2><ul>
<li>根据数据分布情况为不同的少数类样本生成不同数量的新样本</li>
<li>首先根据最终的平衡程度设定总共需要生成的新少数类样本数量，然后为每个少数类样本x计算分布比例</li>
</ul>
<h1 id="下采样-降采样-UnserSampling"><a href="#下采样-降采样-UnserSampling" class="headerlink" title="下采样(降采样, UnserSampling)"></a>下采样(降采样, UnserSampling)</h1><h2 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h2><ul>
<li>对训练集中多数类样本进行“下采样”(undersampling)，即去除一些多数类中的样本使得正例、反例数目接近，然后再学习</li>
</ul>
<h2 id="Random-Undersampling-随机下采样-或-原型选择-Prototype-Selection"><a href="#Random-Undersampling-随机下采样-或-原型选择-Prototype-Selection" class="headerlink" title="Random Undersampling(随机下采样) 或 原型选择(Prototype Selection)"></a>Random Undersampling(随机下采样) 或 原型选择(Prototype Selection)</h2><h3 id="定义-2"><a href="#定义-2" class="headerlink" title="定义"></a>定义</h3><ul>
<li>从多数类$S_{maj}$中随机选择一些样本组成样本集E。然后将样本集E从$S_{maj}$中移除。新的数据集$S_{n e w-m a j}=S_{m a j}-E$</li>
<li>通过改变多数类样本比例以达到修改样本分布的目的，从而使样本分布较为均衡</li>
</ul>
<h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul>
<li>操作简单，只依赖于样本分布，不依赖任何距离信息，属于非启发式方法</li>
</ul>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul>
<li>由于采样的样本集合要少于原来的样本集合，因此会造成一些信息缺失，即将多数类样本删除有可能导致分类器丢失有关多数类的重要信息</li>
</ul>
<h2 id="Ensemble-Methods"><a href="#Ensemble-Methods" class="headerlink" title="Ensemble Methods"></a>Ensemble Methods</h2><h3 id="EasyEnsemble"><a href="#EasyEnsemble" class="headerlink" title="EasyEnsemble"></a>EasyEnsemble</h3><h4 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h4><ul>
<li>多次随机欠采样，尽可能全面地涵盖所有信息，特点是利用boosting减少偏差(Adaboost)、bagging减少方差(集成分类器)。实际应用的时候可尝试选用不同的分类器来提高分类的效果</li>
<li><img src="http://anki190912.xuexihaike.com/20201020145429.png?imageView2/2/h/350"></li>
</ul>
<h4 id="算法流程-2"><a href="#算法流程-2" class="headerlink" title="算法流程"></a>算法流程</h4><ul>
<li>1.把数据划分为两部分，分别是多数类样本$S_{maj}$和少数类样本$S_{min}$</li>
<li>2.从多数类$S_{maj}$中有放回的随机采样n次，每次选取与少数类数目相近的样本个数即$|S_{imaj}|=|S_{min}|$，可得到n个样本集合，记作$\{S_{1 m a j}, S_{2 m a j}, \ldots, S_{n m a j}\}$</li>
<li>3.将每一个多数类样本的子集$S_{imaj}$与少数类样本$S_{min}$合并后训练出Adaboost分类器$H_i$，阈值设置为$\theta_i$，可得到n个模型，即$H_{i}(x)=\operatorname{sgn}\left(\sum\limits_{j=1}^{s_{i}} \alpha_{i j} h_{i, j}(x)-\theta_{i}\right)$</li>
<li>4.将这些模型组合形成一个集成学习系统，最终的模型结果是这n个模型的投票值。此处采用加权多数表决的方法，加大分类误差率小的弱分类器的权值，使其在表决中起较大的作用，减小分类误差率小的弱分类器的权值，使其在表决中起较小的作用，即最终分类器为$H(x)=\operatorname{sgn}\left(\sum\limits_{i=1}^{n} \sum\limits_{j=1}^{s_{i}} \alpha_{i j} h_{i j}(x)-\sum\limits_{i=1}^{n} \theta_{i}\right)$</li>
</ul>
<h3 id="BalanceCascade"><a href="#BalanceCascade" class="headerlink" title="BalanceCascade"></a>BalanceCascade</h3><h4 id="概述-2"><a href="#概述-2" class="headerlink" title="概述"></a>概述</h4><ul>
<li>该算法得到的是一个级联分类器，基于Adaboost，将若干个强分类器由简单到复杂排列，只有和少数类样本特征比较接近的才有可能输入到后面的分类器，比如边界点，因此能更充分地利用多数类样本的信息，一定程度上解决随机欠采样的信息丢失问题</li>
</ul>
<h4 id="算法流程-3"><a href="#算法流程-3" class="headerlink" title="算法流程"></a>算法流程</h4><ul>
<li>输入：一个包含少数类阳性样本P和多数类阴性样本集N的训练集D，定义T是从N中抽取的子集个数，$s_i$是训练Adaboost基分类器$H_i$时的循环次数</li>
<li>输出：一个组合分类器H(x)</li>
<li>1.$f=\sqrt[(\mathrm{T}-1)]{\left(\frac{|\mathrm{P}|}{|\mathrm{N}|}\right)}$，$f$是每一层级的分类器$H_i$该达到的假阳性率(False Positive Rate)，即把多数类样本误分为少数类的错误率</li>
<li>for i = 1 to T:<ul>
<li>从多数类N中随机抽取一个样本子集$N_i$，使得$|N_i| = |P|$</li>
<li>使用少数类样本集P和样本子集$N_i$训练一个Adaboost分类器$H_i$($H_i$由$s_i$个基分类器$h_{i,j}$及其权重$\alpha_{i,j}$构成，$\theta_i$是$H_i$的调节参数)</li>
<li>$\mathrm{H}_{\mathrm{i}}(x)=\operatorname{sgn}(\sum\limits_{j=1}^{s_{i}} \alpha_{i, j} h_{i, j}(x)-\theta_{i})$</li>
<li>调节阈值$\theta_i$令$H_i$的FP率为$f$</li>
<li>移除多数类样本集N中所有被$H_i$正确分类的样本</li>
</ul>
</li>
<li>输出一个集成分类器</li>
<li>$\mathrm{H}(\mathrm{x})=\operatorname{sgn}\left(\sum\limits_{i=1}^{T} \sum\limits_{j=1}^{s_{l}} \alpha_{i, j} h_{i, j}(x)-\sum\limits_{i=1}^{T} \theta_{i}\right)$</li>
</ul>
<h2 id="NearMiss"><a href="#NearMiss" class="headerlink" title="NearMiss"></a>NearMiss</h2><ul>
<li>本质上是一种原型选择(prototype selection)方法，即从多数类样本中选取最具代表性的样本用于训练，主要是为了缓解随机欠采样中的信息丢失问题。Nearmiss采用了3中不同的启发式规则来选择样本<ul>
<li>NearMiss-1：选择到最近的K个少数类样本平均距离最近的多数类样本，考虑的是与最近的k个少数类样本的平均距离，是局部的。该方法得到的多数类样本分布是“不均衡”的，它倾向于在比较集中的少数类附近找到更多的多数类样本，而在孤立的(离群的)少数类附近找到更少的多数类样本，原因是该方法考虑的局部性质和平均距离</li>
<li>NearMiss-2：选择到最远的K个少数类样本平均距离最近的多数类样本，考虑的是与最远的k个少数类样本的平均距离，是全局的。实验结果表明该方法的不均衡分类性能最优</li>
<li>NearMiss-3：对于每个少数类样本选择K个最近的多数类样本，目的是保证每个少数类样本都被多数类样本包围，该方法会使每一个少数类样本附近都有足够多的多数类样本，显然这会使得模型的精确度高、召回率低</li>
</ul>
</li>
</ul>
<h2 id="原型生成-Prototype-generation"><a href="#原型生成-Prototype-generation" class="headerlink" title="原型生成(Prototype generation)"></a>原型生成(Prototype generation)</h2><ul>
<li>给定数据集S，原型生成算法将生成一个子集S’，其中|S’|&lt;|S|，但是子集并非来自于原始数据，而是由原始数据集生成，方法是聚类成|S’|个类，然后取其中心点</li>
</ul>
<h2 id="Data-Cleaning-Techniques"><a href="#Data-Cleaning-Techniques" class="headerlink" title="Data Cleaning Techniques"></a>Data Cleaning Techniques</h2><h3 id="Tomek-Links"><a href="#Tomek-Links" class="headerlink" title="Tomek Links"></a>Tomek Links</h3><h4 id="定义-3"><a href="#定义-3" class="headerlink" title="定义"></a>定义</h4><ul>
<li>给定一个样本对$(x_i, x_j)$，其中$x_{i} \in S_{m a j}, x_{j} \in S_{\min }$，记$d(x_i, x_j)$是样本$x_i$和样本$x_j$之间的距离，如果不存在任何样本$x_k$，使得$d\left(x_{i}, x_{k}\right)&lt;d\left(x_{i}, x_{j}\right)$，那么样本对$(x_i, x_j)$即称为Tomek Links。即Tomek links为相反类最近邻样本之间的一对连接</li>
<li>不属于Tomek Links的情况有这个少数类样本最近的样本是同一类</li>
</ul>
<h4 id="意义"><a href="#意义" class="headerlink" title="意义"></a>意义</h4><ul>
<li>如果两个样本来自Tomek Links，那么他们中的一个样本要么是噪声，要么它们都在两类的边界上</li>
</ul>
<h4 id="图示"><a href="#图示" class="headerlink" title="图示"></a>图示</h4><ul>
<li><img src="http://anki190912.xuexihaike.com/20201021171029.png?imageView2/2/h/300"></li>
</ul>
<h4 id="用途"><a href="#用途" class="headerlink" title="用途"></a>用途</h4><ul>
<li>欠采样：将Tomek Links中属于是多数类的样本剔除</li>
<li>数据清洗：将Tomek Links中的两个样本都剔除</li>
</ul>
<h3 id="ENN-edited-nearest-neighborhood"><a href="#ENN-edited-nearest-neighborhood" class="headerlink" title="ENN(edited nearest neighborhood)"></a>ENN(edited nearest neighborhood)</h3><ul>
<li>这种方法应用knn来编辑(edit)数据集，对于每一个要进行下采样的样本，那些绝大多数近邻样本不属于该类的样本会被移除，而绝大多数的近邻样本属于同一类的样本会被保留</li>
</ul>
<h1 id="综合采样-Oversampling-Undersampling"><a href="#综合采样-Oversampling-Undersampling" class="headerlink" title="综合采样(Oversampling + Undersampling)"></a>综合采样(Oversampling + Undersampling)</h1><h2 id="定义-4"><a href="#定义-4" class="headerlink" title="定义"></a>定义</h2><ul>
<li>先过采样，然后再进行数据的清洗</li>
</ul>
<h2 id="SMOTE-Tomek-Links"><a href="#SMOTE-Tomek-Links" class="headerlink" title="SMOTE+Tomek Links"></a>SMOTE+Tomek Links</h2><h3 id="算法流程-4"><a href="#算法流程-4" class="headerlink" title="算法流程"></a>算法流程</h3><ul>
<li>1.利用SMOTE方法生成新的少数类样本，得到扩充后的数据集T</li>
<li>2.剔除T中的Tomek Links对</li>
</ul>
<h3 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h3><ul>
<li>普通的SMOTE方法生成的少数类样本是通过线性插值得到的，在平衡类别分布的同时也扩张了少数类的样本空间，产生的问题是可能原本属于多数类样本的空间被少数类“入侵”，容易造成模型的过拟合</li>
<li>Tomek Links对寻找的是那种噪声点或者边界点，可以很好地解决“入侵”问题，如图红色加号为SMOTE产生的少数类样本，可以看到红色样本“入侵”到原本属于多数类样本的空间，这种噪声数据问题可以通过Tomek Links很好地解决</li>
<li><img src="http://anki190912.xuexihaike.com/20201021171629.png?imageView2/2/h/150"></li>
</ul>
<h2 id="SMOTE-ENN"><a href="#SMOTE-ENN" class="headerlink" title="SMOTE+ENN"></a>SMOTE+ENN</h2><ul>
<li>1.利用SMOTE方法生成新的少数类样本，得到扩充后的数据集T</li>
<li>2.对T中的每一个样本使用KNN(一般k取3)方法预测，若预测结果与实际类别标签不符，则剔除该样本</li>
</ul>
<h1 id="其它方法"><a href="#其它方法" class="headerlink" title="其它方法"></a>其它方法</h1><h2 id="基于异常检测的方法"><a href="#基于异常检测的方法" class="headerlink" title="基于异常检测的方法"></a>基于异常检测的方法</h2><ul>
<li>把小类的样本作为异常点(outliers)，因此该问题便转化为异常点检测(anomaly detection)与变化趋势检测问题(change detection)</li>
</ul>
<h2 id="分治ensemble"><a href="#分治ensemble" class="headerlink" title="分治ensemble"></a>分治ensemble</h2><ul>
<li>将大类中样本聚类到L个聚类中，然后训练L个分类器</li>
<li>每个分类器使用大类中的一个簇与所有的小类样本进行训练得到</li>
<li>最后对这L个分类器采取少数服从多数的方式对未知类别数据进行分类，如果是连续值，采用平均值</li>
</ul>
<h2 id="分层级ensemble"><a href="#分层级ensemble" class="headerlink" title="分层级ensemble"></a>分层级ensemble</h2><ul>
<li>使用原始数据集训练第一个学习器L1</li>
<li>将L1错分的数据集作为新的数据集训练L2</li>
<li>将L1和L2分类结果不一致的数据作为数据集训练L3</li>
<li>最后测试集上将三个分类器的结果汇总(结合这三个分类器，采用投票的方式来决定分类结果，因此只有当L2与L3都分类为false时，最终结果才为false，否则为true)</li>
</ul>
<h2 id="对小类错分进行加权惩罚"><a href="#对小类错分进行加权惩罚" class="headerlink" title="对小类错分进行加权惩罚"></a>对小类错分进行加权惩罚</h2><ul>
<li>对分类器的小类样本数据增加权值，降低大类样本的权重，从而使得分类器将重点集中在小类样本身上</li>
<li>一个具体做法是，在训练分类器时，若分类器将小类样本分错时，额外增加分类器一个小类样本分错代价，这个额外的代价可以使得分类器更加“关心”小类样本。如penalized-SVM和penalized-LDA算法</li>
<li>对小样本进行过采样(例如含L倍重复数据)，其实在计算小样本错分cost functions时会累加L倍的惩罚分数</li>
</ul>
<h2 id="尝试其它评价指标"><a href="#尝试其它评价指标" class="headerlink" title="尝试其它评价指标"></a>尝试其它评价指标</h2><ul>
<li>准确度这个评价指标在类别不均衡的分类任务中不够好，甚至会造成误导。可考虑更有说服力的评价指标。如混淆矩阵、精确度、召回率、F1得分，其中可关注Kappa和ROC曲线</li>
</ul>
<h2 id="尝试不同的分类算法"><a href="#尝试不同的分类算法" class="headerlink" title="尝试不同的分类算法"></a>尝试不同的分类算法</h2><ul>
<li>决策树在类别不均衡数据上表现不错。它使用基于类变量的划分规则去创建分类树，因此可以强制地将不同类别的样本分开</li>
<li>Lightgbm中有两个参数处理类别不平衡，分别是is_unbalance和scale_pos_weight</li>
<li>xgboost有一个参数类别不平衡，即scale_pos_weight</li>
</ul>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li><a href="https://www.jiqizhixin.com/articles/021704">机器学习中如何处理不平衡数据？</a></li>
<li><a href="https://blog.csdn.net/jiede1/article/details/70215477">SMOTE算法(人工合成数据)</a></li>
<li><a href="https://www.jianshu.com/p/13fc0f7f5565">SMOTE算法</a></li>
<li><a href="https://blog.csdn.net/anshuai_aw1/article/details/89177406">分类问题中类别不平衡问题的有效解决方法</a></li>
<li><a href="http://freewill.top/2017/04/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%B3%BB%E5%88%97%EF%BC%8817%EF%BC%89%EF%BC%9A%E9%9D%9E%E5%B9%B3%E8%A1%A1%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/">机器学习算法系列（17）：非平衡数据处理</a></li>
<li><a href="https://blog.csdn.net/weixin_44871660/article/details/90600522">样本不平衡处理</a></li>
<li><a href="https://imbalanced-learn.readthedocs.io/en/stable/index.html">imbalanced官网</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/36093594">非平衡分类问题 | BalanceCascade方法及其Python实现</a></li>
<li><a href="https://blog.csdn.net/songhk0209/article/details/71484469">解决样本不平衡问题的奇技淫巧 汇总</a></li>
<li><a href="https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/">8 Tactics to Combat Imbalanced Classes in Your Machine Learning Dataset</a></li>
</ul>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>特征工程</tag>
        <tag>数据预处理</tag>
      </tags>
  </entry>
  <entry>
    <title>第一篇博客：为什么我要建博客和写博客</title>
    <url>/first-blog/</url>
    <content><![CDATA[<h1 id="起因"><a href="#起因" class="headerlink" title="起因"></a>起因</h1><p>很久之前就想搭建自己的博客了，只是嘛，一直都没有时间（划掉，就是懒）。这一次之所以突然下定决心要搞一波，完全是因为我的同桌真的是个超级大神，北大本科，杜克大学博士，也有一个自己的博客和介绍页，看着她的介绍页真的是超级牛，超级强，而且不仅是学习强，还在自己感兴趣的各个领域钻研的很深。让我不禁连连感叹，大牛的人生真的是超级强，真可谓最强鸡血，对比下来仿佛我白活了这么多年，没有留下任何值得留存的记录。</p>
<p>所以，受到这个启发（主要是刺激），我也要开始搭建自己的博客和个人主页，但同时我觉得我最好同时发布和维护3个平台，一个是CSDN，一个是公众号，一个是这个博客。毕竟文章写好之后，多发布一下几乎不费时间。</p>
<h1 id="为什么要选择github和hexo"><a href="#为什么要选择github和hexo" class="headerlink" title="为什么要选择github和hexo"></a>为什么要选择github和hexo</h1><p>选择github主要是因为能借助git的版本管理，顺便可以在github的热力图刷的好看一点，还有托管在github免费哇，不需要再另外维护云主机，不想当运维。省一笔主机钱，我只需要出钱买个域名即可，万网这个.tech域名买了10年也才199块，就是整个博客搭建中的唯一花销了</p>
<p>选择hexo是因为，能支持markdown的书写，和我现有的工具套件能配套上，可以无缝迁移过来，hexo的生态和主题都相对完善。</p>
<h1 id="过程和踩坑"><a href="#过程和踩坑" class="headerlink" title="过程和踩坑"></a>过程和踩坑</h1><h2 id="申请域名"><a href="#申请域名" class="headerlink" title="申请域名"></a>申请域名</h2><p>直接上<a href="https://wanwang.aliyun.com/">万网</a>购买自己的域名，做完实名认证之后即可先放着，详细步骤具体参考<a href="https://zhuanlan.zhihu.com/p/103860494">知乎</a>。</p>
<h2 id="安装node和hexo，并部署到github"><a href="#安装node和hexo，并部署到github" class="headerlink" title="安装node和hexo，并部署到github"></a>安装node和hexo，并部署到github</h2><p>具体参考<a href="https://zhuanlan.zhihu.com/p/105715224">知乎</a>，我是安装在macOS上，不需要搞这里面复杂的各种环境变量。</p>
<p>踩坑：我原本以为是建完git仓库后，把仓库pull下来，在里面初始化hexo，但后面看了一下，是要在空文件夹操作，并且后续发布到github的文件是hexo进行编译后的文件。</p>
<h2 id="域名解析"><a href="#域名解析" class="headerlink" title="域名解析"></a>域名解析</h2><p>能够部署之后保证通过github.io能访问即可做域名解析，具体参考<a href="https://zhuanlan.zhihu.com/p/103813944">知乎</a></p>
<h2 id="挑选主题"><a href="#挑选主题" class="headerlink" title="挑选主题"></a>挑选主题</h2><p>原本我想直接在<a href="https://hexo.io/themes/">官方的主题链接</a>里挑一个比较合适的，给自己定了几个标准：</p>
<ol>
<li>整体必须是简洁的，那种大量有图片装饰的，背景花哨的不考虑（原因是，挑图片暴露自己的垃圾审美，还要给每个博客挑配图太费心力了）</li>
<li>必须能支持公式、代码块高亮等的解析</li>
<li>偏好整体布局要简洁，偏好侧边栏在右边，并且偏好文章要有侧边栏</li>
<li>主题必须有开发者长期维护和更新</li>
<li>能有评论系统</li>
</ol>
<p>在上面看花了眼，都没有一个不合适的，看了大半天，猛然觉得自己挑选的思路不对，在最原始的未经过筛选的主题站里挑选，能不费劲吗？</p>
<p>转换思路，直接搜推荐的hexo主题，然后看到next主题是几乎完全符合我的要求的，然后发现next主题经历了好几个大版本的迭代，甚至github仓库都换了几次，直接上最新的8.0版本，拉下来</p>
<h2 id="next主题各种调整优化"><a href="#next主题各种调整优化" class="headerlink" title="next主题各种调整优化"></a>next主题各种调整优化</h2><p>next主题中可以进行自主化调整的地方还挺多的，而且8.0版本中，很多地方和以往版本中有不一样的调整方式，我尽量把我用到的写一下。所做的所有操作基本是改一下themes/next下的_config.yml，很少一部分是更改hexo下的_config.yml，偶尔会使用npm装个包</p>
<h3 id="设置首页信息"><a href="#设置首页信息" class="headerlink" title="设置首页信息"></a>设置首页信息</h3><figure class="highlight yaml"><figcaption><span>hexo/_config.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="attr">title:</span> <span class="string">每天净瞎搞</span></span><br><span class="line"><span class="attr">subtitle:</span> <span class="string">&#x27;关注：AI/CS/数学/自我提升等&#x27;</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">&#x27;既然选择了远方，便只顾风雨兼程&#x27;</span></span><br><span class="line"><span class="attr">author:</span> <span class="string">Shiqi</span> <span class="string">Lu</span></span><br><span class="line"><span class="attr">language:</span> <span class="string">zh-CN</span></span><br><span class="line"><span class="attr">timezone:</span> <span class="string">&#x27;Asia/Shanghai&#x27;</span></span><br><span class="line"><span class="attr">url:</span> <span class="string">http://shiqi-lu.tech</span></span><br></pre></td></tr></table></figure>

<h3 id="风格选择"><a href="#风格选择" class="headerlink" title="风格选择"></a>风格选择</h3><p>我把四个风格都试了一遍，最后比较喜欢Gemini</p>
<figure class="highlight yaml"><figcaption><span>themes/next/_config.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="comment"># Schemes</span></span><br><span class="line"><span class="comment"># scheme: Muse</span></span><br><span class="line"><span class="comment"># scheme: Mist</span></span><br><span class="line"><span class="comment"># scheme: Pisces</span></span><br><span class="line"><span class="attr">scheme:</span> <span class="string">Gemini</span></span><br></pre></td></tr></table></figure>

<h3 id="支持暗黑模式"><a href="#支持暗黑模式" class="headerlink" title="支持暗黑模式"></a>支持暗黑模式</h3><p>这可是个意外惊喜，还会根据系统的设置自动适配</p>
<figure class="highlight yaml"><figcaption><span>themes/next/_config.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="comment"># Dark Mode</span></span><br><span class="line"><span class="attr">darkmode:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<h3 id="设置建站时间"><a href="#设置建站时间" class="headerlink" title="设置建站时间"></a>设置建站时间</h3><figure class="highlight yaml"><figcaption><span>themes/next/_config.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="attr">footer:</span></span><br><span class="line">  <span class="comment"># Specify the date when the site was setup. If not defined, current year will be used.</span></span><br><span class="line">  <span class="attr">since:</span> <span class="number">2020</span></span><br></pre></td></tr></table></figure>

<h3 id="设置网站脚注的信息（图标、备案等）"><a href="#设置网站脚注的信息（图标、备案等）" class="headerlink" title="设置网站脚注的信息（图标、备案等）"></a>设置网站脚注的信息（图标、备案等）</h3><figure class="highlight yaml"><figcaption><span>themes/next/_config.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="attr">footer:</span></span><br><span class="line">  <span class="comment"># Icon between year and copyright info.</span></span><br><span class="line">  <span class="attr">icon:</span></span><br><span class="line">    <span class="comment"># Icon name in Font Awesome. See: https://fontawesome.com/icons</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">fa</span> <span class="string">fa-heart</span></span><br><span class="line">    <span class="comment"># If you want to animate the icon, set it to true.</span></span><br><span class="line">    <span class="attr">animated:</span> <span class="literal">true</span></span><br><span class="line">    <span class="comment"># Change the color of icon, using Hex Code.</span></span><br><span class="line">    <span class="attr">color:</span> <span class="string">&quot;#808080&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="网站图标"><a href="#网站图标" class="headerlink" title="网站图标"></a>网站图标</h3><p>先到网上找适合的图标，然后更新一下对应的文件，免费的图标素材网站：<a href="https://www.easyicon.net/1220579-maple_leaf_icon.html">Easyicon</a></p>
<figure class="highlight yaml"><figcaption><span>themes/next/_config.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="attr">favicon:</span></span><br><span class="line">  <span class="attr">small:</span> <span class="string">/images/7-16.png</span></span><br><span class="line">  <span class="attr">medium:</span> <span class="string">/images/7-32.png</span></span><br><span class="line">  <span class="attr">apple_touch_icon:</span> <span class="string">/images/7-128.png</span></span><br><span class="line">  <span class="attr">safari_pinned_tab:</span> <span class="string">/images/7-128.png</span></span><br></pre></td></tr></table></figure>

<h3 id="标签页和分类页"><a href="#标签页和分类页" class="headerlink" title="标签页和分类页"></a>标签页和分类页</h3><p>参考<a href="https://theme-next.js.org/docs/theme-settings/custom-pages.html#Adding-%C2%ABTags%C2%BB-Page">next文档</a></p>
<h3 id="侧边栏"><a href="#侧边栏" class="headerlink" title="侧边栏"></a>侧边栏</h3><p>我喜欢放在右边，主要是因为视觉聚焦主要是在左边的</p>
<figure class="highlight yaml"><figcaption><span>themes/next/_config.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="attr">sidebar:</span></span><br><span class="line">  <span class="comment"># Sidebar Position.</span></span><br><span class="line">  <span class="comment"># position: left</span></span><br><span class="line">  <span class="attr">position:</span> <span class="string">right</span></span><br></pre></td></tr></table></figure>

<h3 id="打开文章标题下方更新时间、阅读时长等信息"><a href="#打开文章标题下方更新时间、阅读时长等信息" class="headerlink" title="打开文章标题下方更新时间、阅读时长等信息"></a>打开文章标题下方更新时间、阅读时长等信息</h3><p>参考<a href="https://theme-next.js.org/docs/theme-settings/posts.html#Post-Wordcount">官方文档</a><br>先按照npm包：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ npm install hexo-word-counter</span><br><span class="line">$ hexo clean</span><br></pre></td></tr></table></figure>
<figure class="highlight yaml"><figcaption><span>hexo/_config.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="attr">symbols_count_time:</span></span><br><span class="line">  <span class="attr">symbols:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">total_symbols:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">total_time:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><figcaption><span>themes/next/_config.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="comment"># Post meta display settings</span></span><br><span class="line"><span class="attr">post_meta:</span></span><br><span class="line">  <span class="attr">item_text:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">created_at:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">updated_at:</span></span><br><span class="line">    <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">another_day:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">categories:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Post wordcount display settings</span></span><br><span class="line"><span class="comment"># Dependencies: https://github.com/next-theme/hexo-word-counter</span></span><br><span class="line"><span class="attr">symbols_count_time:</span></span><br><span class="line">  <span class="attr">separated_meta:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">item_text_total:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<h3 id="博客首页的摘要设置"><a href="#博客首页的摘要设置" class="headerlink" title="博客首页的摘要设置"></a>博客首页的摘要设置</h3><p>这个要配合文章中的description字段，或在文章中添加一行注释辅助，参考<a href="https://theme-next.js.org/docs/theme-settings/posts.html?highlight=more#Preamble-Text">官方文档</a></p>
<figure class="highlight yaml"><figcaption><span>themes/next/_config.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="comment"># Automatically excerpt description in homepage as preamble text.</span></span><br><span class="line"><span class="attr">excerpt_description:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Read more button</span></span><br><span class="line"><span class="comment"># If true, the read more button will be displayed in excerpt section.</span></span><br><span class="line"><span class="attr">read_more_btn:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<h3 id="置顶的百分比和顶部进度条"><a href="#置顶的百分比和顶部进度条" class="headerlink" title="置顶的百分比和顶部进度条"></a>置顶的百分比和顶部进度条</h3><p>默认给的颜色有点花哨，我改成了灰色</p>
<figure class="highlight yaml"><figcaption><span>themes/next/_config.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="attr">back2top:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># Back to top in sidebar.</span></span><br><span class="line">  <span class="attr">sidebar:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># Scroll percent label in b2t button.</span></span><br><span class="line">  <span class="attr">scrollpercent:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Reading progress bar</span></span><br><span class="line"><span class="attr">reading_progress:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># Available values: top | bottom</span></span><br><span class="line">  <span class="attr">position:</span> <span class="string">top</span></span><br><span class="line">  <span class="comment"># color: &quot;#37c6c0&quot;</span></span><br><span class="line">  <span class="attr">color:</span> <span class="string">&quot;#808080&quot;</span></span><br><span class="line">  <span class="attr">height:</span> <span class="string">3px</span></span><br></pre></td></tr></table></figure>

<h3 id="头像设置"><a href="#头像设置" class="headerlink" title="头像设置"></a>头像设置</h3><p>在url里放置本地图片或者图床链接</p>
<figure class="highlight yaml"><figcaption><span>themes/next/_config.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="comment"># Sidebar Avatar</span></span><br><span class="line"><span class="attr">avatar:</span></span><br><span class="line">  <span class="comment"># Replace the default image and set the url here.</span></span><br><span class="line">  <span class="attr">url:</span> <span class="string">/images/7-128.png</span></span><br><span class="line">  <span class="comment"># If true, the avatar will be dispalyed in circle.</span></span><br><span class="line">  <span class="attr">rounded:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># If true, the avatar will be rotated with the cursor.</span></span><br><span class="line">  <span class="attr">rotated:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure>

<h3 id="代码块高亮风格选择"><a href="#代码块高亮风格选择" class="headerlink" title="代码块高亮风格选择"></a>代码块高亮风格选择</h3><p>使用了hightlight.js的高亮样式</p>
<figure class="highlight yaml"><figcaption><span>hexo/_config.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="attr">highlight:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">line_number:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">auto_detect:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">tab_replace:</span> <span class="string">&#x27;    &#x27;</span></span><br><span class="line">  <span class="attr">wrap:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">hljs:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">prismjs:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">preprocess:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">line_number:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">tab_replace:</span> <span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><figcaption><span>themes/next/_config.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="attr">codeblock:</span></span><br><span class="line">  <span class="comment"># Code Highlight theme</span></span><br><span class="line">  <span class="comment"># All available themes: https://theme-next.js.org/highlight/</span></span><br><span class="line">  <span class="attr">theme:</span></span><br><span class="line">    <span class="attr">light:</span> <span class="string">default</span></span><br><span class="line">    <span class="attr">dark:</span> <span class="string">tomorrow-night-bright</span></span><br><span class="line">  <span class="attr">prism:</span></span><br><span class="line">    <span class="attr">light:</span> <span class="string">prism</span></span><br><span class="line">    <span class="attr">dark:</span> <span class="string">prism-dark</span></span><br><span class="line">  <span class="comment"># Add copy button on codeblock</span></span><br><span class="line">  <span class="attr">copy_button:</span></span><br><span class="line">    <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">    <span class="comment"># Available values: default | flat | mac</span></span><br><span class="line">    <span class="attr">style:</span> <span class="string">flat</span></span><br></pre></td></tr></table></figure>

<h3 id="社交账号设置"><a href="#社交账号设置" class="headerlink" title="社交账号设置"></a>社交账号设置</h3><figure class="highlight yaml"><figcaption><span>themes/next/_config.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="attr">social:</span></span><br><span class="line">  <span class="attr">GitHub:</span> <span class="string">https://github.com/shiqi-lu</span> <span class="string">||</span> <span class="string">fab</span> <span class="string">fa-github</span></span><br><span class="line">  <span class="attr">E-Mail:</span> <span class="string">mailto:traumlou@163.com</span> <span class="string">||</span> <span class="string">fa</span> <span class="string">fa-envelope</span></span><br><span class="line">  <span class="comment">#Weibo: https://weibo.com/yourname || fab fa-weibo</span></span><br><span class="line">  <span class="comment">#Google: https://plus.google.com/yourname || fab fa-google</span></span><br><span class="line">  <span class="comment">#Twitter: https://twitter.com/yourname || fab fa-twitter</span></span><br><span class="line">  <span class="comment">#FB Page: https://www.facebook.com/yourname || fab fa-facebook</span></span><br><span class="line">  </span><br><span class="line"><span class="attr">social_icons:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">icons_only:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">transition:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<h3 id="支持本地搜索"><a href="#支持本地搜索" class="headerlink" title="支持本地搜索"></a>支持本地搜索</h3><p>参考<a href="https://theme-next.js.org/docs/third-party-services/search-services.html?highlight=search#Local-Search">官方文档</a><br>先装包：<code>$ npm install hexo-generator-searchdb </code></p>
<figure class="highlight yaml"><figcaption><span>hexo/_config.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="comment"># Local Search</span></span><br><span class="line"><span class="attr">search:</span></span><br><span class="line">  <span class="attr">path:</span> <span class="string">search.xml</span></span><br><span class="line">  <span class="attr">field:</span> <span class="string">post</span></span><br><span class="line">  <span class="attr">content:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">format:</span> <span class="string">html</span></span><br></pre></td></tr></table></figure>
<figure class="highlight yaml"><figcaption><span>themes/next/_config.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="comment"># Local search</span></span><br><span class="line"><span class="comment"># Dependencies: https://github.com/next-theme/hexo-generator-searchdb</span></span><br><span class="line"><span class="attr">local_search:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># If auto, trigger search by changing input.</span></span><br><span class="line">  <span class="comment"># If manual, trigger search by pressing enter key or search button.</span></span><br><span class="line">  <span class="attr">trigger:</span> <span class="string">auto</span></span><br><span class="line">  <span class="comment"># Show top n results per article, show all results by setting to -1</span></span><br><span class="line">  <span class="attr">top_n_per_article:</span> <span class="number">1</span></span><br><span class="line">  <span class="comment"># Unescape html strings to the readable one.</span></span><br><span class="line">  <span class="attr">unescape:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># Preload the search data when the page loads.</span></span><br><span class="line">  <span class="attr">preload:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure>

<h3 id="评论系统"><a href="#评论系统" class="headerlink" title="评论系统"></a>评论系统</h3><p>评论系统选择了<a href="https://valine.js.org/">valine</a>，请参考<a href="https://theme-next.js.org/docs/third-party-services/comments.html?highlight=comme#Valine-China">next文档</a>，其中头像需要注册一下Gravatar，参考<a href="https://valine.js.org/avatar.html">头像配置</a>，这里的邮箱提醒好像有问题，官方说明的方法不能用了。这个以后再说吧，我也不想有个评论就给我发邮件，要真有比较紧急的事情，直接发我邮箱吧</p>
<h3 id="文章置顶"><a href="#文章置顶" class="headerlink" title="文章置顶"></a>文章置顶</h3><p>注意这里8.0更新之后，就不是通过安装插件改源码的方式实现，直接在文章的front-matter里面添加一个字段：sticky就可以实现了，值越高排的越前，默认为0是按照时间顺序，参考<a href="https://theme-next.js.org/docs/advanced-settings/front-matter.html?highlight=stick">官方文档</a></p>
<h3 id="文章赞赏"><a href="#文章赞赏" class="headerlink" title="文章赞赏"></a>文章赞赏</h3><p>要先准备好微信，支付宝等的二维码，然后放在images下或放在图床中</p>
<figure class="highlight yaml"><figcaption><span>themes/next/_config.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="comment"># Donate (Sponsor) settings</span></span><br><span class="line"><span class="comment"># Front-matter variable (unsupport animation).</span></span><br><span class="line"><span class="attr">reward_settings:</span></span><br><span class="line">  <span class="comment"># If true, a donate button will be displayed in every article by default.</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">animation:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">comment:</span> <span class="string">觉得文章写得不错就请博主喝杯奶茶吧(*￣∇￣*)</span></span><br><span class="line"></span><br><span class="line"><span class="attr">reward:</span></span><br><span class="line">  <span class="attr">wechatpay:</span> <span class="string">/images/wechatpay.png</span></span><br><span class="line">  <span class="attr">alipay:</span> <span class="string">/images/alipay.png</span></span><br><span class="line">  <span class="comment">#paypal: /images/paypal.png</span></span><br><span class="line">  <span class="comment">#bitcoin: /images/bitcoin.png</span></span><br></pre></td></tr></table></figure>


<h1 id="简单的使用指南"><a href="#简单的使用指南" class="headerlink" title="简单的使用指南"></a>简单的使用指南</h1><h2 id="写新博文"><a href="#写新博文" class="headerlink" title="写新博文"></a>写新博文</h2><p>在blog目录下输入命令<code>hexo new post &lt;title&gt;</code>，会自动在<code>&lt;blog-dir&gt;/source/_posts</code>目录下生成对应的title文件，这时候用md编辑器打开写博客即可</p>
<h2 id="本地测试"><a href="#本地测试" class="headerlink" title="本地测试"></a>本地测试</h2><p>博文写完之后，因为各种不同的解析器和浏览器对md的支持会不一样，先本地看看效果，运行命令：<code>hexo clean &amp;&amp; hexo s</code>，然后根据提示在浏览器打开localhost:4000即可查看</p>
<h2 id="推送到网站上"><a href="#推送到网站上" class="headerlink" title="推送到网站上"></a>推送到网站上</h2><p>运行命令：<code>hexo clean &amp;&amp; hexo g -d</code>即可</p>
<h1 id="尚未完成部分"><a href="#尚未完成部分" class="headerlink" title="尚未完成部分"></a>尚未完成部分</h1><p>这部分以后看时间和心情做吧，每做一部分记录一部分吧</p>
<ul>
<li>SEO</li>
<li>个人简介</li>
<li>README</li>
<li>访问速度比较慢，考虑使用除github外的托管服务</li>
<li>考虑使用CI</li>
<li>考虑CDN加速</li>
<li>考虑把http转换成https</li>
<li>备案</li>
<li>图床替换成自己的域名</li>
<li>完善和链接一下领英</li>
<li>研究一下博客如何分享链接到微信</li>
</ul>
<h1 id="已知问题"><a href="#已知问题" class="headerlink" title="已知问题"></a>已知问题</h1><ul>
<li>在ipad上的safari显示的时候没有font awesome图标显示，文章内容侧边栏等显示不出来，但ipad的chrome没问题，iphone的safari也没问题，真是奇怪</li>
</ul>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul>
<li><a href="https://kchen.cc/2016/11/12/hexo-instructions/">基于 Hexo 的全自动博客构建部署系统</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/102592286">从零开始搭建个人博客（超详细）</a></li>
<li><a href="https://hexo.io/zh-cn/docs/">Hexo官方文档</a></li>
<li><a href="https://github.com/next-theme/hexo-theme-next">Next8.0 Github</a></li>
<li><a href="https://theme-next.js.org/">Next8.0 文档</a></li>
</ul>
]]></content>
      <categories>
        <category>自我提升</category>
      </categories>
      <tags>
        <tag>感想</tag>
        <tag>自我提升</tag>
      </tags>
  </entry>
  <entry>
    <title>特征选择方法汇总</title>
    <url>/feature-selection/</url>
    <content><![CDATA[<h1 id="什么是特征选择"><a href="#什么是特征选择" class="headerlink" title="什么是特征选择"></a>什么是特征选择</h1><ul>
<li>对一个学习任务来说，给定属性集，有些属性很有用，另一些则可能没什么用。这里的属性即称为“特征”(feature)。对当前学习任务有用的属性称为“相关特征”(relevant feature)、没什么用的属性称为“无关特征”(irrelevant feature)。从给定的特征集合中选择出相关特征子集的过程，即“特征选择”(feature selection)</li>
</ul>
<h1 id="特征选择的目的"><a href="#特征选择的目的" class="headerlink" title="特征选择的目的"></a>特征选择的目的</h1><ul>
<li><p>1.简化模型，使模型更易于理解：去除不相关的特征会降低学习任务的难度。并且可解释性能对模型效果的稳定性有更多的把握</p>
</li>
<li><p>2.改善性能：节省存储和计算开销</p>
</li>
<li><p>3.改善通用性、降低过拟合风险：减轻维数灾难，特征的增多会大大增加模型的搜索空间，大多数模型所需要的训练样本随着特征数量的增加而显著增加。特征的增加虽然能更好地拟合训练数据，但也可能增加方差</p>
</li>
</ul>
<h1 id="使用特征选择的前提"><a href="#使用特征选择的前提" class="headerlink" title="使用特征选择的前提"></a>使用特征选择的前提</h1><ul>
<li><p>1.训练数据包含许多冗余或无用的特征，移除这些特征并不会导致丢失信息。其中冗余是指一个本身很有用的特征与另外一个有用的特征强相关，或它包含的信息能从其它特征推演出来</p>
</li>
<li><p>2.特征很多但样本相对较少</p>
</li>
</ul>
<h1 id="特征选择的4个步骤"><a href="#特征选择的4个步骤" class="headerlink" title="特征选择的4个步骤"></a>特征选择的4个步骤</h1><ul>
<li><p>1.产生过程：产生特征或特征子集候选集合</p>
</li>
<li><p>2.评价函数：衡量特征或特征子集的重要性或者好坏程度，即量化特征变量和目标变量之间的联系以及特征之间的相互联系。为了避免过拟合，可用交叉验证的方式来评估特征的好坏</p>
</li>
<li><p>3.停止准则：为了减少计算复杂度，需设定一个阈值，当评价函数值达到阈值后搜索停止</p>
</li>
<li><p>4.验证过程：在验证数据集上验证选出来的特征子集的有效性</p>
</li>
</ul>
<h1 id="特征选择的三个方法"><a href="#特征选择的三个方法" class="headerlink" title="特征选择的三个方法"></a>特征选择的三个方法</h1><ul>
<li><p>Filter(过滤法)</p>
</li>
<li><p>Wrapper(包装法)</p>
</li>
<li><p>Embedded(嵌入法)</p>
</li>
</ul>
<h1 id="Filter-过滤法"><a href="#Filter-过滤法" class="headerlink" title="Filter(过滤法)"></a>Filter(过滤法)</h1><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><ul>
<li>按照发散性或相关性对各个特征进行评分，设定阈值或者待选择特征的个数进行筛选，分为单变量过滤方法和多变量过滤方法</li>
</ul>
<h2 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h2><ul>
<li><p>单变量过滤方法：不需要考虑特征之间的相互关系，按照特征变量和目标变量之间的相关性或互信息对特征进行排序，过滤掉最不相关的特征变量。优点是计算效率高、不易过拟合</p>
</li>
<li><p>多变量过滤方法：考虑特征之间的相互关系，常用方法有基于相关性和一致性的特征选择</p>
</li>
</ul>
<h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><ul>
<li>不依赖于任何机器学习方法，且不需要交叉验证，计算效率比较高</li>
</ul>
<h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><ul>
<li>没有考虑机器学习算法的特点</li>
</ul>
<h2 id="图示"><a href="#图示" class="headerlink" title="图示"></a>图示</h2><ul>
<li><img src="http://anki190912.xuexihaike.com/20201014172426.png?imageView2/2/h/80"></li>
</ul>
<h2 id="常用的过滤方法"><a href="#常用的过滤方法" class="headerlink" title="常用的过滤方法"></a>常用的过滤方法</h2><h3 id="覆盖率"><a href="#覆盖率" class="headerlink" title="覆盖率"></a>覆盖率</h3><ul>
<li>即特征在训练集中出现的比例。若覆盖率很小，如有10000个样本，但某个特征只出现了5次，则次覆盖率对模型的预测作用不大，可删除</li>
</ul>
<h3 id="方差选择法"><a href="#方差选择法" class="headerlink" title="方差选择法"></a>方差选择法</h3><ul>
<li>先计算各个特征的方差，然后根据阈值，选择方差大于阈值的特征</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> VarianceThreshold</span><br><span class="line"><span class="comment"># 方差选择法，返回值为特征选择后的数据</span></span><br><span class="line"><span class="comment"># 参数threshold为方差的阈值</span></span><br><span class="line">VarianceThreshold(threshold=<span class="number">3</span>).fit_transform(iris.data)</span><br></pre></td></tr></table></figure>


<h3 id="Pearson-皮尔森-相关系数"><a href="#Pearson-皮尔森-相关系数" class="headerlink" title="Pearson(皮尔森)相关系数"></a>Pearson(皮尔森)相关系数</h3><ul>
<li>用于度量两个变量X和Y之间的线性相关性，结果的取值区间为[-1, 1]， -1表示完全的负相关(这个变量下降，那个就会上升)，+1表示完全的正相关，0表示没有线性相关性</li>
<li>计算方法为两个变量之间的协方差和标准差的商</li>
<li>$$\rho_{X, Y}=\frac{\operatorname{cov}(X, Y)}{\sigma_{X} \sigma_{Y}}=\frac{E\left[\left(X-\mu_{X}\right)\left(Y-\mu_{Y}\right)\right]}{\sigma_{X} \sigma_{Y}}$$</li>
<li>样本上的相关系数为</li>
<li>$$r=\frac{\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)\left(Y_{i}-\bar{Y}\right)}{\sqrt{\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}} \sqrt{\sum_{i=1}^{n}\left(Y_{i}-\bar{Y}\right)^{2}}}$$</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr</span><br><span class="line"><span class="comment"># 选择K个最好的特征，返回选择特征后的数据</span></span><br><span class="line"><span class="comment"># 第一个参数为计算评估特征是否好的函数，该函数输入特征矩阵和目标向量，</span></span><br><span class="line"><span class="comment"># 输出二元组（评分，P值）的数组，数组第i项为第i个特征的评分和P值。</span></span><br><span class="line"><span class="comment"># 在此为计算相关系数</span></span><br><span class="line"><span class="comment"># 其中参数k为选择的特征个数</span></span><br><span class="line">SelectKBest(<span class="keyword">lambda</span> X, Y: array(map(<span class="keyword">lambda</span> x:pearsonr(x, Y), X.T)).T, </span><br><span class="line">            k=<span class="number">2</span>).fit_transform(iris.data, iris.target)</span><br></pre></td></tr></table></figure>

<h3 id="卡方检验"><a href="#卡方检验" class="headerlink" title="卡方检验"></a>卡方检验</h3><ul>
<li>检验定性自变量对定性因变量的相关性。假设自变量有N种取值，因变量有M种取值，考虑自变量等于i且因变量等于j的样本频数的观察值与期望的差距，构建统计量</li>
<li>$$\chi^{2}=\sum \frac{(A-E)^{2}}{E}$$</li>
<li>这个统计量的含义即自变量对因变量的相关性</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> chi2</span><br><span class="line"><span class="comment">#选择K个最好的特征，返回选择特征后的数据</span></span><br><span class="line">SelectKBest(chi2, k=<span class="number">2</span>).fit_transform(iris.data, iris.target)</span><br></pre></td></tr></table></figure>

<h3 id="互信息法-KL散度、相对熵-和最大信息系数-Mutual-information-and-maximal-information-coefficient-MIC"><a href="#互信息法-KL散度、相对熵-和最大信息系数-Mutual-information-and-maximal-information-coefficient-MIC" class="headerlink" title="互信息法(KL散度、相对熵)和最大信息系数 Mutual information and maximal information coefficient (MIC)"></a>互信息法(KL散度、相对熵)和最大信息系数 Mutual information and maximal information coefficient (MIC)</h3><ul>
<li>评价定性自变量对定性因变量的相关性，评价类别型变量对类别型变量的相关性，互信息越大表明两个变量相关性越高，互信息为0时，两个变量相互独立。互信息的计算公式为</li>
<li>$$I(X ; Y)=\sum\limits_{x \in X} \sum\limits_{y \in Y} p(x, y) \log \frac{p(x, y)}{p(x) p(y)}=D_{K L}(p(x, y) | p(x) p(y))$$</li>
<li>其中，p(x)和p(y)为X和Y的边际概率分布函数，p(x,y)为X和Y的联合概率分布函数。直观上，互信息度量两个随机变量之间共享的信息，也可表示为由于X的引入而使Y的不确定性减少的量，这时互信息与信息增益相同</li>
<li>皮尔逊系数只能衡量线性相关性而互信息系数能够很好地度量各种相关性，但是计算相对复杂一些</li>
<li>互信息不能直接用于特征选择的两个原因<ul>
<li>1.不属于度量方式，不能归一化，在不同数据上的结果不能做比较</li>
<li>2.对于连续变量的计算不是很方便(X和Y都是集合，$x_i,y$都是离散值)，通常变量需要先离散化，而互信息的结果对离散化的方式很敏感</li>
</ul>
</li>
<li>为了处理定量数据，提出了最大信息系数法，它首先寻找一种最优的离散化方式，然后把互信息取值转换成一种度量方式，取值区间在[0, 1]</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br><span class="line"><span class="keyword">from</span> minepy <span class="keyword">import</span> MINE</span><br><span class="line"><span class="comment">#由于MINE的设计不是函数式的，定义mic方法将其为函数式的</span></span><br><span class="line"><span class="comment">#返回一个二元组，二元组的第2项设置成固定的P值0.5</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mic</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    m = MINE()</span><br><span class="line">    m.compute_score(x, y)</span><br><span class="line">    <span class="keyword">return</span> (m.mic(), <span class="number">0.5</span>)</span><br><span class="line"><span class="comment">#选择K个最好的特征，返回特征选择后的数据</span></span><br><span class="line">SelectKBest(<span class="keyword">lambda</span> X, Y: array(map(<span class="keyword">lambda</span> x:mic(x, Y), X.T)).T, </span><br><span class="line">            k=<span class="number">2</span>).fit_transform(iris.data, iris.target)</span><br></pre></td></tr></table></figure>

<h3 id="Fisher得分"><a href="#Fisher得分" class="headerlink" title="Fisher得分"></a>Fisher得分</h3><ul>
<li>对于分类问题，好的特征应该是在同一个类别中的取值比较相似，而在不同类别之间的取值差异比较大。因此特征i的重要性可用Fiser得分$S_i$来表示</li>
<li>$$S_{i}=\frac{\sum_{j=1}^{K} n_{j}\left(\mu_{i j}-\mu_{i}\right)^{2}}{\sum_{j=1}^{K} n_{j} \rho_{i j}^{2}}$$</li>
<li>其中，$u_{ij}$和$\rho_{ij}$分别是特征i在类别j中均值和方差，$\mu_i$为特征i的均值，$n_j$为类别j中的样本数。Fisher得分越高，特征在不同类别之间的差异性越大、在同一类别中的差异性越小，则特征越重要</li>
</ul>
<h3 id="相关特征选择-Correlation-Feature-Selection-CFS"><a href="#相关特征选择-Correlation-Feature-Selection-CFS" class="headerlink" title="相关特征选择(Correlation Feature Selection, CFS)"></a>相关特征选择(Correlation Feature Selection, CFS)</h3><ul>
<li>该方法基于的假设是，好的特征集合包含跟目标变量非常相关的特征，但这些特征之间彼此不相关。对于包含k个特征的集合，CFS准则定义为</li>
<li>$$\mathrm{CFS}=\max \limits_{S_{k}}\left[\frac{r_{c f_{1}}+r_{c f_{2}}+\cdots+r_{c f_{k}}}{\sqrt{k+2\left(r_{f_{1} f_{2}}+\cdots+r_{f_{i} f_{j}}+\cdots+r_{f_{k} f_{1}}\right)}}\right]$$</li>
<li>其中，$r_{cf_i}$和$r_{f_i f_j}$是特征变量和目标变量之间，以及特征变量和特征变量之间的相关性，这里的相关性不一定是皮尔森相关系数或斯皮尔曼相关系数</li>
</ul>
<h3 id="最小冗余最大相关性-Minimum-Redundancy-Maximum-Relevance-mRMR"><a href="#最小冗余最大相关性-Minimum-Redundancy-Maximum-Relevance-mRMR" class="headerlink" title="最小冗余最大相关性(Minimum Redundancy Maximum Relevance, mRMR)"></a>最小冗余最大相关性(Minimum Redundancy Maximum Relevance, mRMR)</h3><ul>
<li>由于单变量过滤法只考虑了单特征变量和目标变量之间的相关性，因此选择的特征子集可能过于冗余。mRMR在进行特征时考虑到了特征之间的冗余性，具体做法是对跟已选择特征相关性较高的冗余特征进行惩罚</li>
<li>mRMR可以使用多种相关性的度量指标，如互信息、相关系数以及其它距离或相似度分数</li>
<li>以互信息为例，特征集合S和目标变量c之间的相关性可定义为，特征集合中所有单个特征变量$f_i$和目标变量c的互信息值$I(f_i;c)$的平均值：</li>
<li>$$D(S, c)=\frac{1}{|S|} \sum\limits_{f_{i} \in S} I\left(f_{i} ; c\right)$$</li>
<li>S中所有特征的冗余性为所有特征变量之间的互信息$I(f_i;f_i)$的平均值</li>
<li>$$R(S)=\frac{1}{|S|^{2}} \sum\limits_{f_{i}, f_{j} \in S} I\left(f_{i} ; f_{j}\right)$$</li>
<li>则mRMR准则为</li>
<li>$$\operatorname{mRMR}=\max \limits_{S}[D(S, c)-R(S)]$$</li>
<li>通过求解上述优化问题即可得到特征子集</li>
<li>在一些特定的情况下，mRMR算法可能对特征的重要性估计不足，它没有考虑到特征之间的组合可能与目标变量比较相关。如果单个特征的分类能力都比较弱，但进行组合后分类能力很强，这时mRMR方法效果一般比较差(如目标变量由特征变量之间进行XOR运算得到)</li>
<li>mRMR是一种典型的进行特征选择的增量贪心策略：某个特征一旦被选择了，在后续的步骤不会删除</li>
<li>mRMR可改写为全局的二次规划的优化问题(即特征集合为特征全集的情况)：</li>
<li>$$\mathrm{QPFS}=\min\limits_{x}\left[\alpha \boldsymbol{x}^{\mathrm{T}} \boldsymbol{H} \boldsymbol{x}-\boldsymbol{x}^{\mathrm{T}} \boldsymbol{F}\right] \mathrm{s.t.} \sum\limits_{i=1}^{n} x_{i}=1, x_{i} \geqslant 0$$</li>
<li>其中$\boldsymbol{F}$为特征变量和目标变量相关性向量，$\boldsymbol{H}$为度量特征变量之间的冗余性的矩阵。QPFS可通过二次规划求解，QPFS偏向于选择熵比较小的特征，这是因为特征自身的冗余性$I(f_i;f_j)$</li>
<li>另一种全局的基于互信息的方法是基于条件相关性的</li>
<li>$$\mathrm{SPEC}_{\mathrm{CMI}}=\max\limits_{x}\left[\boldsymbol{x}^{\mathrm{T}} \boldsymbol{Q} \boldsymbol{x}\right] \text { s.t. }|x|=1, x_{i} \geqslant 0$$</li>
<li>其中，$Q_{i i}=I\left(f_{i} ; c\right), Q_{i j}=I\left(f_{i} ; c \mid f_{j}\right), i \neq j$。$\mathrm{SPEC}_{\mathrm{CMI}}$方法的优点是可以通过求解矩阵Q的主特征向量来求解，而且可以处理二阶的特征组合</li>
</ul>
<h1 id="Wrapper-包装法"><a href="#Wrapper-包装法" class="headerlink" title="Wrapper(包装法)"></a>Wrapper(包装法)</h1><h2 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h2><ul>
<li>使用机器学习算法评估特征子集的效果，可以检测两个或多个特征之间的交互关系，而且选择的特征子集让模型的效果达到最优。</li>
<li>这是特征子集搜索和评估指标相结合的方法。前者提供候选的新特征子集，后者基于新特征子集训练一个模型，并用验证集进行评估，为每一组特征子集进行打分</li>
<li>最简单的方法是在每一个特征子集上训练并评估模型，从而找出最优的特征子集</li>
</ul>
<h2 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h2><ul>
<li>1.需要对每一组特征子集训练一个模型，计算量很大</li>
<li>2.样本不够充分的情况下容易过拟合</li>
<li>3.特征变量较多时计算复杂度太高</li>
</ul>
<h2 id="图示-1"><a href="#图示-1" class="headerlink" title="图示"></a>图示</h2><p><img src="http://anki190912.xuexihaike.com/20201014173616.png?imageView2/2/h/120"></p>
<h2 id="3种常用的特征子集搜索方法"><a href="#3种常用的特征子集搜索方法" class="headerlink" title="3种常用的特征子集搜索方法"></a>3种常用的特征子集搜索方法</h2><h3 id="1-完全搜索"><a href="#1-完全搜索" class="headerlink" title="1.完全搜索"></a>1.完全搜索</h3><ul>
<li>即穷举法，遍历所有可能的组合达到全局最优，时间复杂度$2^n$</li>
</ul>
<h3 id="2-启发式搜索"><a href="#2-启发式搜索" class="headerlink" title="2.启发式搜索"></a>2.启发式搜索</h3><ul>
<li>序列向前选择：特征子集从空集开始，每次只加入一个特征，时间复杂度为$O(n+(n-1)+(n-2)+\ldots+1)=O\left(n^{2}\right)$</li>
<li>序列向后选择：特征子集从全集开始，每次删除一个特征，时间复杂度为$O(n^{2})$</li>
</ul>
<h3 id="3-随机搜索"><a href="#3-随机搜索" class="headerlink" title="3.随机搜索"></a>3.随机搜索</h3><ul>
<li>执行序列向前或向后选择时，随机选择特征子集</li>
</ul>
<h3 id="4-递归特征消除法"><a href="#4-递归特征消除法" class="headerlink" title="4.递归特征消除法"></a>4.递归特征消除法</h3><ul>
<li>使用一个基模型进行多轮训练，每轮训练后通过学习器返回的coef_或者feature_importances_消除若干权重较低的特征，再基于新的特征集进行下一轮训练</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> RFE</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="comment">#递归特征消除法，返回特征选择后的数据</span></span><br><span class="line"><span class="comment">#参数estimator为基模型</span></span><br><span class="line"><span class="comment">#参数n_features_to_select为选择的特征个数</span></span><br><span class="line">RFE(estimator=LogisticRegression(), </span><br><span class="line">    n_features_to_select=<span class="number">2</span>).fit_transform(iris.data, </span><br><span class="line">                                          iris.target)</span><br></pre></td></tr></table></figure>


<h1 id="Embedded-嵌入法"><a href="#Embedded-嵌入法" class="headerlink" title="Embedded(嵌入法)"></a>Embedded(嵌入法)</h1><h2 id="定义-2"><a href="#定义-2" class="headerlink" title="定义"></a>定义</h2><ul>
<li>将特征选择嵌入到模型的构建过程中，具有包装法与机器学习算法相结合的优点，也具有过滤法计算效率高的优点</li>
</ul>
<h2 id="图示-2"><a href="#图示-2" class="headerlink" title="图示"></a>图示</h2><ul>
<li><img src="http://anki190912.xuexihaike.com/20201014183741.png?imageView2/2/h/120"></li>
</ul>
<h2 id="LASSO方法"><a href="#LASSO方法" class="headerlink" title="LASSO方法"></a>LASSO方法</h2><ul>
<li>使用LASSO(Least Absolute Shrinkage and Selection Operator)方法</li>
<li>$$\min\limits_{\beta \in \mathbb{R}^{p}}\{\frac{1}{N}|y-X \boldsymbol{\beta}|_{2}^{2}+\lambda|\boldsymbol{\beta}| _{1}\}$$</li>
<li>通过对回归系数添加$L_1$惩罚项来防止过拟合，可以让特定的回归系数变为0，从而可以选择一个不包含那些系数的更简单的模型</li>
<li>实际应用中，$\lambda$越大，回归系数越稀疏，$\lambda$一般采用交叉验证的方式来确定</li>
<li>线性回归、逻辑回归、FM/FFM以及神经网络都可以添加$L_1$惩罚项</li>
<li>即使用带惩罚项的基模型，除了筛选出特征外，同时也进行了降维</li>
<li>实际上，L1惩罚项降维的原理是，在多个对目标值具有同等相关性的特征中，只保留一个，所以没保留的特征并不代表不重要</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectFromModel</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="comment">#带L1惩罚项的逻辑回归作为基模型的特征选择</span></span><br><span class="line">SelectFromModel(LogisticRegression(</span><br><span class="line">          penalty=<span class="string">&quot;l1&quot;</span>, C=<span class="number">0.1</span>)).fit_transform(</span><br><span class="line">               iris.data,iris.target)</span><br></pre></td></tr></table></figure>


<h2 id="基于树模型的特征选择方法"><a href="#基于树模型的特征选择方法" class="headerlink" title="基于树模型的特征选择方法"></a>基于树模型的特征选择方法</h2><ul>
<li>在决策树中，深度较浅的节点一般对应的特征分类能力更强(可以将更多的样本区分开)</li>
<li>对于基于决策树的算法，如随机森林，重要的特征更有可能出现在深度较浅的节点，而且出现的次数可能越多</li>
<li>即可基于树模型中特征出现次数等指标对特征进行重要性排序<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">  <span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectFromModel</span><br><span class="line">  <span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line">  <span class="comment">#GBDT作为基模型的特征选择</span></span><br><span class="line">SelectFromModel(</span><br><span class="line">      GradientBoostingClassifier()).fit_transform(</span><br><span class="line">        iris.data,iris.target)</span><br></pre></td></tr></table></figure>


</li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><p>美团机器学习实践2.2节</p>
</li>
<li><p>精通特征工程2.6节</p>
</li>
<li><p>特征工程入门与实践第5章</p>
</li>
<li><p>机器学习-周志华第11章</p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/74198735">【机器学习】特征选择(Feature Selection)方法汇总</a></p>
</li>
<li><p><a href="https://www.zhihu.com/question/28641663">机器学习中，有哪些特征选择的工程方法？</a></p>
</li>
</ul>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>特征工程</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s培训第4课 资源清单</title>
    <url>/k8s-4/</url>
    <content><![CDATA[<p>来源：<a href="https://www.bilibili.com/video/BV1w4411y7Go?p=1">b站</a></p>
<ul>
<li>Q:集群资源有哪些分类？<ul>
<li>名称空间级别<ul>
<li>工作负载型资源(workload): Pod、ReplicaSet、Deployment、StatefulSet、DaemonSet、Job、CronJob</li>
<li>服务发现及负载均衡型资源(ServiceDiscovery LoadBalance)：Service、Ingress</li>
<li>配置与存储型资源：Volume(存储卷)、CSI(容器存储接口，可扩展各种第三方存储卷)</li>
<li>特殊类型的存储卷：ConfigMap(当配置中心来使用的资源类型)、Secret(保存敏感数据)、DownwardAPI(把外部环境中的信息输出给容器)</li>
</ul>
</li>
<li>集群级别：Namespace、Node、Role、ClusterRole、RoleBinding、ClusterRoleBinding</li>
<li>元数据级别：HPA、PodTemplate、LimitRange</li>
</ul>
</li>
<li>Q:容器报错后如何处理？<ul>
<li><code>kubectl describe pod myapp-pod</code></li>
<li>若有多个容器需要用-c指定，查看日志</li>
<li><code>kubectl log myapp-pod -c test</code></li>
</ul>
</li>
<li>Q:initContainer模板是什么？<ul>
<li>initContainers里面会按照顺序依次往下执行</li>
</ul>
</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">myapp-pod</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">myapp</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-container</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;echo The app is running! &amp;&amp; sleep 3600&#x27;</span>]</span><br><span class="line">  <span class="attr">initContainers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">init-myservice</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">  <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;until nslookup myservice; do echo waiting for myservice; sleep 2; done;&#x27;</span>]</span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">init-mydb</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">  <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;until nslookup mydb; do echo waiting for mydb; sleep 2; done;&#x27;</span>]</span><br></pre></td></tr></table></figure>

<ul>
<li>Q:检测探针-就绪检测模板？readinessProbe-httpget</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">readiness-httpget-pod</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">readiness-httpget-container</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1</span></span><br><span class="line">  <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">  <span class="attr">readinessProbe:</span></span><br><span class="line">    <span class="attr">httpGet:</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">path:</span> <span class="string">/index1.html</span></span><br><span class="line">    <span class="attr">initialDelaySeconds:</span> <span class="number">1</span></span><br><span class="line">    <span class="attr">periodSeconds:</span> <span class="number">3</span></span><br></pre></td></tr></table></figure>

<ul>
<li>Q:检测探针-存活检测模板？livenessProbe-exec</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">liveness-exec-pod</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">liveness-exec-container</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">hub.atguigu.com/library/busybox</span></span><br><span class="line">    <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;touch /tmp/live ; sleep 60; rm -rf /tmp/live; sleep 3600&quot;</span>]</span><br><span class="line">    <span class="attr">livenessProbe:</span></span><br><span class="line">      <span class="attr">exec:</span></span><br><span class="line">        <span class="attr">command:</span> [<span class="string">&quot;test&quot;</span>,<span class="string">&quot;-e&quot;</span>,<span class="string">&quot;/tmp/live&quot;</span>]</span><br><span class="line">      <span class="attr">initialDelaySeconds:</span> <span class="number">1</span></span><br><span class="line">      <span class="attr">periodSeconds:</span> <span class="number">3</span></span><br></pre></td></tr></table></figure>

<ul>
<li>Q:检测探针-存活检测模板？livenessProbe-httpget</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">liveness-httpget-pod</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">liveness-httpget-container</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">hub.atguigu.com/library/myapp:v1</span></span><br><span class="line">  <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">    <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">  <span class="attr">livenessProbe:</span></span><br><span class="line">    <span class="attr">httpGet:</span></span><br><span class="line">      <span class="attr">port:</span> <span class="string">http</span></span><br><span class="line">      <span class="attr">path:</span> <span class="string">/index.html</span></span><br><span class="line">    <span class="attr">initialDelaySeconds:</span> <span class="number">1</span></span><br><span class="line">    <span class="attr">periodSeconds:</span> <span class="number">3</span></span><br><span class="line">    <span class="attr">timeoutSeconds:</span> <span class="number">10</span></span><br></pre></td></tr></table></figure>

<ul>
<li>Q:检测探针-存活检测模板？livenessProbe-tcp</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">probe-tcp</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">hub.atguigu.com/library/myapp:v1</span></span><br><span class="line">    <span class="attr">livenessProbe:</span></span><br><span class="line">      <span class="attr">initialDelaySeconds:</span> <span class="number">5</span></span><br><span class="line">      <span class="attr">timeoutSeconds:</span> <span class="number">1</span></span><br><span class="line">      <span class="attr">tcpSocket:</span></span><br><span class="line">        <span class="attr">port:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<ul>
<li>Q:启动、退出动作pod模板</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">lifecycle-demo</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">lifecycle-demo-container</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">lifecycle:</span></span><br><span class="line">      <span class="attr">postStart:</span></span><br><span class="line">        <span class="attr">exec:</span></span><br><span class="line">          <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>, <span class="string">&quot;-c&quot;</span>, <span class="string">&quot;echo Hello from the postStart handler &gt; /usr/share/message&quot;</span>]</span><br><span class="line">      <span class="attr">preStop:</span></span><br><span class="line">        <span class="attr">exec:</span></span><br><span class="line">          <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>, <span class="string">&quot;-c&quot;</span>, <span class="string">&quot;echo Hello from the poststop handler &gt; /usr/share/message&quot;</span>]</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s培训第5课 资源管理器</title>
    <url>/k8s-5/</url>
    <content><![CDATA[<p>来源：<a href="https://www.bilibili.com/video/BV1w4411y7Go?p=1">b站</a></p>
<ul>
<li>Q:Pod有哪些分类？<ul>
<li>自主式Pod：Pod退出了，此类型的Pod不会被创建</li>
<li>控制器管理的Pod：在控制器的生命周期里，始终要维持Pod的副本数目</li>
</ul>
</li>
<li>Q:什么是控制器？<ul>
<li>k8s中内建了很多controller(控制器)，这些相当于一个状态机，用来控制Pod的具体状态和行为</li>
</ul>
</li>
<li>Q:控制器有哪些类型？<ul>
<li>ReplicationController和ReplicaSet</li>
<li>Deployment</li>
<li>DaemonSet</li>
<li>StateFulSet</li>
<li>Job/CronJob</li>
<li>Horizontal Pod Autoscaling</li>
</ul>
</li>
<li>Q:命令式编程和声明式编程的区别是什么？<ul>
<li>命令式编程：侧重于如何实现，需要把程序的实现过程按照逻辑结果一步步写下来，k8s使用create命令</li>
<li>声明式编程：侧重于定义想要什么，然后告诉计算机/引擎，让它帮忙实现，k8s使用apply命令</li>
</ul>
</li>
<li>Q:ReplicationController和ReplicaSet是什么？<ul>
<li>ReplicationController(RC)用来确保容器应用的副本数始终保持在用户定义的副本数，即如果有容器异常退出，会自动创建新的Pod来替代，而如果异常多出来的容器也会自动回收</li>
<li>在新版本的k8s中建议使用ReplicaSet来取代ReplicationController。ReplicaSet跟ReplicationController没有本质的不同，只是名字不一样，并且ReplicaSet支持集合式的selector</li>
<li>创建命令<code>kubectl create -f rs.yaml</code><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicaSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">frontend</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">selector:</span></span><br><span class="line">  <span class="attr">matchLabels:</span></span><br><span class="line">    <span class="attr">tier:</span> <span class="string">frontend</span></span><br><span class="line"><span class="attr">template:</span></span><br><span class="line">  <span class="attr">metadata:</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">tier:</span> <span class="string">frontend</span></span><br><span class="line">  <span class="attr">spec:</span></span><br><span class="line">    <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">php-redis</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">gcr.io/google_samples/gb-frontend:v3</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">GET_HOSTS_FROM</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">dns</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>


</li>
</ul>
</li>
</ul>
<ul>
<li>Q:Deployment是什么？<ul>
<li>为Pod和ReplicaSet提供了一个声明式定义(declarative)方法，用来替代以前的ReplicationController来方便的管理应用</li>
<li>典型场景有：<ul>
<li>定义Deployment来创建Pod和ReplicaSet</li>
<li>滚动升级和回滚应用</li>
<li>扩容和缩容</li>
<li>暂停和继续Deployment</li>
</ul>
</li>
<li><img src="http://anki190912.xuexihaike.com/20200921170358.png"></li>
</ul>
</li>
<li><h2 id="Q-如何使用Deployment部署一个简单的Nginx应用"><a href="#Q-如何使用Deployment部署一个简单的Nginx应用" class="headerlink" title="Q:如何使用Deployment部署一个简单的Nginx应用"></a>Q:如何使用Deployment部署一个简单的Nginx应用</h2><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-deployment</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.7.9</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>
<ul>
<li>创建命令：<code>kubectl create -f https://kubernetes.io/docs/user-guide/nginx-deployment.yaml --record</code></li>
<li>其中–record参数可以记录命令，可以很方便的查看每次revision的变化</li>
</ul>
</li>
<li>Q:如何查看deployment状态？<ul>
<li><code>kubectl get deployment</code></li>
</ul>
</li>
<li>Q:如何对Deployment进行扩容？<ul>
<li><code>kubectl scale deployment nginx-deployment --replicas 10</code></li>
</ul>
</li>
<li>Q:如何更新deployment镜像？<ul>
<li><code>kubectl set image deployment/nginx-deployment nginx=nginx:1.9.1</code></li>
<li>=前是容器名，后是镜像</li>
</ul>
</li>
<li>Q:如何回滚deployment<ul>
<li><code>kubectl rollout undo deployment/nginx-deployment</code></li>
</ul>
</li>
<li>Q:如何查看可回滚的deployment历史版本？<ul>
<li><code>kubectl rollout history deployment/nginx-deployment</code></li>
</ul>
</li>
<li>Q:如何回滚deployment到指定的历史版本？<ul>
<li><code>kubectl rollout undo deployment/nginx-deployment --to-version=2</code></li>
</ul>
</li>
<li>Q:如何查看rollout状态？<ul>
<li><code>kubectl rollout status deployment/nginx-deployment</code></li>
</ul>
</li>
<li>Q:如何编辑Deployment？<ul>
<li><code>kubectl edit deployment/nginx-deployment</code></li>
</ul>
</li>
<li>Q:Deployment的清理策略是什么？<ul>
<li>可以通过设置<code>.spec.revisonHistoryLimit</code>项来指定deployment最多保留多少revision历史记录。默认的会保留所有的revision；如果将该项设置为0，Deployment就不允许回退了</li>
</ul>
</li>
<li>Q:Deployment的更新策略是什么？<ul>
<li>保证在升级时只有一定数量的Pod是down的。默认的，它会确保至少有比期望的Pod数量少一个是up状态（最多一个不可用）</li>
<li>Deployment 同时也可以确保只创建出超过期望数量的一定数量的Pod。默认的，它会确保最多比期望的Pod数 量多一个的Pod是up的（最多1个surge）</li>
<li>未来的 Kuberentes 版本中，将从1-1变成25%-25%</li>
</ul>
</li>
<li>Q:DaemonSet是什么？<ul>
<li>确保全部(或者一些)Node上运行一个Pod的副本。当有Node加入集群时，也会为它们新增一个Pod。当有Node从集群移除时，这些Pod也会被回收。删除DaemonSet将会删除它创建的所有Pod</li>
<li>使用DaemonSet的一些典型用法：<ul>
<li>运行集群存储daemon，例如在每个Node上运行glusterd、ceph</li>
<li>在每个Node上运行日志手机daemon，例如fluentd、logstash</li>
<li>在每个Node上运行监控daemon，例如Prometheus Node Exporter、collectd、Datadog代理、New Relic代理，或Ganglia gmond<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">deamonset-example</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">daemonset</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="comment"># 注意这个name和上面的metadata中的name必须要一致</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">deamonset-example</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">deamonset-example</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">daemonset-example</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
</li>
<li>Q:Job的作用是什么？<ul>
<li>负责批处理任务，即仅执行一次的任务，它保证批处理任务的一个或多个Pod成功结束</li>
<li>特殊说明<ul>
<li>spec.template格式同Pod</li>
<li>RestartPolicy仅支持Never或OnFailure</li>
<li>单个Pod时，默认Pod成功运行后Job即结束</li>
<li><code>.spec.completions</code>标志Job结束需要成功运行的Pod个数，默认为1</li>
<li><code>.spec.parallelism</code>标志并行运行的Pod的个数，默认为1</li>
<li><code>spec.activeDeadlineSeconds</code>标志失败Pod的重试最大时间，超过这个时间不会继续重试<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Job</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pi</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">pi</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">pi</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">perl</span></span><br><span class="line">        <span class="attr">command:</span> [<span class="string">&quot;perl&quot;</span>, <span class="string">&quot;-Mbignum=bpi&quot;</span>, <span class="string">&quot;-wle&quot;</span>, <span class="string">&quot;print bpi(2000)&quot;</span>] </span><br><span class="line">      <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>创建：<code>kubectl create -f job.yaml</code></li>
</ul>
</li>
<li>Q:CronJob的作用是什么？<ul>
<li>管理基于时间的Job，即：<ul>
<li>在给定时间点只运行一次</li>
<li>周期性地在给定时间点运行</li>
</ul>
</li>
<li>典型用法是：<ul>
<li>在给定的时间点调度Job运行</li>
<li>创建周期性运行的Job，如数据库备份、发送邮件</li>
</ul>
</li>
</ul>
</li>
<li>Q:如何查看cronjob状态？<ul>
<li><code>kubectl get cronjob</code></li>
</ul>
</li>
<li>Q:StatefulSet是什么？<ul>
<li>作为Controller为Pod提供唯一的标识。可以保证部署和scale的顺序</li>
<li>是为了解决有状态服务的问题(对应Delpoyments和ReplicaSets是为无状态服务而设计)，其应用场景包括：<ul>
<li>稳定的持久化存储，即Pod重新调度后还是能访问到相同的持久化数据，基于PVC来实现</li>
<li>稳定的网络标志，即Pod重新调度后其PodName和HostName不变，基于Headless Service(即没有Cluster IP的Service)来实现</li>
<li>有序部署，有序扩展，即Pod是有顺序的，在部署或者扩展的时候要依据定义的顺序依次进行，基于init containers来实现</li>
<li>有序收缩，有序删除</li>
</ul>
</li>
</ul>
</li>
<li>Q:Horizontal Pod Autoscaling是什么？<ul>
<li>应用的资源使用率通常都有高峰和低谷的时候，如何削峰填谷，提高集群的整体资源利用率，让service中的pod个数自动调整呢？就是Horizontal Pod Autoscaling，即使Pod水平自动缩放</li>
</ul>
</li>
<li>Q:如何查看命令详细信息如rs？<ul>
<li><code>kubectl explain rs</code></li>
</ul>
</li>
<li>Q:如何删除所有pod？<ul>
<li><code>kubectl delete pod --all</code></li>
</ul>
</li>
<li>Q:查看pod状态的时候如何查看标签？<ul>
<li><code>kubectl get pod --show-labels</code></li>
</ul>
</li>
<li>Q:如何给pod添加标签？<ul>
<li><code>kubectl label pod frontend-m8szd tier=frontend1</code></li>
<li>即给frontend-m8szd这个容器加了一个标签，若已存在，需要使用–overwrite=True来覆盖</li>
</ul>
</li>
<li>Q:如何删除所有rs？<ul>
<li><code>kubectl delete rs --all</code></li>
</ul>
</li>
<li>Q:如何查看pod的详细信息？<ul>
<li><code>kubectl get pod -o wide</code></li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习项目清单</title>
    <url>/ml-checklist/</url>
    <content><![CDATA[<h1 id="1-框出问题并看整体"><a href="#1-框出问题并看整体" class="headerlink" title="1.框出问题并看整体"></a>1.框出问题并看整体</h1><ul>
<li>1.用业务术语定义目标。</li>
<li>2.你的解决方案将如何使用?</li>
<li>3.当前有什么解决方案/解决方法（如果有）?</li>
<li>4.你应该如何阐述这个问题（有监督/无监督，在线/离线等）？</li>
<li>5.应该如何衡量性能?</li>
<li>6.性能指标是否符合业务目标?</li>
<li>7.达到业务目标所需的最低性能是多少？</li>
<li>8.有没有一些相似的向题？你可以重用经验或工具吗？</li>
<li>9.有没有相关有经验的人？</li>
<li>10.你会如何手动解决问题？</li>
<li>11.列出你（或其他人）到目前为止所做的假设。</li>
<li>12.如果可能，请验证假设。</li>
</ul>
<h1 id="2-获取数据"><a href="#2-获取数据" class="headerlink" title="2.获取数据"></a>2.获取数据</h1><ul>
<li>注意：尽可能地自动化，以便你可以轻松地获取新数据</li>
<li>1.列出所需的数据以及你需要多少数据。</li>
<li>2.查找并记录可从何处获取该数据。</li>
<li>3.检查将占用多少空间。</li>
<li>4.检查法律义务，并在必要时获得授权。</li>
<li>5.获取访问授权。</li>
<li>6.创建一个工作空间（具有足够的存储空间）。</li>
<li>7.获取数据。</li>
<li>8.将数据转换为可以轻松操作的格式（无须更改数据本身）。</li>
<li>9.确保敏感信息被删除或受保护（例如匿名）。</li>
<li>10.检查数据的大小和类型（时间序列、样本、地理等）。</li>
<li>11.抽样一个测试集，将其放在一边，再也不要看它（无数据监听！）。</li>
</ul>
<h1 id="3-研究数据"><a href="#3-研究数据" class="headerlink" title="3.研究数据"></a>3.研究数据</h1><ul>
<li>注意：请尝试从现场专家那里获取有关这些步骤的见解。</li>
<li>1.创建数据副本来进行研究（必要时将其采样到可以管理的大小）。</li>
<li>2.创建Jupyter notebook以记录你的数据研究。</li>
<li>3.研究每个属性及其特征：<ul>
<li>名称</li>
<li>类型（分类、整数/浮点型、有界/无界、文本、结构化等）</li>
<li>缺失值的百分比</li>
<li>噪声和噪声类型（随机、异常值、舍入误差等）</li>
<li>任务的实用性</li>
<li>分布类型（高斯分布、均匀分布、对数分布等）</li>
</ul>
</li>
<li>4.对于有监督学习任务，请确定目标属性。</li>
<li>5.可视化数据。</li>
<li>6.研究属性之间的相关性。</li>
<li>7.研究如何手动解决问题。</li>
<li>8.确定你可能希望使用的转变。</li>
<li>9.确定有用的额外数据。</li>
<li>10.记录所学的知识。</li>
</ul>
<h1 id="4-准备数据"><a href="#4-准备数据" class="headerlink" title="4.准备数据"></a>4.准备数据</h1><ul>
<li>注意：<ul>
<li>在数据副本上工作（保持原始数据集完整）。</li>
<li>为你应用的所有数据转换编写函数，原因有5个：<ul>
<li>下次获取新的数据集时，你可以轻松准备数据。</li>
<li>可以在未来的项目中应用这些转换。</li>
<li>清理并准备测试集。</li>
<li>解决方案上线后清理并准备新的数据实例。</li>
<li>使你可以轻松地将准备选择视为超参数。</li>
</ul>
</li>
</ul>
</li>
<li>1.数据清理：<ul>
<li>修复或删除异常值（可选）。</li>
<li>填写缺失值（例如，零、均值、中位数）或删除其行（或列）。</li>
</ul>
</li>
<li>2.特征选择（可选）：<ul>
<li>删除没有为任务提供有用信息的属性。</li>
</ul>
</li>
<li>3.特征工程（如果适用）：<ul>
<li>离散化连续特征。</li>
<li>分解特征（例如分类、日期/时间等）。</li>
<li>添加有希望的特征转换(如 Iog(x)、sqrt(x）、$x^2$等）</li>
<li>将特征聚合为有希望的新特征。</li>
</ul>
</li>
<li>4.特征缩放：<ul>
<li>标准化或归一化特征。</li>
</ul>
</li>
</ul>
<h1 id="5-列出有前途的模型"><a href="#5-列出有前途的模型" class="headerlink" title="5.列出有前途的模型"></a>5.列出有前途的模型</h1><ul>
<li>注意：<ul>
<li>如果数据量巨大，则可能需要采样为较小的训练集，以便可以在合理的时间内训练许多不同的模型(请注意，这会对诸如大型神经网络或随机森林之类的复杂模型造成不利影响)</li>
<li>尽可能自动化地执行这些步骤</li>
</ul>
</li>
<li>1.使用标准参数训练来自不同类别（例如线性、朴素贝叶斯、SVM，随机森林、神经网络等）的许多快速和粗糙的模型。</li>
<li>2.衡量并比较其性能。</li>
<li>对于每个模型，使用N折交叉验证，在N折上计算性能度量的均值和标准差。</li>
<li>3.分析每种算法的最重要的变量。</li>
<li>4.分析模型所犯错误的类型。<ul>
<li>人类将使用什么数据来避免这些错误?</li>
</ul>
</li>
<li>5.快速进行特征选择和特征工程。</li>
<li>6.在前面5个步骤中执行一两个以上的快速迭代。</li>
<li>7.筛选出前三到五个最有希望的模型，优先选择会产生不同类型错误的模型。</li>
</ul>
<h1 id="6-微调系统"><a href="#6-微调系统" class="headerlink" title="6.微调系统"></a>6.微调系统</h1><ul>
<li>注意：<ul>
<li>你将需要在此步骤中使用尽可能多的数据，尤其是在微调结束时。</li>
<li>与往常一样，尽可能做到自动化。</li>
</ul>
</li>
<li>1.使用交叉验证微调超参数：<ul>
<li>将你的数据转换选择视为超参数，尤其是当你对它们不确定时（例如，如果不确定是否用零或中位数替换缺失值，或者只是删除行）。</li>
<li>除非要研究的超参数值很少，否则应优先选择随机搜索而不是网格搜索。如果训练时间很长，你可能更喜欢贝叶斯优化方法（如Jasper Snoek等人所述使用高斯过程先验）。</li>
</ul>
</li>
<li>2.尝试使用集成方法。组合最好的模型通常会比单独运行有更好的性能。</li>
<li>3.一旦对最终模型有信心，就可以在测试集中测量其性能，以估计泛化误差。</li>
<li>注意：在测量了泛化误差之后，请不要对模型进行调整：否则你会开始过拟合测试集。</li>
</ul>
<h1 id="7-演示你的解决方案"><a href="#7-演示你的解决方案" class="headerlink" title="7.演示你的解决方案"></a>7.演示你的解决方案</h1><ul>
<li>1.记录你所做的事情。</li>
<li>2.创建一个不错的演示文稿。<ul>
<li>确保先突出大的蓝图。</li>
</ul>
</li>
<li>3.说明你的解决方案为何可以实现业务目标。</li>
<li>4.别忘了介绍你一路上注意到的有趣观点。<ul>
<li>描述什么有效，什么无效。</li>
<li>列出你的假设和系统的局限性。</li>
</ul>
</li>
<li>5.确保通过精美的可视化效果或易于记忆的陈述来传达你的主要发现（例如，“中等收入是房价的第一大预测指标”）。</li>
</ul>
<h1 id="8-启动！"><a href="#8-启动！" class="headerlink" title="8.启动！"></a>8.启动！</h1><ul>
<li>1.使你的解决方案准备投入生产环境（插入生产数据输入、编写单元测试等）。</li>
<li>2.编写监控代码，以定期检查系统的实时性能，并在系统故障时触发警报。<ul>
<li>当心缓慢的退化：随着数据的发展，模型往往会“腐烂”。</li>
<li>评估性能可能需要人工流水线（例如通过众包服务）。</li>
<li>监视你的输入的质量（例如，传感器出现故障，发送了随机值，或者另一个团队的输出变得过时)。这对于在线学习系统尤其重要。</li>
</ul>
</li>
<li>3.定期根据新数据重新训练模型（尽可能自动进行）。</li>
</ul>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>pytorch学习笔记</title>
    <url>/pytorch-learning/</url>
    <content><![CDATA[<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>这个目录是从深度之眼的pytorch课程中学习并整理的学习笔记</p>
<ul>
<li><a href="https://ai.deepshare.net/detail/p_5df0ad9a09d37_qYqVmt85/6">课程页面入口</a></li>
<li><a href="https://github.com/JansonYuan/Pytorch-Camp">课程代码github</a></li>
<li><a href="https://github.com/greebear/pytorch-learning">作业讲解代码</a></li>
<li>课程所有代码汇总中配套数据百度网盘地址：<a href="https://pan.baidu.com/s/1mA8wSCLnKphByzvHBzc9Pw">https://pan.baidu.com/s/1mA8wSCLnKphByzvHBzc9Pw</a><br>提取码：g5ym</li>
<li>课程所有课件汇总百度网盘地址：<a href="https://pan.baidu.com/s/1svt3lbDgNGixk5lKM1zfig">https://pan.baidu.com/s/1svt3lbDgNGixk5lKM1zfig</a><br>提取码：9j2f</li>
</ul>
<h1 id="目录笔记"><a href="#目录笔记" class="headerlink" title="目录笔记"></a>目录笔记</h1><p><a href="https://nbviewer.jupyter.org/github/shiqi-lu/Learn-AI/blob/master/pytorch_deepshare/week1.ipynb">Week1 Pytorch基础概念</a></p>
<ul>
<li>Pytorch简介及环境配置</li>
<li>Pytorch基础数据结构——张量</li>
<li>张量操作与线性回归</li>
<li>计算图与动态图机制</li>
<li>autograd与逻辑回归</li>
</ul>
<p><a href="https://nbviewer.jupyter.org/github/shiqi-lu/Learn-AI/blob/master/pytorch_deepshare/week2.ipynb">Week2 PyTorch数据处理</a></p>
<ul>
<li>数据读取机制DataLoader与Dataset</li>
<li>数据预处理transforms模块机制</li>
<li>二十二种transforms数据预处理方法</li>
<li>学会自定义transforms方法</li>
</ul>
<p><a href="https://nbviewer.jupyter.org/github/shiqi-lu/Learn-AI/blob/master/pytorch_deepshare/week3.ipynb">Week3 PyTorch模型搭建</a></p>
<ul>
<li>nn.Module与网络模型构建步骤</li>
<li>模型容器与AlexNet构建</li>
<li>网络层中的卷积层</li>
<li>网络层中的池化层、全连接层和激活函数层</li>
</ul>
<p><a href="https://nbviewer.jupyter.org/github/shiqi-lu/Learn-AI/blob/master/pytorch_deepshare/week4.ipynb">Week4 PyTorch损失优化</a></p>
<ul>
<li>权值初始化</li>
<li>损失函数（一）</li>
<li>Pytorch的14种损失函数</li>
<li>优化器optimizer的概念</li>
<li>torch.optim.SGD</li>
</ul>
<p><a href="https://nbviewer.jupyter.org/github/shiqi-lu/Learn-AI/blob/master/pytorch_deepshare/week5.ipynb">Week5 PyTorch训练过程</a></p>
<ul>
<li>学习率调整</li>
<li>TensorBoard简介与安装</li>
<li>TensorBoard使用（一）</li>
<li>TensorBoard使用（二）</li>
<li>hook函数与CAM</li>
</ul>
<p><a href="https://nbviewer.jupyter.org/github/shiqi-lu/Learn-AI/blob/master/pytorch_deepshare/week6.ipynb">Week6 PyTorch的正则化</a></p>
<ul>
<li>weight_decay</li>
<li>dropout</li>
<li>Batch Normalization</li>
<li>Layer Normalization、Instance</li>
<li>Normalization和Group Normalization</li>
</ul>
<p><a href="https://nbviewer.jupyter.org/github/shiqi-lu/Learn-AI/blob/master/pytorch_deepshare/week7.ipynb">Week7 PyTorch训练技巧</a></p>
<ul>
<li>模型保存与加载</li>
<li>Finetune</li>
<li>GPU的使用</li>
<li>Pytorch中常见报错</li>
</ul>
<p>Week8、9 PyTorch深度体验</p>
<ul>
<li>图像分类一瞥</li>
<li>图像分割一瞥</li>
<li>目标检测一瞥（上）</li>
<li>目标检测一瞥（下）</li>
<li>对抗生成网络一瞥</li>
<li>循环神经网络一瞥</li>
</ul>
]]></content>
      <categories>
        <category>pytorch学习笔记</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>恶魔奶爸语法4-6课</title>
    <url>/gramma4-6/</url>
    <content><![CDATA[<h1 id="4-被动语态的重难点——不完全及物动词和授予动词补充"><a href="#4-被动语态的重难点——不完全及物动词和授予动词补充" class="headerlink" title="4.被动语态的重难点——不完全及物动词和授予动词补充"></a>4.被动语态的重难点——不完全及物动词和授予动词补充</h1><ul>
<li>第四大句型，主谓宾补，其实就是“让某人做某事”<ul>
<li>My mother made me wash the car.</li>
<li>宾语是“我”，宾补是“洗车”，也就是说，宾语和宾补放在一起，逻辑上可以构成一个句子“我洗车”。</li>
<li>宾语和宾补之间的关系是被动语态呢?</li>
<li>他让这个任务完成了。</li>
<li>如果按照造句规律，应该是: He made this task be finished.或者He get this task to be finished.</li>
<li>宾补中，出现的be或者to be，通常要省略！所以，这句话应该说成: He made this task finished.</li>
</ul>
</li>
<li>英语中还有什么时候会出现be动词呢?<ul>
<li>除了被动语态(过去分词作表语)之外，还有主系表句型(be动词后面的名词作表语，形容词作表语，地点副词作表语)</li>
</ul>
</li>
<li>使役动词+宾语+过去分词（补语）<ul>
<li>Now a group of students will have the plane restored.一群学生计划修复这架飞机。</li>
<li>Officials have the clock checked twice a day.官员们每天两次派人检查此钟。</li>
</ul>
</li>
<li>使役动词+宾语+名词、形容词或地点副词<ul>
<li>使役动词也可加名词、形容词或地点副词等作补语，其原因是前面省略了不定式be或to be。<ul>
<li>His teacher made him a good student. (名词作宾补)他的老师使他成为好学生。</li>
<li>The trip made him happy.(形容词作宾补)这次旅行使他很愉快。</li>
<li>He let me in. (地点副词作宾补)他让我进来。</li>
<li>Get him out of here. (介词短语，相当于地点副词)把他弄出去!</li>
</ul>
</li>
</ul>
</li>
<li>各种不完全及物动词：接上宾语后意思仍然不完整<ul>
<li>让某人做某事，只能接不定时作宾语补语：ask、encourage、tell、push、expect、want、drive/force/oblige/compel、order、cause/urge<ul>
<li>The postman <code>wanted</code> me to sign for a letter!邮递员要我签收一封挂号信!</li>
<li>Last week at a dinner-party, the hostess <code>asked</code> me to sit next to Mrs. Rumbold.在上星期的一次宴会上，女主人安排我坐在兰伯尔德夫人的身旁。</li>
<li>Byrd at once <code>ordered</code> his men to throw out two heavy food sacks.伯德马上命令他的助手们把两个沉重的食物袋扔掉。</li>
<li>My dentist had <code>told</code> me to rest for a while.我的牙科医生叫我休息一会儿。</li>
<li>My old friend Brian <code>urged</code> me to accept a cigarette.我的老朋友布赖恩极力劝我接受一枝香烟。</li>
</ul>
</li>
<li>知觉动词（5看，2听，1感觉）：感觉：feel，听：hear, listen to，看：see, observe, watch, look at, notice<ul>
<li>表事实：此类动词+宾语+动词原形(补语)，译为”……..了。”<ul>
<li>I <code>saw</code> him dance.我看见他跳舞了。</li>
<li>I <code>heard</code> him sing.我听见他唱歌了。</li>
</ul>
</li>
<li>表进行状态：此类动词+宾语+现在分词(补语)，译为”…..正在……”<ul>
<li>Early next morning, she <code>heard</code> planes passing overhead. 第二天一大早，她听到头顶上飞机正在盘旋。</li>
<li>The pilot <code>saw</code> one of the men taking photographs.当气球飞临基地上空时，飞行员看见有一个人在拍照。</li>
</ul>
</li>
<li>表被动状态：此类动词+宾语+过去分词(补语)，译为”…..被…..”<ul>
<li>I <code>saw</code> him killed.我看见他被杀了。</li>
</ul>
</li>
</ul>
</li>
<li>认定动词：视…为…；认为…是…：动词 + 宾语 + 介词as + 名词或形容词(补语)<ul>
<li>regard<ul>
<li>In spite of this, the Italians <code>regarded</code> him <code>as</code> a sort of hero.尽管如此，意大利人还是把他视作某种英雄。</li>
</ul>
</li>
<li>look upon<ul>
<li>His students all <code>look upon</code> him <code>as</code> a friend.他的学生都把他看成是朋友。</li>
</ul>
</li>
<li>think of<ul>
<li>They <code>think of</code> themselves <code>as</code> the salt of the earth.他们自认为是社会中坚。</li>
</ul>
</li>
<li>see<ul>
<li>I’d like to <code>see</code> Europe <code>as</code> a nuclear-free zone.我希望欧洲成为无核区。</li>
</ul>
</li>
<li>view<ul>
<li>We <code>view</code> every customer <code>as</code> a partner.我们将每一位客户视为合作伙伴。</li>
</ul>
</li>
</ul>
</li>
<li>认定动词：视…为…；认为…是…：动词 + 宾语 + (to be) + 名词或形容词(补语)：consider, deem, think, find, believe<ul>
<li>He is <code>finding</code> his new work far more exciting.他发觉自己的新工作令人兴奋得多。</li>
<li>I <code>found</code> his advice really useful.我发现他的建议非常有用。</li>
<li>People <code>think</code> this problem determination.人们认为这个问题解决了。</li>
</ul>
</li>
<li>转变动词：使…变成…：change/turn + 宾语 + into + 名词(补语)<ul>
<li>I need to change my dollars into francs.我需要把美金换成法郎。</li>
<li>The experience turned him into a good student.这个经验使他变成了好学生。</li>
</ul>
</li>
<li>call/name + 宾语 + 名词(补语)<ul>
<li>‘Do you call that a hat?’ I said to my wife.“你把那个叫帽子吗?”我对妻子说。</li>
<li>You can name your pet dog Doctor.你可以把你的狗狗取名为博士。</li>
</ul>
</li>
<li>help后接不定式(to可省略) 作宾语补语。<ul>
<li>A short while ago, my sister helped me to carry my old bookcases up the stairs.几分钟前，我妹妹帮我把我的旧书橱抬上了楼。</li>
</ul>
</li>
<li>造句练习<ul>
<li>1.店员看见这个衣着很好的妇女正在偷东西。<ul>
<li>1.The shop assistant saw the well-dressed woman stealing something.</li>
</ul>
</li>
<li>2.你能帮我洗衣服吗?<ul>
<li>2.Can you help me to wash clothes?</li>
</ul>
</li>
<li>3.作为老师，你应该鼓励你的学生努力学习。<ul>
<li>3.As a teacher, you should encourage your students to study hard.</li>
</ul>
</li>
<li>4.父母不应该期望他们的孩子做任何事都成功。<ul>
<li>4.The parents should not expect their children to succeed in doing everything.</li>
</ul>
</li>
<li>5.你应该命令这个计划在一个月内完成。(order)<ul>
<li>5.You should order this project to finished within a month.</li>
</ul>
</li>
<li>6.我发现我们的老师被警察逮捕了。<ul>
<li>6.I found our teacher arrested by the police.</li>
</ul>
</li>
<li>7.工人们明天将把墙刷成绿色。<ul>
<li>7.The workers will paint the wall green.</li>
</ul>
</li>
<li>8.女主人邀请我们进去。<ul>
<li>8.The hostess invited us in.</li>
</ul>
</li>
<li>9.我们认为这个男人处于危险中。<ul>
<li>9.We considered the man in danger.</li>
</ul>
</li>
<li>10.大部分人把他当作英雄。<ul>
<li>10.Most people regarded him as a hero.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>特殊的授予动词<ul>
<li>间接宾语与直接宾语位置可以倒置，此时需要加介词to, for, of。<ul>
<li>表“给予”的概念，要用to<ul>
<li>My holidays passed quickly, but I did not send any cards <code>to</code> my friends.假期过得真快，可我还没有给我的朋友们寄过一张明信片。</li>
</ul>
</li>
<li>表“代劳”的概念(buy等) ，要用for<ul>
<li>I bought a book <code>for</code> him.我为他买了一本书</li>
</ul>
</li>
<li>ask要用of<ul>
<li>I asked a question <code>of</code> him.我问了他一个问题。</li>
</ul>
</li>
</ul>
</li>
<li>下列授予动词与of连用<ul>
<li>1.rob 抢夺<ul>
<li>He robbed me of my money.他抢了我的钱。</li>
<li>注:中式思维容易说成He robbed my money. (X) 这是绝对错误的!</li>
</ul>
</li>
<li>2.deprive 剥夺(权利)<ul>
<li>This law will deprive us of our most basic rights.这条法律将剥夺我们最基本的权利。</li>
</ul>
</li>
<li>3.cure 治愈<ul>
<li>The teacher cured him of bad habits.老师纠正了他的坏习惯。</li>
</ul>
</li>
<li>4.relieve 减轻<ul>
<li>It will relieve her of a tremendous burden. 这将给她解决一个巨大的负担。</li>
</ul>
</li>
<li>5.remind 提醒<ul>
<li>I continually have to remind him of his responsibilities.我得一再提醒他记住他的责任。</li>
</ul>
</li>
</ul>
</li>
<li>表“提供”概念的授予动词provide, furnish, supply必须与介词with连用。(但双宾语倒置的时候任然用to，for)<ul>
<li>He provided me with a lot of money.他提供给我很多钱。</li>
<li>The present conflict may provide fresh impetus for peace talk.目前的冲突可能会给和谈提供新的推动力。</li>
<li>The school doesn’t furnish students with lunch.学校不供给学生午饭。</li>
<li>The gas station usually supplies its nearby communities with gas.这个加油站通常为附近的社区提供汽油。</li>
<li>We supply power to the three nearby towns.我们对附近的三个城镇提供电力。</li>
</ul>
</li>
<li>造句练习<ul>
<li>1.这个著名的歌手给我们演唱了一首流行歌曲。<ul>
<li>1.The famous singer sang us a popular song.</li>
</ul>
</li>
<li>2.这座新桥带给当地人极大的方便。<ul>
<li>2.The new bridge brings the local people the great convenience.</li>
</ul>
</li>
<li>3.你不能剥夺她的权利。<ul>
<li>3.You can’t deprive her of her rights.</li>
</ul>
</li>
<li>4.这张照片使我想起了我们在夏令营度过的日子。<ul>
<li>4.The photo reminds me of the days which spent in the summer camp.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>第四大句型:主语+不完全及物动词+宾语+宾语补语，变成被动语态时，原句的宾语补语，在被动语态中的名称为“主语补语”<ul>
<li>My father was shocked. Now we are not allowed to touch it. 我父亲大为吃惊，不许我们再动它。</li>
<li>The Games will be held just outside the capital and the whole area will be called ‘Olympic City’. 奥运会就在首都市郊举办，整个地区将被称作奥林匹克城”。</li>
<li>The man was ordered to pay 43,545 for the cost of the trip. 此人被责令交付旅费3,500英镑.</li>
</ul>
</li>
<li>make, have, let, get 这4个使役动词，只有make可以用于被动语态。这类句型在被动语态句里边，主语补语必须加上to!<ul>
<li>They made me repeat the story. / I was made to repeat the story.他们让我又把那事讲了一遍。</li>
</ul>
</li>
<li>能用动词原形作宾语补语的不完全(及物)动词有<ul>
<li>5看：see, observe, watch, look at, notice<ul>
<li>I saw him dance. / He was seen to dance. 我看见他跳舞了。</li>
</ul>
</li>
<li>1使：make</li>
<li>2听：hear, listen to</li>
<li>1感：feel</li>
</ul>
</li>
<li>第五大句型变成被动语态时，两个宾语都可以成为被动句的主语。但由于间接宾语是人，通常更常变成主语。<ul>
<li>I give him a book. = He was given a book by me. = A book was given to him by me.</li>
</ul>
</li>
</ul>
<h1 id="5-最简单的长句——并列句"><a href="#5-最简单的长句——并列句" class="headerlink" title="5.最简单的长句——并列句"></a>5.最简单的长句——并列句</h1><h2 id="简单句、复合句、并列句"><a href="#简单句、复合句、并列句" class="headerlink" title="简单句、复合句、并列句"></a>简单句、复合句、并列句</h2><ul>
<li>简单句：是只有一个主干的句子</li>
<li>复合句：是除主句外还包含一个或一个以上从句的句子</li>
<li>并列句：由并列连词连接两个或两个以上简单句而成的句子。</li>
<li>注意：汉语可以用逗号分隔两个完整的句子，英语绝对不可以！而是必须有连词连接，或者把其中一个句子，化简为分词短语或不定时短语</li>
</ul>
<h2 id="连接主句和从句的连词有三种"><a href="#连接主句和从句的连词有三种" class="headerlink" title="连接主句和从句的连词有三种"></a>连接主句和从句的连词有三种</h2><ul>
<li>引导词，连接名词性从句</li>
<li>副词连词，连接状语从句</li>
<li>关系词，连接定语从句</li>
</ul>
<h2 id="单一连接词：and-or-but"><a href="#单一连接词：and-or-but" class="headerlink" title="单一连接词：and, or, but"></a>单一连接词：and, or, but</h2><ul>
<li>连接对等的句子<ul>
<li>I had just lost $50 <code>and</code> I felt very upset. 我刚刚丢了50英镑，感到非常烦恼。(and连接不用加逗号)</li>
<li>The police had a difficult time, <code>but</code> they were most amused. 警察虽然吃了苦头，但他们还是感到很有趣。(but连接要加逗号)</li>
<li>注：or连接句子的时候，通常用于祈使句后面，翻译为“否则”</li>
<li>Obey your boss <code>or</code> you will be fired. 服从你的上司，否则你会被解雇。</li>
<li>Don’t cheat at exams <code>or</code> others will despise you. 考试不要作弊，否则别人会瞧不起你。</li>
<li>Give me liberty <code>or</code> give me death. 不自由，毋宁死。</li>
</ul>
</li>
<li>连接句子中任何对等的成分<ul>
<li>连接主语<ul>
<li>A young man <code>and</code> a young woman were sitting behind me.</li>
<li>一青年男子与一青年女子坐在我的身后。</li>
</ul>
</li>
<li>连接谓语：相当于是连接两个句子，省略了第二个句子的主语<ul>
<li>I visited museums <code>and</code> sat in public gardens. 我参观了博物馆，还去了公园。</li>
<li>I entered the hotel manager’s office <code>and</code> sat down. 我走进饭店经理的办公室，坐了下来</li>
<li>注：连接谓语的时候，只要助动词相同，即可省略助动词<ul>
<li>After taking off, we were flying low over the city <code>and</code> (were) slowly gaining height, when the plane suddenly turned round and flew back to the airport. 起飞之后，我们在城市上空低低地飞行，然后慢慢爬高。这时飞机突然调转头来，飞回了 机场。(括号里的助动词were可省略)</li>
</ul>
</li>
<li>谓语动词相同的，也可以省略。<ul>
<li>Mary is very happy <code>but</code> John (is) very miserable. 玛丽很幸福，但是约翰很悲惨。</li>
<li>Experience is the father of wisdom, <code>and</code> memory (is) the mother. 经验乃智慧之父，记忆为智慧之母。</li>
<li>Reading makes a full man; conference a ready man; <code>and</code> writing an exact man.读书使人渊博，交谈使人机敏，写作使人严谨。(conference和writing后省略了makes)- Francis Bacon(弗朗西斯培根)</li>
</ul>
</li>
</ul>
</li>
<li>连接宾语<ul>
<li>I looked at the man <code>and</code> the woman angrily. 我回过头去怒视着那一男一女。</li>
<li>He asked me for a meal <code>and</code> a glass of beer. 他问我要一顿饭和一杯啤酒。(连接介词for的两个宾语)</li>
</ul>
</li>
<li>连接表语<ul>
<li>The railway station was big, black <code>and</code> dark. 火车站很大，又黑又暗。</li>
<li>The explanation was simple <code>but</code> very unusual. 解释很简单，却异乎寻常</li>
</ul>
</li>
<li>连接宾语补语<ul>
<li>He saw two thieves rush out of a shop <code>and</code> run towards a waiting car. 他看到有两个小偷从一家商店里冲出来，奔向等在那里的一辆汽车。</li>
</ul>
</li>
<li>连接定语<ul>
<li>Pupils of the school, old <code>and</code> new, will be sending him a present to mark the occasion.为了纪念这个日子，学校的学生——无论老同学还是新同学——将送他一件礼物。</li>
</ul>
</li>
<li>连接状语<ul>
<li>We shall all remember Mr. Page for his patience <code>and</code> understanding and for the kindly encouragement.我们不会忘记佩奇先生对我们既有耐心又充满理解，还有亲切鼓励。</li>
</ul>
</li>
<li>注：or连接对等成分的时候，通常翻译为“或者”<ul>
<li>They will go to the zoo <code>or</code> play volleyball. 他们要去动物园或打排球</li>
<li>I want to have a talk with Mr. Jones <code>or</code> Mr. Smith. 我想和琼斯先生或者史密斯先生谈谈。</li>
</ul>
</li>
<li>And也可表示“然后”，“但是”，”那么，则”的意思<ul>
<li>Cease to struggle and you cease to live. 停止奋斗，则终止了生命。</li>
<li>Idleness is sweet, and its consequences are cruel.  懒惰是甜蜜的，但其结果是残酷的。</li>
<li>I will set my goal and work toward it. 我要确定目标，然后为此努力。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="由单一连词衍生的连接词"><a href="#由单一连词衍生的连接词" class="headerlink" title="由单一连词衍生的连接词"></a>由单一连词衍生的连接词</h2><ul>
<li>要么…要么…：either…or…(连接2者以上的结构)<ul>
<li>In answer to these questions I <code>either</code> nodded <code>or</code> made strange noises. 作为对这些问题的回答，我不是点头，就是发出奇怪的声音。</li>
<li><code>Either</code> Bob <code>or</code> Jim or Sam will be the new vice president of the company. 不是鲍勃就是吉姆或者是山姆会成为这家公司的新副总裁。</li>
</ul>
</li>
<li>既不是…也不是…：neither…nor…，也可用其它否定词代替neither<ul>
<li>He answered me, but he spoke <code>neither</code> slowly <code>nor</code> clearly. 他回答了，但他讲得既不慢也不清楚。</li>
<li>We are worried about Mary. She <code>neither</code> eats <code>nor</code> drinks <code>nor</code> talks. 我们替玛丽担心。她不吃不喝也不说话</li>
<li>The story is <code>not</code> interesting <code>nor</code> instructive. 这个故事没有味道，也没有教育意义。</li>
<li>I have <code>never</code> spoken <code>nor</code> written to her. 我跟她从来没说过话，也没写过信。</li>
</ul>
</li>
<li>不是…而是…：not…but…<ul>
<li>I went to the concert <code>not</code> with my brother <code>but</code> with my friend. 我不是和我哥哥去音乐会，而是和我朋友去的。(只能省略动词，不能省略介词)</li>
<li>We choose to go to the moon in this decade and do the other things, <code>not</code> because they are easy, <code>but</code> because they are hard. 我们选择10年内登月以及另外一些事情，不是因为它们容易，而是因为它们困难。(肯尼迪总统在阿波罗登月计划动员会上的讲话)</li>
<li>“Listen, my dear, we must hold on to hope,” my father calm but insistently replied.“<code>Not</code> because hope is real, but because we have to live up to nobility.” “听着，亲爱的，我们必须抱有希望，”我爸爸平静但坚定地回答。“这并不是因为希望真的存在，而是因为我们要做高贵的人。” 《The wandering earth》Liu Cixin (刘慈欣《流浪地球》)</li>
</ul>
</li>
<li>不仅…而且…：not only…but(also)…/not only…but…as well<ul>
<li>He answered all the question <code>not only</code> quickly <code>but (also)</code> accurately. 他回答所有问题时不仅快，而且准确。</li>
<li>The Big Ben is <code>not only</code> of immense size, <code>but</code> is extremely accurate <code>as well.</code> 此钟不仅外型巨大，而且走时也非常准确。</li>
<li>英国英语常用not only… but… as well,</li>
<li>美国英语常用not only… but also…(also可省略)</li>
<li>I <code>not only</code> spoke English very carefully, <code>but</code> very clearly <code>as well</code>.(英)</li>
<li>I <code>not only</code> spoke English very carefully, <code>but (also)</code> very clearly. (美)我的英语讲得不但非常认真，而且咬字也非常清楚。</li>
</ul>
</li>
<li>注：上述并列连词连接的并列名词作主语时，谓语动词的单复数与靠后面的名词一致<ul>
<li>Either Thomas or I <code>am</code> going to call you tomorrow about the job.不是托马斯就是我明天会打电话给你谈工作的事。</li>
</ul>
</li>
<li>…和…两者都：both…and…<ul>
<li>To go far, you need <code>both</code> a dream <code>and</code> a positive attitude.要成功，你需要梦想和积极的态度。</li>
<li>注：本并列连接的并列名词作主语时，谓语动词一律用复数</li>
<li>Both my mother and my sister <code>work</code> at the grocery store. 我妈妈和我姐姐都在这个杂货店工作。</li>
</ul>
</li>
<li>既是…又是…：… as well as …<ul>
<li>Nursing is a vocation <code>as well as</code> a profession. 护理工作既是职业又是救死扶伤的责任。</li>
<li>He shared in my sorrows <code>as well as</code> in my joys. 他分担我的快乐也分享我的悲伤。</li>
<li>注：…as well as…的意思和not only…but (also)…相近，但是前者强调前面的名词，谓语动词与强调的名词一致。<ul>
<li>The bedrooms, as well as the kitchen, <code>need</code> to be repaired if we rent the house. 如果我们要租这个房子，卧室和厨房都需要维修。</li>
</ul>
</li>
</ul>
</li>
<li>是…而不是…：…rather than…<ul>
<li>These are political <code>rather than</code> social matters.这是政治问题而不是社会问题。</li>
</ul>
</li>
</ul>
<h2 id="造句练习"><a href="#造句练习" class="headerlink" title="造句练习"></a>造句练习</h2><ul>
<li>1.中国和印度的人口都超过了10亿。<ul>
<li>1.Both China and India have a population of over one billion.</li>
</ul>
</li>
<li>2.我们应该要么把电脑送修要么买台新的。<ul>
<li>2.We should either get the computer fixed or buy a new one.</li>
</ul>
</li>
<li>3.冰箱里既没有牛奶也没有蔬菜。<ul>
<li>3.Neither milk nor vegetables is in the refrigerator.</li>
</ul>
</li>
<li>4.无论下雪、下雨或者高温天气都不能阻止这些邮递员完成他们的投递工作。<ul>
<li>4.Neither snow nor rain nor hot weather prevents these postmen from completing their deliveries.</li>
</ul>
</li>
<li>5.不是公司董事长而是我将出席明天早上的商务会议。<ul>
<li>5.Not the company’s president but I am going to the business meeting tomorrow morning.</li>
</ul>
</li>
<li>6.我们都喜欢张小姐，不是因为她是我们老师，而是因为她是美女。<ul>
<li>6.We all like Miss Zhang not because she is our teacher but because she is very beautiful.</li>
</ul>
</li>
<li>7.恶心和呕吐都是食物中毒的症状。<ul>
<li>7.Both nausea and vomiting are signs of food poisoning.</li>
</ul>
</li>
<li>8.他不但英语说得非常好，而且还会说法语。<ul>
<li>8.He can not only speak English very well but also French.</li>
</ul>
</li>
<li>9.这名女子听到这个消息的时候是高兴而不是悲伤。<ul>
<li>9.The woman was happy rather than sad when she heard the news</li>
</ul>
</li>
</ul>
<h1 id="6-把句子套进另一个句子里，变身“大名词”"><a href="#6-把句子套进另一个句子里，变身“大名词”" class="headerlink" title="6.把句子套进另一个句子里，变身“大名词”"></a>6.把句子套进另一个句子里，变身“大名词”</h1><ul>
<li>从句是什么<ul>
<li>就是一个句子在另外一个句子里边做句子成分</li>
</ul>
</li>
<li>名词从句<ul>
<li>一个句子，在另外一个句子里边当名词使用</li>
<li>4种用法：主语、宾语、同位语、表语</li>
<li>名词从句需要有引导词：<code>That</code> he doesn’t like to study makes me angry.</li>
</ul>
</li>
<li>that从句：任何一个陈述句，前面加上引导词that，构成that从句。（作宾语/表语时，that可省略）<ul>
<li><code>That</code> everyone may receive a moderate education is an object of vital importance. 每个人能够接受适当的教育似乎是一个至关重要的目标。(主语从句)</li>
<li>Many people pretend <code>that</code> they understand modern art. 有很多人装成很懂现代艺术的样子。(宾语从句)</li>
<li>The most surprising thing about it, however, is <code>that</code> it can land anywhere: on snow, water, or even on a ploughed field. 然而，最令人惊奇的是它能够在任何地方降落:雪地，水面，甚至刚耕过的田里。(表语从句)</li>
<li>No one could account for the fact <code>that</code> one of the boxes was extremely heavy.其中有只箱子特别重，可谁也弄不清是怎么回事。(同位语从句)</li>
</ul>
</li>
<li>that从句作主语时，为了使主干更紧凑，通常可用it作行驶时主语，而将真正的主语后置<ul>
<li>It was obvious <code>that</code> he was very embarrassed. 显然他感到很尴尬。</li>
<li>It is a curious coincidence <code>that</code> Mr. Page will have been teaching for a total of forty years. 佩奇先生执教满总共40年，这真是奇妙的巧合。</li>
</ul>
</li>
<li>consider, deem, think, find, believe五个动词是宾补动词，构成第四大句型，表示“认为…是…”<ul>
<li>我认为健康是非常重要的</li>
<li>I think health very important.其中health是宾语，important是补语</li>
<li>我认为我们每天说英语是重要的</li>
<li>I think that we should speak English important. X</li>
<li>I think it important that we should speak English.√</li>
<li>I think it necessary that you do it at once.我认为你必须立刻做那件事。</li>
<li>We find it necessary that we practice spoken English every day. 我们发现每天练习英语口语很有必要。</li>
</ul>
</li>
<li>whether/if从句：任何一个一般疑问句，前面加上引导词whether或if，构成whether从句，但主语与be动词或助动词的位置还原。如果助动词为do, does, did, 还原后将do, does, did去掉，后面的动词根据人称和时态变化<ul>
<li><code>Whether</code> they would support us was a problem. 他们是否会支持我们还是一个问题。(主语从句) </li>
<li>He asked <code>if</code> Mr Gilbert’s operation had been successful and the doctor told him that it had been. 他问吉尔伯特先生的手术中否成功，医生告诉他手术很成功。(宾语从句)</li>
<li>On the way home, he asked Jenny <code>if</code> she had enjoyed the speech. 在回家的路上，他问珍妮是否喜欢他的祝词。(宾语从句， 直接宾语)</li>
</ul>
</li>
<li>介词后及or not结构中，通常用whether<ul>
<li>My sister is only seven, but she always tells me <code>whether</code> my pictures are good <code>or not</code>. 我的妹妹只有7岁，但她总能说出我的画是好还是坏。</li>
<li>I worry about <code>whether</code> I hurt his feeling. 我担心是否伤害了他的感情</li>
</ul>
</li>
<li>疑问词从句：构成方法与whether从句一样，只是将whether换成疑问词而已，句子必须改为陈述句语序<ul>
<li>He then asked <code>when</code> Mr Gilbert would be allowed to go home and the doctor told him that he would have to stay in hospital for another two weeks.然后他又问吉尔伯特先生什么时候可以回家，医生说他在医院还必须再住上两个星期。(宾语从句，其中when作从句中的状语)</li>
<li>The doctors have not yes decided <code>how</code> the woman died. 医生们至今还未确定这位妇女的死因。</li>
<li>I have no idea <code>what</code> has happened to him. 我不知道他发生了什么事?</li>
</ul>
</li>
<li>造句练习<ul>
<li>1.谁将负责这项工程还没有(被)决定。(be in charge of)<ul>
<li>1.Who will be in charge of the project hasn’t been decided yet.</li>
</ul>
</li>
<li>2.他要来参加这个会议(已经)使得我们每个人激动了。<ul>
<li>2.That he will come to the conference has excited every one of us.</li>
</ul>
</li>
<li>3.他告诉我他们会帮助我们完成整个工作的。<ul>
<li>3.He told me that they would help us finish the whole work.</li>
</ul>
</li>
<li>4.我不知道(wonder)您是否能小声点。<ul>
<li>4.I wonder whether/if you would mind making less noise.</li>
</ul>
</li>
<li>5.我认为每天多喝水是有必要的。<ul>
<li>5.I think it necessary that we (should) take plenty of water every day.</li>
</ul>
</li>
<li>6.我不知道(have no idea)他们什么时候回来定居。<ul>
<li>6.I have no idea when they will be back and settle down.</li>
</ul>
</li>
<li>7.我(已经)发现所有的票都(已经)卖光了。<ul>
<li>7.I have found that all the tickets had been sold out.</li>
</ul>
</li>
<li>8.问题是这部电视剧是否值得一看。<ul>
<li>8.The question is whether the TV play is worth watching.</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>英语</category>
      </categories>
      <tags>
        <tag>英语</tag>
        <tag>语法</tag>
      </tags>
  </entry>
  <entry>
    <title>pytorch第一周学习笔记</title>
    <url>/pytorch-week1/</url>
    <content><![CDATA[<p>最原始编辑版在<a href="https://nbviewer.jupyter.org/github/shiqi-lu/Learn-AI/blob/master/pytorch_deepshare/week1.ipynb">Github链接</a></p>
<h1 id="1-PyTorch简介与安装"><a href="#1-PyTorch简介与安装" class="headerlink" title="1.PyTorch简介与安装"></a>1.PyTorch简介与安装</h1><p>Q:如何安装Pytorch?</p>
<ul>
<li>安装anaconda：<code>conda install pytorch torchvision</code></li>
<li>测试是否安装成功：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.cuda.is_available()</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.__version__</span><br><span class="line"><span class="string">&#x27;1.3.1&#x27;</span></span><br></pre></td></tr></table></figure>


<h1 id="2-张量简介与创建"><a href="#2-张量简介与创建" class="headerlink" title="2.张量简介与创建"></a>2.张量简介与创建</h1><p>Q:张量是什么？</p>
<ul>
<li>一个多维数组，它是标量、向量、矩阵的高维拓展</li>
<li><img src="http://anki190912.xuexihaike.com/20200918142143.png?imageView2/2/h/150"></li>
</ul>
<p>Q:Pytorch中的Variable是什么？与Tensor的关系是什么？</p>
<ul>
<li>Variable是torch.autograd中的数据类型主要用于封装Tensor，进行自动求导</li>
<li>data:被包装的Tensor</li>
<li>grad:data的梯度</li>
<li>grad_fn:创建Tensor的Function，是自动求导的关键</li>
<li>requires_grad:指示是否需要梯度</li>
<li>is_leaf:指示是否是叶子结点（张量）</li>
<li><img src="http://anki190912.xuexihaike.com/20200918143346.png?imageView2/2/w/200"></li>
</ul>
<p>Q:Pytorch中的Tensor是什么？</p>
<ul>
<li>PyTorch 0.4.0开始，Variable并入Tensor</li>
<li>dtype: 张量的数据类型，如torch.FloatTensor, torch.cuda.FloatTensor</li>
<li>shape: 张量的形状，如（64，3， 224， 224）</li>
<li>device: 张量所在设备，GPU/CPU，是加速的关键</li>
<li><img src="http://anki190912.xuexihaike.com/20200918143722.png?imageView2/2/h/100"></li>
</ul>
<p>Q:Tensor的函数原型是怎样？</p>
<ul>
<li><code>torch.tensor(data, dtype=None, device=None, requires_grad=False, pin_memory=False)</code></li>
<li>功能：从data创建tensor</li>
<li>data: 数据，可以是list，numpy</li>
<li>dtype: 数据类型，默认与data一致</li>
<li>device: 所在设备，cuda/cpu</li>
<li>requires_grad: 是否需要梯度</li>
<li>pin_memory:是否存于锁页内存</li>
</ul>
<p>Q:通过torch.tensor创建Tensor的代码是什么？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">arr = np.ones((<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line">print(arr)</span><br><span class="line">print(<span class="string">&#x27;ndarray的数据类型:&#x27;</span>, arr.dtype)</span><br><span class="line"></span><br><span class="line">t = torch.tensor(arr)</span><br><span class="line">print(t)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 放到gpu上</span></span><br><span class="line">t = torch.tensor(arr, device=<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">print(t)</span><br></pre></td></tr></table></figure>

<pre><code>[[1. 1. 1.]
 [1. 1. 1.]
 [1. 1. 1.]]
ndarray的数据类型: float64
tensor([[1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.]], dtype=torch.float64)
tensor([[1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.]], device=&#39;cuda:0&#39;, dtype=torch.float64)</code></pre>
<p>Q:如何通过torch.from_numpy创建张量？</p>
<ul>
<li>函数原型：<code>torch.from_numpy(ndarray)</code></li>
<li>功能：从numpy创建tensor</li>
<li>注意事项：从torch.from_numpy创建的tensor于原ndarray共享内存，当修改其中一个的数据，另外一个也将会被改动</li>
<li><img src="http://anki190912.xuexihaike.com/20200918151039.png?imageView2/2/h/150"></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]])</span><br><span class="line">t = torch.from_numpy(arr)</span><br><span class="line">print(<span class="string">&quot;numpy array:&quot;</span>)</span><br><span class="line">print(arr)</span><br><span class="line">print(<span class="string">&quot;tensor:&quot;</span>)</span><br><span class="line">print(t)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;修改arr:&quot;</span>)</span><br><span class="line">arr[<span class="number">0</span>, <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">print(<span class="string">&quot;numpy array:&quot;</span>)</span><br><span class="line">print(arr)</span><br><span class="line">print(<span class="string">&quot;tensor:&quot;</span>)</span><br><span class="line">print(t)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;修改tensor:&quot;</span>)</span><br><span class="line">arr[<span class="number">1</span>, <span class="number">1</span>] = <span class="number">-10</span></span><br><span class="line">print(<span class="string">&quot;numpy array:&quot;</span>)</span><br><span class="line">print(arr)</span><br><span class="line">print(<span class="string">&quot;tensor:&quot;</span>)</span><br><span class="line">print(t)</span><br></pre></td></tr></table></figure>

<pre><code>numpy array:
[[1 2 3]
 [4 5 6]]
tensor:
tensor([[1, 2, 3],
        [4, 5, 6]])
修改arr:
numpy array:
[[0 2 3]
 [4 5 6]]
tensor:
tensor([[0, 2, 3],
        [4, 5, 6]])
修改tensor:
numpy array:
[[  0   2   3]
 [  4 -10   6]]
tensor:
tensor([[  0,   2,   3],
        [  4, -10,   6]])</code></pre>
<p>Q:如何通过torch.zeros或torch.ones创建张量？</p>
<ul>
<li>函数原型：<code>torch.zeros(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)</code></li>
<li>函数原型：<code>torch.ones(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)</code></li>
<li>功能：依size创建全0张量和全1</li>
<li>size:张量的形状</li>
<li>out:输出的张量，貌似其原始类型必须为tensor，通过out得到的和返回值得到的是完全一样的，相当于赋值</li>
<li>layout:内存中布局形式，有strided,sparse_coo等</li>
<li>device:所在设备,gpu/cpu</li>
<li>requires_grad: 是否需要梯度</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">out_t = torch.tensor([<span class="number">1</span>])</span><br><span class="line">t = torch.zeros((<span class="number">3</span>,<span class="number">3</span>), out=out_t)</span><br><span class="line">print(t)</span><br><span class="line">print(out_t)</span><br><span class="line">print(id(t), id(out_t), id(t) == id(out_t))</span><br></pre></td></tr></table></figure>

<pre><code>tensor([[0, 0, 0],
        [0, 0, 0],
        [0, 0, 0]])
tensor([[0, 0, 0],
        [0, 0, 0],
        [0, 0, 0]])
140556294938560 140556294938560 True</code></pre>
<p>Q:如何通过torch.zeros_like或torch.ones_like创建张量？</p>
<ul>
<li>函数原型：<code>torch.zeros_like(input, dtype=None, layout=None, device=None, requires_grad=False)</code></li>
<li>函数原型：<code>torch.ones_like(input, dtype=None, layout=None, device=None, requires_grad=False)</code></li>
<li>功能：依input形状创建全0张量或全1，input是一个tensor类型</li>
<li>input:创建与input同形状的全0张量</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">t = torch.empty(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">print(torch.zeros_like(t))</span><br><span class="line">print(torch.ones_like(t))</span><br></pre></td></tr></table></figure>

<pre><code>tensor([[0., 0., 0.],
        [0., 0., 0.]])
tensor([[1., 1., 1.],
        [1., 1., 1.]])</code></pre>
<p>Q:如何通过torch.full创建张量？</p>
<ul>
<li><code>torch.full(size, fill_value, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)</code></li>
<li><code>torch.full_like(input, fill_value, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False, memory_format=torch.preserve_format)</code></li>
<li>功能：创建全等张量</li>
<li>size: 张量的形状，如（3,3）</li>
<li>fill_value: 张量的值</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.full((<span class="number">3</span>,<span class="number">3</span>), <span class="number">8</span>)</span><br></pre></td></tr></table></figure>


<pre><code>tensor([[8., 8., 8.],
        [8., 8., 8.],
        [8., 8., 8.]])</code></pre>
<p>Q:如何通过torch.arange创建等差数列的1维张量？</p>
<ul>
<li>函数原型：<code>torch.arange(start=0, end, step=1, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)</code></li>
<li>功能：创建等差为1的张量</li>
<li>注意事项：数值区间为[start, end)</li>
<li>start: 数列起始值</li>
<li>end: 数列“结束值”</li>
<li>step: 数列公差，默认为1</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.arange(<span class="number">2</span>,<span class="number">10</span>,<span class="number">2</span>)</span><br></pre></td></tr></table></figure>




<pre><code>tensor([2, 4, 6, 8])</code></pre>
<p>Q:如何通过torch.linspace创建均分数列张量</p>
<ul>
<li>函数原型：<code>torch.linspace(start=0, end, steps=100, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)</code></li>
<li>功能：创建均分的1维张量</li>
<li>注意事项：数值区间为[start, end]</li>
<li>start: 数列起始值</li>
<li>end: 数列结束值</li>
<li>steps: 数列长度</li>
<li>步长为：(end-start)/(steps-1)</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.linspace(<span class="number">2</span>, <span class="number">10</span>, <span class="number">7</span>)</span><br></pre></td></tr></table></figure>




<pre><code>tensor([ 2.0000,  3.3333,  4.6667,  6.0000,  7.3333,  8.6667, 10.0000])</code></pre>
<p>Q:如何通过torch.logspace创建对数均分的1维张量？</p>
<ul>
<li>函数原型：<code>torch.logspace(start, end, steps=100, base=10.0, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)</code></li>
<li>功能：创建对数均分的1维张量</li>
<li>注意事项：长度为steps，底为base</li>
<li>base: 对数函数的低，默认为10</li>
</ul>
<p>Q:如何通过torch.eye创建单位对角矩阵？</p>
<ul>
<li>函数原型：<code>torch.eye(n, m=None, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)</code></li>
<li>功能：创建单位对角矩阵（2维张量）</li>
<li>注意事项：默认为方阵</li>
<li>n: 矩阵行数</li>
<li>m: 矩阵列数</li>
</ul>
<p>Q:如何通过torch.normal生成正态分布的张量？</p>
<ul>
<li>函数原型：<code>torch.normal(mean, std, *, generator=None, out=None)</code></li>
<li>功能：生成正态分布（高斯分布）</li>
<li>mean: 均值</li>
<li>std: 标准差</li>
<li>因mean和std可以分别为标量和张量，有4种不同的组合</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># mean：张量 std: 张量</span></span><br><span class="line"><span class="comment"># 其中t[i]是从mean[i],std[i]的标准正态分布中采样得来</span></span><br><span class="line">mean = torch.arange(<span class="number">1</span>, <span class="number">5</span>, dtype=torch.float)</span><br><span class="line">std = torch.arange(<span class="number">1</span>, <span class="number">5</span>, dtype=torch.float)</span><br><span class="line">t = torch.normal(mean, std)</span><br><span class="line">print(<span class="string">&quot;mean:&#123;&#125;\nstd:&#123;&#125;&quot;</span>.format(mean, std))</span><br><span class="line">print(t)</span><br><span class="line">print()</span><br><span class="line"></span><br><span class="line"><span class="comment"># mean：标量 std: 标量，此时要指定size大小</span></span><br><span class="line">t_normal = torch.normal(<span class="number">0.</span>, <span class="number">1.</span>, size=(<span class="number">4</span>,))</span><br><span class="line">print(t_normal)</span><br><span class="line">print()</span><br><span class="line"></span><br><span class="line"><span class="comment"># mean：张量 std: 标量</span></span><br><span class="line">mean = torch.arange(<span class="number">1</span>, <span class="number">5</span>, dtype=torch.float)</span><br><span class="line">std = <span class="number">1</span></span><br><span class="line">t_normal = torch.normal(mean, std)</span><br><span class="line">print(<span class="string">&quot;mean:&#123;&#125;\nstd:&#123;&#125;&quot;</span>.format(mean, std))</span><br><span class="line">print(t_normal)</span><br></pre></td></tr></table></figure>

<pre><code>mean:tensor([1., 2., 3., 4.])
std:tensor([1., 2., 3., 4.])
tensor([ 0.6063,  2.9914,  4.0138, -0.5877])

tensor([ 1.1977, -0.1746,  1.5572, -1.1905])

mean:tensor([1., 2., 3., 4.])
std:1
tensor([0.7165, 1.5649, 3.2308, 3.2504])</code></pre>
<p>Q:如何创建标准正态分布的张量？</p>
<ul>
<li><code>torch.randn(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor</code></li>
<li><code>torch.randn_like(input, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format) → Tensor</code></li>
<li>size:张量的形状</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(torch.randn(<span class="number">4</span>))</span><br><span class="line">print(torch.randn(<span class="number">2</span>,<span class="number">3</span>))</span><br></pre></td></tr></table></figure>

<pre><code>tensor([-0.2387, -0.3638,  0.3597,  0.1225])
tensor([[ 0.4709,  0.8593, -0.5970],
        [-0.1133,  0.3273,  0.0106]])</code></pre>
<p>Q:如何生成均匀分布和整数均匀分布的张量？</p>
<ul>
<li>在[0,1)区间上，生成均匀分布</li>
<li><code>torch.rand(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor</code></li>
<li><code>torch.rand_like(input, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format) → Tensor</code></li>
<li>在[low, high)区间生成整数均匀分布</li>
<li><code>torch.randint(low=0, high, size, *, generator=None, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor</code></li>
<li><code>torch.randint_like(input, low=0, high, dtype=None, layout=torch.strided, device=None, requires_grad=False, memory_format=torch.preserve_format) → Tensor</code></li>
<li>其中size是张量形状</li>
</ul>
<p>Q:如何生成从0到n-1的随机排列？</p>
<ul>
<li><code>torch.randperm(n, out=None, dtype=torch.int64, layout=torch.strided, device=None, requires_grad=False) → LongTensor</code></li>
<li>n是张量的长度</li>
<li>经常用于生成乱序索引</li>
</ul>
<p>Q:如何生成一个伯努利分布的张量？</p>
<ul>
<li><code>torch.bernoulli(input, *, generator=None, out=None) → Tensor</code></li>
<li>以input为概率，生成伯努利分布（0-1分布，两点分布）</li>
</ul>
<h1 id="3-张量操作与线性回归"><a href="#3-张量操作与线性回归" class="headerlink" title="3.张量操作与线性回归"></a>3.张量操作与线性回归</h1><h2 id="张量的操作：拼接、切分、索引和变换"><a href="#张量的操作：拼接、切分、索引和变换" class="headerlink" title="张量的操作：拼接、切分、索引和变换"></a>张量的操作：拼接、切分、索引和变换</h2><p>Q:如何用torch.cat对张量进行拼接？</p>
<ul>
<li><code>torch.cat(tensors, dim=0, out=None) → Tensor</code></li>
<li>功能：将张量按维度dim进行拼接</li>
<li>tensors: 张量序列</li>
<li>dim：要拼接的维度</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">t = torch.randn(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">print(t)</span><br><span class="line">t1 = torch.cat([t,t], dim=<span class="number">0</span>)</span><br><span class="line">print(t1)</span><br><span class="line">print(<span class="string">&quot;shape:&quot;</span>, t1.shape)</span><br><span class="line">t2 = torch.cat([t,t], dim=<span class="number">1</span>)</span><br><span class="line">print(t2)</span><br><span class="line">print(<span class="string">&quot;shape:&quot;</span>, t2.shape)</span><br><span class="line"><span class="comment"># dim是指在哪个方向上进行叠加</span></span><br></pre></td></tr></table></figure>

<pre><code>tensor([[-0.6851,  0.0099, -1.4586],
        [ 0.2965,  0.4991, -0.4938]])
tensor([[-0.6851,  0.0099, -1.4586],
        [ 0.2965,  0.4991, -0.4938],
        [-0.6851,  0.0099, -1.4586],
        [ 0.2965,  0.4991, -0.4938]])
shape: torch.Size([4, 3])
tensor([[-0.6851,  0.0099, -1.4586, -0.6851,  0.0099, -1.4586],
        [ 0.2965,  0.4991, -0.4938,  0.2965,  0.4991, -0.4938]])
shape: torch.Size([2, 6])</code></pre>
<p>Q:如何用torch.stack对张量进行拼接？</p>
<ul>
<li><code>torch.stack(tensors, dim=0, out=None) → Tensor</code></li>
<li>功能：在新创建的维度dim上进行拼接</li>
<li>tensors:张量序列</li>
<li>dim：要拼接的维度</li>
<li>注意：cat不会扩张张量的维度，stack会扩张，相当于insert</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">t = torch.randn(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">print(t)</span><br><span class="line">t1 = torch.stack([t,t], dim=<span class="number">0</span>)</span><br><span class="line">print(t1)</span><br><span class="line">print(<span class="string">&quot;shape:&quot;</span>, t1.shape)</span><br></pre></td></tr></table></figure>

<pre><code>tensor([[ 0.6266,  0.8918,  0.6165],
        [ 1.1646, -1.8152, -0.7309]])
tensor([[[ 0.6266,  0.8918,  0.6165],
         [ 1.1646, -1.8152, -0.7309]],

        [[ 0.6266,  0.8918,  0.6165],
         [ 1.1646, -1.8152, -0.7309]]])
shape: torch.Size([2, 2, 3])</code></pre>
<p>Q:如何用torch.chunk对切分张量？</p>
<ul>
<li><code>torch.chunk(input, chunks, dim=0) → List of Tensors</code></li>
<li>功能：将张量按维度dim进行平均切分</li>
<li>返回值：张量列表</li>
<li>注意事项：若不能整除，最后一份张量小于其它张量</li>
<li>input：要切分的张量</li>
<li>chunks：要切分的份数</li>
<li>dim：要切分的维度</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.ones((<span class="number">2</span>,<span class="number">7</span>))</span><br><span class="line">print(a)</span><br><span class="line">list_of_tensors = torch.chunk(a, dim=<span class="number">1</span>, chunks=<span class="number">3</span>)</span><br><span class="line"><span class="keyword">for</span> i, t <span class="keyword">in</span> enumerate(list_of_tensors):</span><br><span class="line">    print(<span class="string">f&quot;第<span class="subst">&#123;i&#125;</span>个张量：&quot;</span>)</span><br><span class="line">    print(t)</span><br><span class="line"><span class="comment"># 切分后的长度的计算方式为：7/3向上取整为3</span></span><br></pre></td></tr></table></figure>

<pre><code>tensor([[1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1.]])
第0个张量：
tensor([[1., 1., 1.],
        [1., 1., 1.]])
第1个张量：
tensor([[1., 1., 1.],
        [1., 1., 1.]])
第2个张量：
tensor([[1.],
        [1.]])</code></pre>
<p>Q:如何用torch.split对张量进行切分？</p>
<ul>
<li><code>torch.split(tensor, split_size_or_sections, dim=0)</code></li>
<li>功能：将张量按维度dim进行平均切分</li>
<li>返回值：张量列表</li>
<li>tensor：要切分的张量</li>
<li>split_size_or_sections：为int时，表示每一份的长度；为list时，按list元素切分，list元素和必须为该维度的长度</li>
<li>dim：要切分的维度</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.ones((<span class="number">2</span>,<span class="number">7</span>))</span><br><span class="line">print(a)</span><br><span class="line">list_of_tensors = torch.split(a, [<span class="number">2</span>,<span class="number">4</span>,<span class="number">1</span>], dim=<span class="number">1</span>)</span><br><span class="line"><span class="keyword">for</span> i, t <span class="keyword">in</span> enumerate(list_of_tensors):</span><br><span class="line">    print(<span class="string">f&quot;第<span class="subst">&#123;i&#125;</span>个张量：&quot;</span>)</span><br><span class="line">    print(t)</span><br></pre></td></tr></table></figure>

<pre><code>tensor([[1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1.]])
第0个张量：
tensor([[1., 1.],
        [1., 1.]])
第1个张量：
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.]])
第2个张量：
tensor([[1.],
        [1.]])</code></pre>
<p>Q:如何在dim维度上，按index索引数据？</p>
<ul>
<li><code>torch.index_select(input, dim, index, out=None) → Tensor</code></li>
<li>返回值：按index索引数据拼接的张量</li>
<li>input：要索引的张量</li>
<li>dim：要索引的维度</li>
<li>index：要索引数据的序号</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">t = torch.randint(<span class="number">0</span>,<span class="number">9</span>, size=(<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line">idx = torch.tensor([<span class="number">0</span>,<span class="number">2</span>], dtype=torch.long)</span><br><span class="line">t_select = torch.index_select(t, dim=<span class="number">0</span>, index=idx)</span><br><span class="line">print(t)</span><br><span class="line">print(idx)</span><br><span class="line">print(t_select)</span><br></pre></td></tr></table></figure>

<pre><code>tensor([[1, 2, 8],
        [2, 3, 0],
        [0, 2, 0]])
tensor([0, 2])
tensor([[1, 2, 8],
        [0, 2, 0]])</code></pre>
<p>Q:如何对张量按mask中的True进行索引？</p>
<ul>
<li><code>torch.masked_select(input, mask, out=None) → Tensor</code></li>
<li>返回值：一维张量</li>
<li>input：要索引的张量</li>
<li>mask：与input同形状的布尔类型张量</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">t = torch.randint(<span class="number">0</span>, <span class="number">9</span>, size=(<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line">print(t)</span><br><span class="line">mask = t.le(<span class="number">5</span>) <span class="comment"># le是小于等于，还有lt,gt,ge</span></span><br><span class="line">print(mask)</span><br><span class="line">t_select = torch.masked_select(t, mask)</span><br><span class="line">print(t_select)</span><br></pre></td></tr></table></figure>

<pre><code>tensor([[2, 5, 0],
        [5, 8, 5],
        [2, 8, 5]])
tensor([[ True,  True,  True],
        [ True, False,  True],
        [ True, False,  True]])
tensor([2, 5, 0, 5, 5, 2, 5])</code></pre>
<p>Q:如何改变张量的形状？</p>
<ul>
<li><code>torch.reshape(input, shape) → Tensor</code></li>
<li>注意事项：当张量在内存中是连续时，新张量与input共享数据内存</li>
<li>input：要变换的张量</li>
<li>shape：新张量的形状，允许某个维度为-1，意味着这个维度根据其它的算出来的</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">t = torch.randperm(<span class="number">8</span>)</span><br><span class="line">t_reshape = torch.reshape(t, (<span class="number">2</span>,<span class="number">4</span>))</span><br><span class="line">print(t)</span><br><span class="line">print(t_reshape)</span><br></pre></td></tr></table></figure>

<pre><code>tensor([2, 0, 7, 5, 6, 4, 3, 1])
tensor([[2, 0, 7, 5],
        [6, 4, 3, 1]])</code></pre>
<p>Q:如何交换张量的两个维度？</p>
<ul>
<li><code>torch.transpose(input, dim0, dim1) → Tensor</code></li>
<li>input：要交换的张量</li>
<li>dim0，dim1：要交换的维度</li>
<li>若为2维张量转置，即矩阵转置，可使用<code>torch.t(input) → Tensor</code>，等价于<code>torch.transpose(input, 0, 1)</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">t = torch.rand((<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line">t_transpose = torch.transpose(t, dim0=<span class="number">1</span>,dim1=<span class="number">2</span>)</span><br><span class="line">print(t)</span><br><span class="line">print(t_transpose)</span><br></pre></td></tr></table></figure>

<pre><code>tensor([[[0.8657, 0.5869, 0.1105, 0.4381],
         [0.7276, 0.6606, 0.3778, 0.3643],
         [0.6180, 0.6693, 0.9983, 0.4252]],

        [[0.3526, 0.6365, 0.6643, 0.5310],
         [0.4653, 0.5056, 0.1065, 0.7873],
         [0.6175, 0.6650, 0.1325, 0.5837]]])
tensor([[[0.8657, 0.7276, 0.6180],
         [0.5869, 0.6606, 0.6693],
         [0.1105, 0.3778, 0.9983],
         [0.4381, 0.3643, 0.4252]],

        [[0.3526, 0.4653, 0.6175],
         [0.6365, 0.5056, 0.6650],
         [0.6643, 0.1065, 0.1325],
         [0.5310, 0.7873, 0.5837]]])</code></pre>
<p>Q:如何压缩长度为1的维度（轴）？</p>
<ul>
<li><code>torch.squeeze(input, dim=None, out=None) → Tensor</code></li>
<li>dim: 若为None，移除所有长度为1的轴；若指定维度，当且仅当该轴长度为1时，可以被移除</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">t = torch.rand((<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>))</span><br><span class="line">t_sq = torch.squeeze(t)</span><br><span class="line">t_0 = torch.squeeze(t, dim=<span class="number">0</span>)</span><br><span class="line">t_1 = torch.squeeze(t, dim=<span class="number">1</span>)</span><br><span class="line">print(t.shape)</span><br><span class="line">print(t_sq.shape)</span><br><span class="line">print(t_0.shape)</span><br><span class="line">print(t_1.shape)</span><br></pre></td></tr></table></figure>

<pre><code>torch.Size([1, 2, 3, 1])
torch.Size([2, 3])
torch.Size([2, 3, 1])
torch.Size([1, 2, 3, 1])</code></pre>
<p>Q:如何根据dim扩展维度？</p>
<ul>
<li><code>torch.unsqueeze(input, dim) → Tensor</code></li>
<li>dim:扩展的维度</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">t = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">print(t)</span><br><span class="line">t1 = torch.unsqueeze(t, <span class="number">0</span>)</span><br><span class="line">print(t1)</span><br><span class="line">t2 = torch.unsqueeze(t, <span class="number">1</span>)</span><br><span class="line">print(t2)</span><br></pre></td></tr></table></figure>

<pre><code>tensor([1, 2, 3, 4])
tensor([[1, 2, 3, 4]])
tensor([[1],
        [2],
        [3],
        [4]])</code></pre>
<h2 id="张量的数学运算"><a href="#张量的数学运算" class="headerlink" title="张量的数学运算"></a>张量的数学运算</h2><p>Q:有哪些常见的数学运算？</p>
<ul>
<li>一、加减乘除<ul>
<li>torch.add()</li>
<li>torch.addcdiv()</li>
<li>torch.addcmul()</li>
<li>torch.sub() </li>
<li>torch.div()</li>
<li>torch.mul()</li>
</ul>
</li>
<li>二、对数，指数，幂函数<ul>
<li>torch.log(input, out=None)</li>
<li>torch.log10(input, out=None)</li>
<li>torch.log2(input, out=None)</li>
<li>torch.exp(input, out=None)</li>
<li>torch.pow()</li>
</ul>
</li>
<li>三、三角函数<ul>
<li>torch.abs(input, out=None)</li>
<li>torch.acos(input, out=None)</li>
<li>torch.cosh(input, out=None)</li>
<li>torch.cos(input, out=None)</li>
<li>torch.asin(input, out=None)</li>
<li>torch.atan(input, out=None)</li>
<li>torch.atan2(input, other, out=None)</li>
</ul>
</li>
</ul>
<p>Q:如何逐元素计算input + alpha x other?</p>
<ul>
<li><code>torch.add(input, other, *, alpha=1, out=None)</code></li>
<li>input：第一个张量</li>
<li>alpha：乘项因子</li>
<li>other：第二个张量</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">t_0 = torch.randn((<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line">t_1 = torch.ones_like(t_0)</span><br><span class="line">t_add = torch.add(t_0, t_1, alpha=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;t_0:\n&#123;&#125;\nt_1:\n&#123;&#125;\nt_add_10:\n&#123;&#125;&quot;</span>.format(t_0, t_1, t_add))</span><br></pre></td></tr></table></figure>

<pre><code>t_0:
tensor([[ 0.5570, -0.4743,  1.0113],
        [-1.2665,  0.1997, -0.6957],
        [-0.0714, -0.7002, -1.4687]])
t_1:
tensor([[1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.]])
t_add_10:
tensor([[10.5570,  9.5257, 11.0113],
        [ 8.7335, 10.1997,  9.3043],
        [ 9.9286,  9.2998,  8.5313]])</code></pre>
<p>Q:如何计算$\text { out }<em>{i}=\text { input }</em>{i}+\text { value } \times \text { tensor } 1_{i} \times \text { tensor } 2_{i}$</p>
<ul>
<li><code>torch.addcmul(input, tensor1, tensor2, *, value=1, out=None) → Tensor</code></li>
</ul>
<p>Q:如何计算$\text { out }<em>{i}=\text { input }</em>{i}+\text { value } \times \frac{\text { tensor } 1}{\text { tensor } 2_{i}}$</p>
<ul>
<li><code>torch.addcdiv(input, tensor1, tensor2, *, value=1, out=None) → Tensor</code></li>
</ul>
<h2 id="线性回归的Pytorch实现"><a href="#线性回归的Pytorch实现" class="headerlink" title="线性回归的Pytorch实现"></a>线性回归的Pytorch实现</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">torch.manual_seed(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">lr = <span class="number">0.05</span>  <span class="comment"># 学习率</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建训练数据</span></span><br><span class="line">x = torch.rand(<span class="number">20</span>, <span class="number">1</span>) * <span class="number">10</span>  <span class="comment"># x data (tensor), shape=(20, 1)</span></span><br><span class="line">y = <span class="number">2</span>*x + (<span class="number">5</span> + torch.randn(<span class="number">20</span>, <span class="number">1</span>))  <span class="comment"># y data (tensor), shape=(20, 1)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建线性回归参数的初始值</span></span><br><span class="line">w = torch.randn((<span class="number">1</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line">b = torch.zeros((<span class="number">1</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> iteration <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 前向传播，计算y_pred=w * x+b</span></span><br><span class="line">    wx = torch.mul(w, x)</span><br><span class="line">    y_pred = torch.add(wx, b)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算 MSE loss</span></span><br><span class="line">    loss = (<span class="number">0.5</span> * (y - y_pred) ** <span class="number">2</span>).mean()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 反向传播</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 更新参数</span></span><br><span class="line">    b.data.sub_(lr * b.grad)</span><br><span class="line">    w.data.sub_(lr * w.grad)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 清零张量的梯度</span></span><br><span class="line">    w.grad.zero_()</span><br><span class="line">    b.grad.zero_()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘图</span></span><br><span class="line">    <span class="keyword">if</span> iteration % <span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">        plt.scatter(x.data.numpy(), y.data.numpy())</span><br><span class="line">        plt.plot(x.data.numpy(), y_pred.data.numpy(), <span class="string">&#x27;r-&#x27;</span>, lw=<span class="number">5</span>)</span><br><span class="line">        plt.text(<span class="number">2</span>, <span class="number">20</span>, <span class="string">&#x27;Loss=%.4f&#x27;</span> % loss.data.numpy(), fontdict=&#123;<span class="string">&#x27;size&#x27;</span>: <span class="number">20</span>, <span class="string">&#x27;color&#x27;</span>:  <span class="string">&#x27;red&#x27;</span>&#125;)</span><br><span class="line">        plt.xlim(<span class="number">1.5</span>, <span class="number">10</span>)</span><br><span class="line">        plt.ylim(<span class="number">8</span>, <span class="number">28</span>)</span><br><span class="line">        plt.title(<span class="string">f&quot;Iteration: <span class="subst">&#123;iteration&#125;</span>\nw: <span class="subst">&#123;w.data.numpy()&#125;</span> b: <span class="subst">&#123;b.data.numpy()&#125;</span>&quot;</span>)</span><br><span class="line">        plt.pause(<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> loss.data.numpy() &lt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="http://anki190912.xuexihaike.com/20200920095346.png"></p>
<h1 id="4-计算图与动态图机制"><a href="#4-计算图与动态图机制" class="headerlink" title="4.计算图与动态图机制"></a>4.计算图与动态图机制</h1><p>Q:计算图是什么？</p>
<ul>
<li>用来描述运算的有向无环图</li>
<li>有两个主要元素：结点（Node）和边（Edge）</li>
<li>结点表示数据，如向量、矩阵、张量，边表示运算，如加减乘除卷积等</li>
</ul>
<p>Q:如何用计算图表示$y = (x+w)*(w+1)$?</p>
<ul>
<li>$a = x + w, b = w + 1, y = a * b$</li>
<li><img src="http://anki190912.xuexihaike.com/20200919144309.png?imageView2/2/h/200"></li>
</ul>
<p>Q:如何用计算图进行梯度求导，如$y = (x+w)*(w+1)$</p>
<ul>
<li>$a = x + w, b = w + 1, y = a * b$</li>
<li>$$\begin{aligned}<br>\frac{\partial \mathrm{y}}{\partial w} &amp;=\frac{\partial \mathrm{y}}{\partial a} \frac{\partial a}{\partial w}+\frac{\partial \mathrm{y}}{\partial b} \frac{\partial b}{\partial w} \\<br>&amp;=b * 1+\mathrm{a} * 1 \\<br>&amp;=\mathrm{b}+\mathrm{a} \\<br>&amp;=(\mathrm{w}+1)+(\mathrm{x}+\mathrm{w}) \\<br>&amp;=2 * \mathrm{w}+\mathrm{x}+1 \\<br>&amp;=2 * 1+2+1=5\end{aligned}$$</li>
<li><img src="http://anki190912.xuexihaike.com/20200919144541.png?imageView2/2/h/200"></li>
<li>y对w求导在计算图中其实就是找到y到w的所有路径上的导数，进行求和</li>
</ul>
<p>Q:叶子结点是什么？</p>
<ul>
<li><img src="http://anki190912.xuexihaike.com/20200919144541.png?imageView2/2/h/200"></li>
<li>用户创建的结点称为叶子结点，如X和W</li>
<li>torch.Tensor中有is_leaf指示张量是否为叶子结点</li>
<li>设置叶子结点主要是为了节省内存，因为非叶子结点的梯度在反向传播后会被释放掉</li>
<li>若需要保留非叶子结点的梯度，可使用retain_grad()方法</li>
</ul>
<p>Q:torch.Tensor中的grad_fn作用是什么？</p>
<ul>
<li>记录创建该张量时所用的方法（函数）</li>
<li><img src="http://anki190912.xuexihaike.com/20200919144541.png?imageView2/2/h/200"></li>
<li>y.grad_fn = &lt;MulBackward0&gt;</li>
<li>a.grad_fn = &lt;AddBackward0&gt;</li>
</ul>
<p>Q:$y = (x+w)*(w+1)$计算图的代码示例，求解y对w的梯度？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">w = torch.tensor([<span class="number">1.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">x = torch.tensor([<span class="number">2.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">a = torch.add(w, x)</span><br><span class="line"><span class="comment"># 若需要保留非叶子结点a的梯度，否则调用a.grad时为None</span></span><br><span class="line"><span class="comment"># a.retain_grad()</span></span><br><span class="line">b = torch.add(w, <span class="number">1</span>)</span><br><span class="line">y = torch.mul(a, b)</span><br><span class="line"></span><br><span class="line">y.backward()</span><br><span class="line">print(w.grad)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看叶子结点</span></span><br><span class="line">print(<span class="string">&quot;\nis_leaf:\n&quot;</span>, w.is_leaf, x.is_leaf, a.is_leaf, b.is_leaf, y.is_leaf)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看梯度</span></span><br><span class="line">print(<span class="string">&quot;\ngradient:\n&quot;</span>, w.grad, x.grad, a.grad, b.grad, y.grad)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 grad_fn</span></span><br><span class="line">print(<span class="string">&quot;\ngrad_fn:\n&quot;</span>, w.grad_fn, x.grad_fn, a.grad_fn, b.grad_fn, y.grad_fn)</span><br></pre></td></tr></table></figure>

<pre><code>tensor([5.])

is_leaf:
 True True False False False

gradient:
 tensor([5.]) tensor([2.]) None None None

grad_fn:
 None None &lt;AddBackward0 object at 0x7fd54938bb00&gt; &lt;AddBackward0 object at 0x7fd5285f4c50&gt; &lt;MulBackward0 object at 0x7fd5285f4be0&gt;</code></pre>
<h1 id="5-autograd与逻辑回归"><a href="#5-autograd与逻辑回归" class="headerlink" title="5.autograd与逻辑回归"></a>5.autograd与逻辑回归</h1><p>Q:torch.autograd.backward是什么？</p>
<ul>
<li>torch.autograd.backward(tensors: Union[torch.Tensor, Sequence[torch.Tensor]], grad_tensors: Union[torch.Tensor, Sequence[torch.Tensor], None] = None, retain_graph: Optional[bool] = None, create_graph: bool = False, grad_variables: Union[torch.Tensor, Sequence[torch.Tensor], None] = None) → None</li>
<li>功能：自动求取梯度</li>
<li>tensors：用于求导的张量，如loss</li>
<li>retain_graph：保存计算图，若不保存，则紧接着再调用一次backward()会报错</li>
<li>create_graph：创建导数计算图，用于高阶求导</li>
<li>grad_tensors：多梯度权重</li>
</ul>
<p>Q:torch.autograd.backward中的retain_graph的代码示例？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">w = torch.tensor([<span class="number">1.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">x = torch.tensor([<span class="number">2.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">a = torch.add(w, x)</span><br><span class="line">b = torch.add(w, <span class="number">1</span>)</span><br><span class="line">y = torch.mul(a, b)</span><br><span class="line"></span><br><span class="line">y.backward(retain_graph=<span class="literal">True</span></span><br><span class="line">          )</span><br><span class="line">print(w.grad)</span><br><span class="line">y.backward()</span><br><span class="line">print(w.grad)</span><br></pre></td></tr></table></figure>

<pre><code>tensor([5.])
tensor([10.])</code></pre>
<p>Q:torch.autograd.backward中的grad_tensors的代码示例？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">w = torch.tensor([<span class="number">1.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">x = torch.tensor([<span class="number">2.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">a = torch.add(w, x)     <span class="comment"># retain_grad()</span></span><br><span class="line">b = torch.add(w, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">y0 = torch.mul(a, b)    <span class="comment"># y0 = (x+w) * (w+1)</span></span><br><span class="line">y1 = torch.add(a, b)    <span class="comment"># y1 = (x+w) + (w+1)    dy1/dw = 2</span></span><br><span class="line"></span><br><span class="line">loss = torch.cat([y0, y1], dim=<span class="number">0</span>)       <span class="comment"># [y0, y1]</span></span><br><span class="line">grad_tensors = torch.tensor([<span class="number">1.</span>, <span class="number">2.</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># gradient 传入 torch.autograd.backward()中的grad_tensors</span></span><br><span class="line">loss.backward(gradient=grad_tensors)</span><br><span class="line"><span class="comment"># 实际上相当于1*y0导数+2*y1导数</span></span><br><span class="line"></span><br><span class="line">print(w.grad)</span><br></pre></td></tr></table></figure>

<pre><code>tensor([9.])</code></pre>
<p>Q:torch.autograd.grad是什么？</p>
<ul>
<li>torch.autograd.grad(outputs: Union[torch.Tensor, Sequence[torch.Tensor]], inputs: Union[torch.Tensor, Sequence[torch.Tensor]], grad_outputs: Union[torch.Tensor, Sequence[torch.Tensor], None] = None, retain_graph: Optional[bool] = None, create_graph: bool = False, only_inputs: bool = True, allow_unused: bool = False) → Tuple[torch.Tensor, …]</li>
<li>功能：求取梯度</li>
<li>outputs：用于求导的张量，如loss</li>
<li>inputs：需要梯度的张量</li>
<li>create_graph：创建导数计算图，用于高阶求导</li>
<li>retain_graph：保存计算图</li>
<li>grad_outputs：多梯度权重</li>
</ul>
<p>Q:如何使用torch.autograd.grad对$y=x^2$进行一阶和二阶求导？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = torch.tensor([<span class="number">3.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">y = torch.pow(x, <span class="number">2</span>)  <span class="comment"># y = x**2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># grad_1 = dy/dx = 2x = 2 * 3 = 6</span></span><br><span class="line">grad_1 = torch.autograd.grad(y, x, create_graph=<span class="literal">True</span>)</span><br><span class="line">print(grad_1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># grad_2 = d(dy/dx)/dx = d(2x)/dx = 2</span></span><br><span class="line"><span class="comment"># grad_1的返回值是元组，所以要取出第一个</span></span><br><span class="line">grad_2 = torch.autograd.grad(grad_1[<span class="number">0</span>], x)</span><br><span class="line">print(grad_2)</span><br></pre></td></tr></table></figure>

<pre><code>(tensor([6.], grad_fn=&lt;MulBackward0&gt;),)
(tensor([2.]),)</code></pre>
<p>Q:autograd的3点使用小贴士是什么？</p>
<ul>
<li>1.梯度不自动清零，每次传播时会一直叠加上去，所以使用梯度之后要手动进行清零，即w.grad.zero_()，其中下划线表示inplace（原地）操作</li>
<li>2.依赖于叶子结点的节点，requires_grad默认为True</li>
<li>3.叶子结点不可执行in-place</li>
</ul>
<p>Q:逻辑回归的pytorch代码实现是什么？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">torch.manual_seed(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成数据</span></span><br><span class="line">sample_nums = <span class="number">100</span></span><br><span class="line">mean_value = <span class="number">1.7</span></span><br><span class="line">bias = <span class="number">1</span></span><br><span class="line">n_data = torch.ones(sample_nums, <span class="number">2</span>)</span><br><span class="line"><span class="comment"># 类别0 数据 shape=(100, 2)</span></span><br><span class="line">x0 = torch.normal(mean_value * n_data, <span class="number">1</span>) + bias</span><br><span class="line"><span class="comment"># 类别0 标签 shape=(100)</span></span><br><span class="line">y0 = torch.zeros(sample_nums)</span><br><span class="line"><span class="comment"># 类别1 数据 shape=(100, 2)</span></span><br><span class="line">x1 = torch.normal(-mean_value * n_data, <span class="number">1</span>) + bias</span><br><span class="line"><span class="comment"># 类别1 标签 shape=(100)</span></span><br><span class="line">y1 = torch.ones(sample_nums)</span><br><span class="line">train_x = torch.cat((x0, x1), <span class="number">0</span>)</span><br><span class="line">train_y = torch.cat((y0, y1), <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择模型</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LR</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        super(LR, self).__init__()</span><br><span class="line">        self.features = nn.Linear(<span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.features(x)</span><br><span class="line">        x = self.sigmoid(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化逻辑回归模型</span></span><br><span class="line">lr_net = LR()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择损失函数，交叉熵损失</span></span><br><span class="line">loss_fn = nn.BCELoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择优化器</span></span><br><span class="line">lr = <span class="number">0.01</span> <span class="comment"># 学习率</span></span><br><span class="line">optimizer = torch.optim.SGD(lr_net.parameters(), lr=lr, momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line"><span class="keyword">for</span> iteration <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    <span class="comment"># 前向传播</span></span><br><span class="line">    y_pred = lr_net(train_x)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算loss</span></span><br><span class="line">    loss = loss_fn(y_pred.squeeze(), train_y)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 反向传播</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 更新参数</span></span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 清空梯度</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 绘图</span></span><br><span class="line">    <span class="keyword">if</span> iteration % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 以0.5为阈值进行分类</span></span><br><span class="line">        mask = y_pred.ge(<span class="number">0.5</span>).float().squeeze()</span><br><span class="line">        <span class="comment"># 计算正确预测的样本个数</span></span><br><span class="line">        correct = (mask == train_y).sum()</span><br><span class="line">        <span class="comment"># 计算分类准确率</span></span><br><span class="line">        acc = correct.item() / train_y.size(<span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line">        plt.scatter(x0.data.numpy()[:, <span class="number">0</span>], x0.data.numpy()[:, <span class="number">1</span>], c=<span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;class 0&#x27;</span>)</span><br><span class="line">        plt.scatter(x1.data.numpy()[:, <span class="number">0</span>], x1.data.numpy()[:, <span class="number">1</span>], c=<span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;class 1&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        w0, w1 = lr_net.features.weight[<span class="number">0</span>]</span><br><span class="line">        w0, w1 = float(w0.item()), float(w1.item())</span><br><span class="line">        plot_b = float(lr_net.features.bias[<span class="number">0</span>].item())</span><br><span class="line">        plot_x = np.arange(<span class="number">-6</span>, <span class="number">6</span>, <span class="number">0.1</span>)</span><br><span class="line">        plot_y = (-w0 * plot_x - plot_b) / w1</span><br><span class="line">        </span><br><span class="line">        plt.xlim(<span class="number">-5</span>, <span class="number">7</span>)</span><br><span class="line">        plt.ylim(<span class="number">-7</span>, <span class="number">7</span>)</span><br><span class="line">        plt.plot(plot_x, plot_y)</span><br><span class="line">        </span><br><span class="line">        plt.text(<span class="number">-5</span>, <span class="number">5</span>, <span class="string">&#x27;Loss=%.4f&#x27;</span> % loss.data.numpy(), fontdict=&#123;<span class="string">&#x27;size&#x27;</span>:<span class="number">20</span>, <span class="string">&#x27;color&#x27;</span>:<span class="string">&#x27;red&#x27;</span>&#125;)</span><br><span class="line">        plt.title(<span class="string">&quot;Iteration: &#123;&#125;\nw0:&#123;:.2f&#125; w1:&#123;:.2f&#125; b: &#123;:.2f&#125; accuracy:&#123;:.2%&#125;&quot;</span>.format(iteration, w0, w1, plot_b, acc))</span><br><span class="line">        plt.legend()</span><br><span class="line"></span><br><span class="line">        plt.show()</span><br><span class="line">        plt.pause(<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> acc &gt; <span class="number">0.99</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<p><img src="http://anki190912.xuexihaike.com/20200920100028.png"></p>
]]></content>
      <categories>
        <category>pytorch学习笔记</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>恶魔奶爸语法1-3课</title>
    <url>/gramma1-3/</url>
    <content><![CDATA[<h1 id="1-英语简单句的造句规则和基本语法概念"><a href="#1-英语简单句的造句规则和基本语法概念" class="headerlink" title="1.英语简单句的造句规则和基本语法概念"></a>1.英语简单句的造句规则和基本语法概念</h1><h2 id="一些基本的语法概念"><a href="#一些基本的语法概念" class="headerlink" title="一些基本的语法概念"></a>一些基本的语法概念</h2><ul>
<li>英语单词分为虚词和实词<ul>
<li>虚词：介词，连词</li>
<li>实词：名词，动词，形容词，副词</li>
</ul>
</li>
<li>句子成分：主谓宾</li>
</ul>
<h2 id="英语句子的本质和灵魂：五大动词——五大句型"><a href="#英语句子的本质和灵魂：五大动词——五大句型" class="headerlink" title="英语句子的本质和灵魂：五大动词——五大句型"></a>英语句子的本质和灵魂：五大动词——五大句型</h2><h3 id="系动词-gt-主语-系动词-表语（主系表句型）"><a href="#系动词-gt-主语-系动词-表语（主系表句型）" class="headerlink" title="系动词-&gt;主语+系动词+表语（主系表句型）"></a>系动词-&gt;主语+系动词+表语（主系表句型）</h3><ul>
<li>什么是系动词<ul>
<li>所谓的系动词，也属于动词的一种在句子里做谓语，没有实际意思比如汉语里的”是”、”为”英语里的am、is、 are就是联系，在句子中起一个联系作用，叫做系动词。</li>
</ul>
</li>
<li>什么是表语<ul>
<li>而在联系动词之后的补充说明主语性质的部分，就叫做表语</li>
</ul>
</li>
<li>如何判断主系表结构<ul>
<li>用中文判断这个句子里的谓语，可否用“是”或者“为”来翻译</li>
<li>I am a good person</li>
<li>I become a good person</li>
</ul>
</li>
<li>4大类系动词<ul>
<li>1.be动词：am is are和它们对应的过去将来时态，在be动词之后，有3大类表语：名词、形容词、地点副词<ul>
<li>名词作表语：这种句子和汉语可以完全对应，be动词翻译成汉语“是”<ul>
<li>Tim is an engineer.蒂姆是个工程师</li>
<li>The price is £2,000! 价格是2,000英镑!</li>
</ul>
</li>
<li>形容词作表语：和汉语不一样，be动词不会被翻译，直接被省略，介词短语也相当于形容词<ul>
<li>The play was very interesting. 戏很有意思</li>
<li>The milk is in the refrigerator. 牛奶在冰箱里</li>
</ul>
</li>
<li>地点副词作表语：只能是地点副词，别的副词不行<ul>
<li>Your sister is here these days. 你姐姐这几天在这</li>
<li>My bedroom is downstairs. 我的卧室在楼下</li>
</ul>
</li>
</ul>
</li>
<li>2.状态保持动词（keep, remain, stay）后只能加形容词作表语，可以和be无缝切换<ul>
<li>You should keep quiet! 你应该保持安静!</li>
<li>No one can remain youthful forever. 没有人能永保青春。</li>
<li>The weather stayed fine for a week. 这个星期天气一直很好。</li>
</ul>
</li>
<li>3.状态转变类动词(become, get, go, come, grow, turn)<ul>
<li>become:万能词，表示“变成”的时候后面只能接名词，表示“变得”后面一般接形容词<ul>
<li>He became a teacher.他成为了一名教师</li>
<li>He became very nervous. 他变得很紧张</li>
</ul>
</li>
<li>get:表示“变得怎样”，后面只能加形容词<ul>
<li>He got very angry. 他非常生气</li>
</ul>
</li>
<li>come:本意是来，通常是好的东西会来，所以come含有“变好”的意思<ul>
<li>Thing will come right.事情会变好</li>
</ul>
</li>
<li>go:意思是走，去，通常是坏的东西离你而去，所以可表达“变坏”<ul>
<li>The meat always goes bad in summer. 肉在夏天经常会坏掉</li>
</ul>
</li>
<li>grow:本意“生长”，可表达“慢慢变”<ul>
<li>The weather grew cold in the night.晚上天气慢慢变冷</li>
</ul>
</li>
<li>turn:本意转身，可表达“快速变”<ul>
<li>His face turned pale.他脸色变得苍白</li>
</ul>
</li>
</ul>
</li>
<li>4.感官动词(look, sound, smell, taset, feel)：一律翻译为“。。。起来”，即看起来，听起来。。后面只能接形容词（或相当于形容词的分词）作表语<ul>
<li>I felt very nervous when I went into his office.我走进他的办公室，感到非常紧张。</li>
<li>He looked very angry.他看上去非常气愤。</li>
<li>They were all hungry and the food smelled good.他们全都饿了，饭菜散发出阵阵香味。</li>
<li>感官动词后，决不能直接加名词作表语，如要加名词，必须用：感官动词+介词like+名词，此时翻译为”像…..”<ul>
<li>The sun looks like an orange globe.太阳看上去像只橙色的球体。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>造句练习<ul>
<li>每件事都很有序。( in good order )<ul>
<li>Everything is in good order.</li>
</ul>
</li>
<li>我的房子就在这里。<ul>
<li>My house is here.</li>
</ul>
</li>
<li>这辆轿车看起来很棒。<ul>
<li>This car looks very good.</li>
</ul>
</li>
<li>鳄鱼肉尝起来就像鸡肉。<ul>
<li>Alligator meat tastes like chicken.</li>
</ul>
</li>
<li>地震期间你应该保持冷静。<ul>
<li>You should keep calm during an earthquake.</li>
</ul>
</li>
<li>迈克去年成为一名职业篮球运动员。<ul>
<li>Mike became a professional basketball player last year.</li>
</ul>
</li>
<li>天气变得寒冷而多风( cold and windy )<ul>
<li>The weather has turned cold and windy.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="不及物动词-gt-主谓句型"><a href="#不及物动词-gt-主谓句型" class="headerlink" title="不及物动词-&gt;主谓句型"></a>不及物动词-&gt;主谓句型</h3><ul>
<li>不及物动词是什么<ul>
<li>intransitive verb，简称vi. 就是本身意就很完全，没有作用对象，不需要加宾语就能构成完整的句子，例如：游泳，出生，笑，做梦.</li>
<li>判断这类动词，有个方法很简单，把这个动词前面加上”被”字，看正常不正常。如果正常，就是及物动词，不正常，就是不及物动词。例如：被打，被处罚，被喜欢.</li>
<li>但如果说：被跳舞，被做梦，被游泳…..，肯定自己会觉得不通顺</li>
</ul>
</li>
<li>注意事项<ul>
<li>1.这个句型，一般来说都带有状语，来进一步说明这个动作发生的时间，地点，目的….<ul>
<li>Detectives(主语) were waiting(谓语) at the airport(地点状语) all morning(时间状语</li>
<li>They(主语) were talking(谓语) loudly(方式状语)</li>
</ul>
</li>
<li>2.很多动词，本身既可作不及物动词，也可作及物动词，得在具体语境中判断</li>
</ul>
</li>
<li>造句练习<ul>
<li>1.鸟儿快乐地唱着歌。<ul>
<li>1.The birds sing happily.</li>
</ul>
</li>
<li>2.这场雨下午会停。<ul>
<li>2.The rain will stop in the afternoon.</li>
</ul>
</li>
<li>3.孩子们正在公园里玩耍。<ul>
<li>3.The children are playing in the park.</li>
</ul>
</li>
<li>4.我的老师昨天在医院去世了。(pass away)<ul>
<li>4.My teacher passed away in the hospital yesterday.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="及物动词-gt-主谓宾"><a href="#及物动词-gt-主谓宾" class="headerlink" title="及物动词-&gt;主谓宾"></a>及物动词-&gt;主谓宾</h3><ul>
<li>举例<ul>
<li>Yesterday(时间状语), a pigeon(主语) carried(谓语) the first(定语) message(宾语) from Pinhurst to Silbury(地点状语). 昨天，一只鸽子把第一封信从平赫特带到锡尔伯里。</li>
<li>The bird(主语) covered(谓语) the distance(宾语) in three minutes.(时间状语) 这只鸟只用了3分钟就飞完了全程。</li>
<li>The bride and the groom cut the wedding cake together.新郎和新娘一起切下结婚蛋糕。</li>
<li>I had an amusing experience last year.去年我有过一次有趣的经历。</li>
<li>This wonderful plane can carry seven passengers.这架奇妙的飞机可以载7名乘客。</li>
</ul>
</li>
<li>及物动词是什么？<ul>
<li>transitive verb，简称vt. 就是加了宾语以后意思很完全的动词，有主动和被动两种语态</li>
<li>有些短语相当于及物动词，称为及物动词短语</li>
</ul>
</li>
<li>造句练习<ul>
<li>1.老师在教室的墙上贴了一些照片。<ul>
<li>1.The teacher put up some pictures on the wall in the classroom.</li>
</ul>
</li>
<li>2.在公共场合你应该尊敬老人。<ul>
<li>2.You should respect the old in public places.</li>
</ul>
</li>
<li>3.他一周前开始节食。<ul>
<li>3.He began his diet a week ago.</li>
</ul>
</li>
<li>4.他于1935年9月创造了一项新的世界纪录。<ul>
<li>4.He set up a new world record in September 1935.</li>
</ul>
</li>
<li>5.只有极少数人能实现他们的梦想。<ul>
<li>5.Only very few people can realize their dreams.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="不完全及物动词-gt-主语-谓语-宾语-宾语补语"><a href="#不完全及物动词-gt-主语-谓语-宾语-宾语补语" class="headerlink" title="不完全及物动词-&gt;主语+谓语+宾语+宾语补语"></a>不完全及物动词-&gt;主语+谓语+宾语+宾语补语</h3><ul>
<li>概述<ul>
<li>她使我爱上生活。</li>
<li>这个”使”就是不完全及物动词，如果只说“她使我”意思当然不完整, 得加上补语”爱上生活”，才是完整的句子</li>
<li>他的表演让我失望。</li>
<li>这个“让”如果说”他的表演让我”，当然也不完全得加上补语”失望”</li>
</ul>
</li>
<li>不完全及物动词是什么？<ul>
<li>incomplete transitive verb, 简称i.vt 这种动词加了宾语以后，意思仍</li>
<li>然不完全, 需要加上补语( complement )才能使句子完整</li>
<li>补语是补充说明宾语的特征，或者宾语的动作。</li>
</ul>
</li>
<li>如何区分完全及物动词和不完全及物动词<ul>
<li>最常见的不完全及物动词：使役动词：使…..做…. (make, have, let, get)</li>
<li>make / have /let +宾语+动词原形(补语)</li>
<li>get +宾语+动词不定式(补语)<ul>
<li>I made him wash the car. 我叫他洗车。</li>
<li>I got him to wash the car.我叫他洗车。</li>
</ul>
</li>
</ul>
</li>
<li>综上所述，只要是宾语发出的动作，或宾语的状态，均可构成此类句型。知道了这一道理，遇到类似句子，都能做出准确判断。</li>
<li>造句练习<ul>
<li>炎热的天气使我感到昏昏欲睡(feel lethargic)。<ul>
<li>The hot weather made me feel lethargic.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="授予动词-gt-主语-谓语-间接宾语-直接宾语"><a href="#授予动词-gt-主语-谓语-间接宾语-直接宾语" class="headerlink" title="授予动词-&gt;主语+谓语+间接宾语+直接宾语"></a>授予动词-&gt;主语+谓语+间接宾语+直接宾语</h3><ul>
<li>概述<ul>
<li>我给了他一本书”</li>
<li>动作“给”需要两个步骤,先拿起书,再给他</li>
<li>有两个宾语“他”和“书”，因为先拿书,再给他，所以“书”是直接宾语，“他”是间接宾语</li>
</ul>
</li>
<li>授予动词是什么？<ul>
<li>及物动词中的一种，但需要接两个宾语，第一个是间接宾语(indirect object， i.o.)，表示授予的对象，第二个宾语是直接宾语(direct object, d.o.)，表示授予的东西</li>
<li>要注意的是，直接宾语和间接宾语，都是谓语动作的作用对象，这是与第四大句型的区别。在第四大句型中，补语是说明宾语的性质，或者是宾语发出的动作</li>
</ul>
</li>
<li>最常用的授予动词：give, send, tell, teach, pay, show, offer<ul>
<li>Richard Mattes gave the testers six different kinds of things. Richard Mattes给了这些测试者6种不同类型的东西。</li>
<li>I send him a book in reward for his help.我送给他一本书来答谢他的帮助。</li>
<li>The scientist told us many stories about birds.博物学家给我们讲述了许多有关鸟儿的故事。</li>
<li>A friendly waiter taught me a few words of Italian. Then he lent me a book.一位好客的服务员教了我几句意大利语，之后还借给我一本书。</li>
<li>Yesterday I paid him a visit.昨天我去看望 了他。</li>
<li>Then he showed me the contents of the parcel.接着他给我看了包里的东西。</li>
<li>He offered me a lot of money.他给了我很多钱。</li>
</ul>
</li>
<li>第4大句型和第5大句型的区分<ul>
<li>只要是谓语的动作，作用于两个不同的名词，也就是两个宾语,就是第5大句型。而在第4大类句型中，补语是宾语的动作或状态。</li>
<li>举例:</li>
<li>1.他让我学习。”学习”是“我”发出的动作</li>
<li>2.他给了我一本书。 “书”和“我”都是谓语“给”的作用对象</li>
<li>所以，第1句是第4大句型，第2句是第5大句型。</li>
</ul>
</li>
<li>造句练习<ul>
<li>1.情人节他送给女友一束花。<ul>
<li>1.He gave a bunch of flowers to his girlfriend on Valentine’s Day.</li>
</ul>
</li>
<li>2.请寄给我一张收到此款的收据。<ul>
<li>2.Please send me a receipt for the money.</li>
</ul>
</li>
<li>3.他告诉我几个关于英语老师的神奇故事。<ul>
<li>3.He told me some magical stories about our English teacher.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="首相的英语学习方法"><a href="#首相的英语学习方法" class="headerlink" title="首相的英语学习方法"></a>首相的英语学习方法</h2><ul>
<li>1.了解句子成分的具体含义识别出句子的不同成分</li>
<li>2.学习时态、语态等基础知识</li>
<li>3.学习从句的构句方法把一个长句子变成一个句子成分把不同句子成分组合</li>
<li>4.用彩色笔标注不同句子成分，从句子相关成分中，积累相关用法</li>
<li>5.把复杂句拆成若干个简单句子，设定好主语宾语，采用学习的规则，拼成长句子</li>
<li>或，读完句子英汉互译，先翻译成中文再翻译成英文再对照原句</li>
</ul>
<h2 id="7大英语句子成分概述"><a href="#7大英语句子成分概述" class="headerlink" title="7大英语句子成分概述"></a>7大英语句子成分概述</h2><ul>
<li>主语：句子的主人</li>
<li>谓语：表达主语动作状态</li>
<li>宾语：客体、受体</li>
<li>表语：表达主语具体情况</li>
<li>补语：补充说明</li>
<li>定语：一个句子里用来界定、限定名词的部分<ul>
<li>能作定语的语法成分：形容词以及相当于形容词性质的语法成分</li>
<li>英语95%的定语遵循“前小后大”法则<ul>
<li>1个单词组成的定语(限定词，形容词，名词及名词所有格)， 放在所修饰名词的前面。</li>
<li>2个以上单词组成的定语( of属格，形容词短语，介词短语，分词短语，不定式短语等)， 放在所修饰词后面。 <ul>
<li>1.They were expecting a(限定词) valuable(形容词) parcel of diamonds(of属格) from South Africa.(介词短语)他们正期待从南非来的一个装着钻石的贵重包裹。(上面四个定语,均修饰parcel)</li>
<li>2.Mrs. Rumbold was a(限定词) large(形容词), unsmiling(形容词) lady in a tight black dress.(介词短语) 兰伯尔德夫人是一位身材高大、表情严肃的女人，穿一件紧身的黑衣服。</li>
<li>3.First of all, he wrote out a(限定词) long(形容词) list of all the foods.(of属格)首先，他开列了一张长长列了所有食物的目录。</li>
</ul>
</li>
</ul>
</li>
<li>造句练习<ul>
<li>1.我喜欢课桌上那本英语书。<ul>
<li>I like the English book on the table.</li>
</ul>
</li>
<li>2.他们正在研究一个关于贸易标准(trading standard)的复杂问题。<ul>
<li>They are studying a complicated problem about trading Standard.</li>
</ul>
</li>
<li>3.我将告诉你们昨天老师给我讲的那个非常有趣的关于月亮的中国古代故事<ul>
<li>I will tell you a very interesting old Chinese story about the moon that my teacher told me yesterday</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>状语：用来描述一个动作的细节特征的成分，除了修饰动词外，状语也可以修饰除了名词之外的任何词(如形容词，介词，连词，还可以修饰副词本身!)<ul>
<li>能作状语的语法成分：副词以及相当于副词的语法成分</li>
<li>小状语(单独的副词)，放在其所修饰的词语之前：修饰动词时，放在动词之前。修饰其它成分(形容词、介词、连词、副词)时，放在其它成分之前。注：如有需要，小状语可以放在句中任何位置!<ul>
<li>We are now living in a beautiful new house in the country.我们现在住在乡间的一栋漂亮的新住宅里。</li>
<li>Letters will cost a little more, but they will certainly travel faster.这样会稍微多花点钱，但肯定是快得多了。</li>
</ul>
</li>
<li>大状语(2个及以上单词构成的状语，如介词短语、不定式短语、状语从句)，放在整句的两头。放在开头时，一般要加上逗号。<ul>
<li>On Wednesday evening, we went to the Town Hall. 星期三的晚上，我们去了市政厅。</li>
<li>I was having dinner at a restaurant when Tony Steele came in.我正在一家饭馆吃饭，托尼斯蒂尔走进来。</li>
</ul>
</li>
<li>1.句子同时出现几个时间或者地点状语时，从小到大<ul>
<li>We landed in America at 8 o’ clock on June 15th，2012.我们2012年6月15日上午8点在美国着陆。</li>
<li>We live at number 35, South Renmin Road, Chengdu.我们住在成都市人民南路35号。</li>
</ul>
</li>
<li>2.句子后面有多种状语时，顺序是方式-地点-时间<ul>
<li>He put his milk bottles carefully on the doorstep every morning. 他每天早上小心地把牛奶瓶放在门口台阶上。</li>
</ul>
</li>
</ul>
</li>
<li>同位语：句子中指代同一事物的两个词、短语或从句，称为同位关系<ul>
<li>英语里边的同位语， 不属于单独的7大句子成分，而是和英语里边的名词成分(主语，宾语，表语)是并列关系，相当于对该名词的进一步解释说明。名词或任何相当于名词的成分，均可作同位语。</li>
<li>造句练习<ul>
<li>1.我的英语老师Brent Peter先生是加拿大人。<ul>
<li>My English teacher, Mr. Brent Peter, is a Canadian.</li>
</ul>
</li>
<li>2.昨天我遇到了我弟弟的朋友汤姆。<ul>
<li>Yesterday I met Tom, a friend of my brother’ s.</li>
</ul>
</li>
<li>3.我们中国人民是勤劳勇敢的。<ul>
<li>We Chinese people are brave and hardworking.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="2-如何避免犯时态错误"><a href="#2-如何避免犯时态错误" class="headerlink" title="2.如何避免犯时态错误"></a>2.如何避免犯时态错误</h1><h2 id="时态的本质"><a href="#时态的本质" class="headerlink" title="时态的本质"></a>时态的本质</h2><ul>
<li>时态=”时间”和”状态”=tense and aspect</li>
<li><img src="http://anki190912.xuexihaike.com/20201104130711.png?imageView2/2/h/200"></li>
</ul>
<h2 id="谓语动词的四种状态"><a href="#谓语动词的四种状态" class="headerlink" title="谓语动词的四种状态"></a>谓语动词的四种状态</h2><ul>
<li>1.一般（simple）:强调动作发生的时间，而非状态<ul>
<li>I play basketball. 我打篮球</li>
</ul>
</li>
<li>2.进行（continuous）：强调动作的过程（描绘，生动性）<ul>
<li>I am playing basketball. 我正在打篮球</li>
</ul>
</li>
<li>3.完成（perfect）:强调动作的结果（逻辑推导性）<ul>
<li>I have played basketball. 我打完篮球了</li>
</ul>
</li>
<li>4.完成进行（perfect continuous）：强调动作的结果和过程<ul>
<li>I have been playing basket ball. 我一直都有打篮球</li>
</ul>
</li>
</ul>
<h2 id="动词在不同时态下词形的变化"><a href="#动词在不同时态下词形的变化" class="headerlink" title="动词在不同时态下词形的变化"></a>动词在不同时态下词形的变化</h2><ul>
<li>进行：be+现在分词(be按照3时及主语人称变化)</li>
<li>完成：have+过去分词(have按照3时及主语人称变化)</li>
<li>完成进行：have been+现在分词(have按照3时及主语人称变化)</li>
<li>以动词do为例：<ul>
<li>现在 进行: am/is/are doing</li>
<li>过去 进行: was/were doing</li>
<li>将来 进行: will be doing</li>
<li>现在 完成: have/has done</li>
<li>过去 完成: had done</li>
<li>将来 完成: will have done</li>
<li>现在 完成进行: have/has been doing</li>
<li>过去 完成进行: had been doing</li>
<li>将来 完成进行: will have been doing</li>
</ul>
</li>
</ul>
<h2 id="一般态：强调动作本身"><a href="#一般态：强调动作本身" class="headerlink" title="一般态：强调动作本身"></a>一般态：强调动作本身</h2><ul>
<li>定义<ul>
<li>只强调动作发生的时间，不强调动作的状态，就是说它只关心这个动作是发生在过去，现在，还是将来，不关心这件事情有没有做好</li>
</ul>
</li>
<li>一般态和进行态的主要区别<ul>
<li>I walk to school.我走路去学校， 这个句子只强调一般情况，不强调动作的状态是怎么样。</li>
<li>I’m walking to school.这个强调的就是动作本身，我正在路上</li>
</ul>
</li>
<li>一般现在时<ul>
<li>1.表示事物现在的情况或状态（主系表句型）<ul>
<li>I <code>am</code> a doctor. 我是一个医生。</li>
<li>You <code>are</code> an unrepeatable miracle. 你是一个无法重复的奇迹。</li>
</ul>
</li>
<li>2.表示经常性、习惯性动作（常有时间副词修饰）<ul>
<li>I <strong>never</strong> <code>get up</code> early on Sundays. I sometimes <strong>stay</strong> in bed until lunch time. 星期天我是从来不早起的，有时我要直躺到吃 午饭的时候。</li>
<li>Winners <strong>often</strong> <code>seek</code> opportunity when losers <strong>want</strong> security. 失败者寻求安全的时候，成功者寻求机遇。</li>
<li>Do you <strong>always</strong> <code>get up</code> so late? It’s one o’clock! 你总是起得这么晚吗?现在已经1点钟了!</li>
<li>注：一般现在时常使用表示频率的副词，如never, often, always</li>
</ul>
</li>
<li>3.表示客观真理、格言<ul>
<li>Time <code>flies</code>. 时光飞逝。</li>
<li>The early bird <code>catches</code> the worm. 早起的鸟儿有虫吃。</li>
<li>Failure <code>is</code> the mother of success. 失败是成功之母。</li>
</ul>
</li>
</ul>
</li>
<li>一般过去式：表示过去的动作、习惯、事实<ul>
<li>Last Sunday I <code>got up</code> very late. I <code>looked</code> out of the window. It <code>was</code> dark outside. 在上个星期天，我起得很晚。我望望窗外，外面一片昏暗。</li>
<li>Last summer, I <code>went</code> to Italy. 去年夏天，我去了意大利。</li>
<li>Colubus discovered America in 1742. 哥伦布于1492年发现了美洲。</li>
<li>注：一般过去时常使用过去具体时间的副词，如yesterday, last week, two years ago, in 1998……</li>
</ul>
</li>
<li>一般将来时<ul>
<li>1.表示将来发生的动作或状态，或倾向(will译为“将要”)<ul>
<li>He <code>will</code> soon <code>visit</code> Darwin. From there, he <code>will fly</code> to Perth. 他不久还将到达达尔文去，从那里，他再飞往珀斯。</li>
<li>People <code>will</code> run into problems in their lives. 人们在生活中总会遇到问题。</li>
<li>A small leak <code>will</code> sink a great ship. 小裂缝可以沉大船。(千里之堤，溃于蚁穴)</li>
</ul>
</li>
<li>be going to+动词原形：表示将来时，但多表示“计划”，主语多为“人”。will表示“意愿”时，主语是“人”。但也可以表示“预测”，主语是“物”<ul>
<li>Debbie Hart is going to swim across the English Channel tomorrow. 黛比.哈特准备明天横渡英吉利海峡。</li>
<li>She is going to set out from the French coast at five o’clock in the morning. 她打算早上5点钟从法国海岸出发。</li>
<li>Mr. Thompson is going to sell it because it is haunted. 汤普森先生之所以想卖它，是因为那里常闹鬼。</li>
</ul>
</li>
<li>be about to + 动词原形：即将。。<ul>
<li>He is about to leave for Shenyang. 他将要离开去沈阳。</li>
</ul>
</li>
</ul>
</li>
<li>造句练习<ul>
<li>1.这家便利店全天24小时营业。<ul>
<li>1.This convenience store is open 24 hours a day.</li>
</ul>
</li>
<li>2.我爷爷每天早上都在公园里散步。<ul>
<li>2.My grandfather takes a walk in the park every morning.</li>
</ul>
</li>
<li>3.昨天我很无聊，便跟着几个朋友看电影去了。<ul>
<li>3.I felt bored yesterday, So I went to the movies with several friends.</li>
</ul>
</li>
<li>4.他明天将要去纽约。<ul>
<li>4.He will go to New York tomorrow.</li>
</ul>
</li>
<li>5.看！那艘船快要沉没了。(be about to)<ul>
<li>5.Look! The boat is about to sink.</li>
</ul>
</li>
<li>6.我们马上就要吃午餐了。<ul>
<li>6.We are going to have lunch soon.</li>
</ul>
</li>
<li>7.太阳东升西落。<ul>
<li>7.The sun rises in the east and sets in the west.</li>
</ul>
</li>
<li>8.我每周去两次健身房。<ul>
<li>8.I go to the gym twice a week.</li>
</ul>
</li>
<li>9.我昨天早上在图书馆看到他。<ul>
<li>9.I saw him in the library yesterday morning.</li>
</ul>
</li>
<li>10.我准备学习计算机科学。<ul>
<li>10.I am going to learn the computer science.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="进行态：强调动作的过程"><a href="#进行态：强调动作的过程" class="headerlink" title="进行态：强调动作的过程"></a>进行态：强调动作的过程</h2><ul>
<li>延续性动词和瞬间动词<ul>
<li>在英语中，按照动作发生的时间长短，动词分成了延续性动词和瞬间动词</li>
<li>如结婚是一个瞬间动词，交换仪式之后，就是结婚了。所以不能说They were marrying last week. 只能说They married last week. 若要表达正在举行婚礼，可以说They are having a wedding ceremony</li>
</ul>
</li>
<li>现在进行时<ul>
<li>1.表示现在正在做的动作，此时be动词译为“正在”<ul>
<li>He <code>is playing</code> basketball. 他正在打篮球。</li>
<li><code>It&#39;s raining</code> heavily now. 现在正在下大雨。</li>
<li>注意：主系表句型在口语中通常用一般现在时，但如果要强调此时的状态，可以用现在进行时</li>
<li>You are very rude! ——&gt; You are <code>being</code> very rude! 你太粗鲁了！（你现在的行为粗鲁，而不是你这个人粗鲁）</li>
</ul>
</li>
<li>2.表示即将发生的动作（通常是表示“位移”短暂动词come, go, arrive, leave, start, begin, return, die, take），此时be动词译为“即将”<ul>
<li>“A new play <code>is coming</code> to’The Globe’ soon,” I said.“Will you be seeing it?” “一出新剧要来’环球剧场’上演了，”我说，“您去看吗?”</li>
<li>‘We <code>are going back</code> now,’ said the conductor. “我们现在要返回去，”售票员说。</li>
</ul>
</li>
</ul>
</li>
<li>过去进行时<ul>
<li>表示过去某时正在做的事情<ul>
<li>A man <code>was lying</code> in the box during the flight. 那个航班上，有一个人正躺在箱子里。</li>
<li>I <code>was having</code> dinner at a restaurant when Tony Steele came in. 我正在一家饭馆吃饭，托尼.斯蒂尔走了进来。</li>
</ul>
</li>
</ul>
</li>
<li>将来进行时<ul>
<li>表示将来某时将进行的动作<ul>
<li>They <code>will be arriving</code> here tomorrow. 他们明天就要到达此地。</li>
<li>Tomorrow evening they <code>will be singing</code> at the Workers’ Club. 明晚他们将在工人俱乐部演出。</li>
<li>The Greenwood Boys <code>will be staying</code> for five days. “绿林少年”准备在此逗留5天。</li>
<li>They <code>will be trying</code> to keep order. 他们将设法维持秩序。</li>
<li>The shuttle Endeavour <code>will be taking</code> the astronauts to the Hubble. “奋进”号航天飞机将把宇航员送上哈勃。</li>
</ul>
</li>
</ul>
</li>
<li>注意事项<ul>
<li>进行态，其实就是一般态的生动模式。任何一个进行态的句子，都可以改成一般态。一般态却不一定能改成进行态，比如动词是延续动词才能改。<ul>
<li>I <code>looked</code> out of the window. 可以改成 I <code>was looking</code> out of the window. (look是延续的)</li>
<li>I never get up early on Sundays. 不能改成 I was never getting up early on Sundays. 因为get up是短暂的。</li>
</ul>
</li>
</ul>
</li>
<li>造句练习<ul>
<li>1.你在桌子下面做什么? <ul>
<li>1.What are you doing under the table?</li>
</ul>
</li>
<li>2.我正梦见你时，电话铃响了。(dream about)<ul>
<li>2.I was dreaming about you when the telephone rang.</li>
</ul>
</li>
<li>3.明天早上这个时候，我爸爸将正在修剪草坪。(mow the lawn)<ul>
<li>3.My dad will be mowing the lawn at this time tomorrow morning.</li>
</ul>
</li>
<li>4.我女儿正在学习，所以你最好别去烦她。<ul>
<li>4.My daughter is studying, so you’d better not bother her.</li>
</ul>
</li>
<li>5.明年这个时候我将正在美国念书。<ul>
<li>5.l’ll be studying in the United States at this time next year.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="完成态：强调动作的结果"><a href="#完成态：强调动作的结果" class="headerlink" title="完成态：强调动作的结果"></a>完成态：强调动作的结果</h2><ul>
<li>现在完成时<ul>
<li>1.表示到现在为止已经完成的动作（发生时间不明）<ul>
<li>I <code>have</code> just <code>received</code> a letter from my brother, Tim. 我刚刚收到弟弟蒂姆的来信。</li>
<li>He <code>has</code> just <code>bought</code> an Australian car and <code>has gone</code> to Alice Springs, a small town in the centre of Australia. 他刚买了一辆澳大利亚小汽车，现在去了澳大利亚中部的小镇艾利斯斯普林斯。</li>
<li>Since then, he <code>has developed</code> another bad habit. 从那以后，它养成了另外一种坏习惯。</li>
<li>He <code>has gone</code> to Shanghai. 他去了上海(言外之意:他不在说话现场)</li>
</ul>
</li>
<li>2.如果是延续性动词，表示持续到现在的动作（或状态）。（注意：be动词是可延续的）<ul>
<li>She <code>has lived</code> here for 10 years. 她住在这里10年了。</li>
<li>He <code>has been</code> there for six months. 他在那儿已经住了6个月了。</li>
<li>I <code>have been</code> to the Great Wall. 我去过长城。</li>
</ul>
</li>
</ul>
</li>
<li>现在完成时常用时间副词<ul>
<li>1.自从：since+时间点<ul>
<li>Since then, Captain Fawcett <code>has flown</code> passengers to many unusual places. 从那时开始，弗西特机长已经载送乘客到过许多不寻常的地方。</li>
</ul>
</li>
<li>2.有若干时间之久：for+时间段<ul>
<li>Mr. Hart <code>has trained</code> his daughter for years. 哈特先生训练她的女儿已经多年了。</li>
</ul>
</li>
<li>3.到目前为止：so far/up to now<ul>
<li>But so far, the public <code>has expressed</code> its gratitude to the students in letters to the Press. 但到目前为止，公众已经向新闻界写信表达他们对学生们的感激之情了。</li>
<li>Up to now, Mr. Scott <code>has sent</code> a great many requests for spare parts and other urgent messages from one garage to the other. 到目前为止，斯科特先生从一个汽车修理部向另一个发送了大量索取备件的信件和其他紧急函件。</li>
</ul>
</li>
<li>4.最近：recently/lately<ul>
<li><code>Have</code> you <code>talked</code> to Jane lately? 你最近有没有和Jane说过话?</li>
</ul>
</li>
<li>5.一次/两次/几次/多次：once/twice/a few times/many times<ul>
<li>Jack <code>has read</code> the novel three times. (这里的read是过去分词) 这本小说杰克已经看过三遍了。</li>
</ul>
</li>
<li>6.过去若干年/月/日以来：over/during/for + the last/past+数字+years/months/days<ul>
<li>Over the last three months, oil prices <code>have reached</code> a record high. 过去三个月以来，油价创了历史新高。</li>
</ul>
</li>
</ul>
</li>
<li>中国人最容易用错的3个短暂动词<ul>
<li>请翻译一下:<ul>
<li>1:他去北京3天了。</li>
<li>2:他结婚已经3年了。</li>
<li>3:他已经死了3年了</li>
</ul>
</li>
<li>答案：<ul>
<li>常见错误翻译</li>
<li>1: He has go to Beijing for 3 days. (X)</li>
<li>2: He has married for 3 years. (X)</li>
<li>3: He has died for 3 years. (X)</li>
<li>go, marry, die在英语中均为短暂动词，都是一瞬间完成的，后面不可以接时间副词，这里可以说:</li>
<li>1: He has gone to Beijing. </li>
<li>2: He has married. </li>
<li>3: He has died. </li>
<li>他不可能不停地做“去”这个动作3天，也不可能不停“结婚”这个动作3年，更不可能“死”3年才死透。要正确表达，必须使用对应的主系表句型，因为系动词是可以延续的，用主系表句型表示状态，才能加表示一段时间的状语。所以正确的说法是:</li>
<li>1: He has <code>been to Beijing</code> for 3 days.</li>
<li>2: He has <code>been married</code> for 3 years.</li>
<li>3: He has <code>been dead</code> for 3 years.</li>
<li>此时，句子的动词是be动词，后面的to Beijing (介词短语)，married, dead (形容词)为表语。</li>
</ul>
</li>
</ul>
</li>
<li>过去完成时<ul>
<li>表示截止过去某时为止所完成的动作或经验。（过去完成时不能单独存在，要与另一使用一般过去时的句子或者表示过去的副词短语连用）。(had译为“已经”或“曾经”)<ul>
<li>My old friend, Harrison, <code>had lived</code> in the Mediterranean for many years before he returned to England. 我的老朋友哈里森在回到英国以前曾多年居住在地中海地区。</li>
<li>A short time before, great trees <code>had covered</code> the countryside for miles around. 就在不久之前，参天大树还覆盖着方圆数英里的土地。</li>
<li>By then, however, in many places the grass <code>had</code> already <code>taken root</code>. 然而到那时，很多地方的草已经生了根。</li>
</ul>
</li>
</ul>
</li>
<li>将来完成时<ul>
<li>表示到将来某时为止所完成或仍然继续的动作或经验等。（常与介词by构成的时间状语连用，表示“到…的时候”）<ul>
<li>Workers <code>will have completed</code> the new roads by the end of this year. 工人们将在今年年底前把新路铺好。</li>
<li>By the end of next year, they <code>will have finished</code> work on the new stadium. 到明年年底，他们将把新体育场建成。</li>
</ul>
</li>
</ul>
</li>
<li>造句练习<ul>
<li>1.彼得去过香港很多次。<ul>
<li>1.Peter has been to Hong Kong many times.</li>
</ul>
</li>
<li>2.进入初中以来，我对英语很狂热。(be crazy about)<ul>
<li>2.I have been crazy about English since I entered junior high school.</li>
</ul>
</li>
<li>3.到目前为止，我已经完成这项计划的三分之二。<ul>
<li>3.So far, I have finished two third of the project.</li>
</ul>
</li>
<li>4.我最近很忙，恐怕要到下周一我才有空。<ul>
<li>4.I have been very busy recently. l’m afraid that I won’t be free until next Monday.</li>
</ul>
</li>
<li>5.过去5年来，这个好孩子都尽力照顾他生病的母亲。<ul>
<li>5.Over the past 5 years, the good boy has tried his best to take care of his ill mother.</li>
</ul>
</li>
<li>6.史密斯先生搬来这里之前已经在加拿大住了20年。<ul>
<li>6.Mr. Smith had lived in Canada for 20 years before he moved here.</li>
</ul>
</li>
<li>7.等我到达车站时，火车已经开走了。<ul>
<li>7.By the time I got to the station, the train had left.</li>
</ul>
</li>
<li>8.玛丽昨天告诉我她很久以来一直想出国旅游。<ul>
<li>8.Mary told me yesterday that she had long wanted to travel abroad.</li>
</ul>
</li>
<li>9.我很生气，因为我女朋友又对我爽约了。(stand sb. up)<ul>
<li>9.I was very angry because my girlfriend had stood me up again.</li>
</ul>
</li>
<li>10.明天这个时候，约翰将已经达到芝加哥了。<ul>
<li>10.John will have arrived in Chicago by this time tomorrow.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="完成进行态：同时强调动作的结果和过程（延续性动词）"><a href="#完成进行态：同时强调动作的结果和过程（延续性动词）" class="headerlink" title="完成进行态：同时强调动作的结果和过程（延续性动词）"></a>完成进行态：同时强调动作的结果和过程（延续性动词）</h2><ul>
<li>延续性动词<ul>
<li>“我收到一封信”<ul>
<li>你只能说I have received a letter.</li>
<li>但是绝对不能说“I have been receiving a letter.”</li>
<li>因为receive收到这个动词， 是一瞬间完成的，不能延续，你不可能一直不停收同一 封信。</li>
</ul>
</li>
<li>“我住在广州3年了“<ul>
<li>你可以说I have lived in Guangzhou for three years.</li>
<li>也可以说I have been living in Guangzhou for three years.两句话意思完全相同。但是第二句更加生动形象。</li>
<li>瞬间动词是不能放在完成进行形态的。</li>
</ul>
</li>
</ul>
</li>
<li>现在完成进行时<ul>
<li>表示一直继续到现在，且可能继续下去的动作。（通常和表示时间段的副词连用，如for, since, all morning…）<ul>
<li>We have just moved into a new house and I <code>have been working</code> hard all morning. 我们刚刚搬进一所新房子，我辛辛苦苦地干了整整一个上午。</li>
<li>If you haven’t discovered your dream, probably <code>you&#39;ve been missing</code> too much. 如果你还没有发现梦想，或许一直以来你失去的太多了。</li>
</ul>
</li>
</ul>
</li>
<li>过去完成进行时<ul>
<li>表示一直继续到过去某时，而当时仍然在继续的动作。（过去完成进行时的句中必须有表示过去的时间状语）<ul>
<li>Firemen had been fighting the forest fire for nearly three weeks before they could get it under control. 消防队员们同那场森林大火搏斗了将近3个星期才最后把火势控制住。</li>
<li>The planes had been planting seed for nearly a month when it began to rain. 飞机撒播近一一个月后，开始下起雨来。</li>
<li>Bleriot had been making planes since 1905 and this was his latest model. 布莱里奥从1905年起便开始研制飞机，这架飞机是他制作的最新型号。</li>
</ul>
</li>
</ul>
</li>
<li>将来完成进行时<ul>
<li>一直继续到将来某时，且可能继续下去的动作<ul>
<li>The day before his retirement, Mr. Page will have been teaching for a total of forty years. 佩奇先生退休的前一天正好是他执教满40年的日子。</li>
<li>By the time you come back tonight, I will have been sleeping for five hours. 等你今晚回来时，我已经持续睡了5个小时了。</li>
</ul>
</li>
</ul>
</li>
<li>总结<ul>
<li>任何完成进行态，都能改成完成态。但是完成态不一定能改成完成进行态，必须是延续动词，才能改</li>
</ul>
</li>
<li>造句练习<ul>
<li>1.约翰自去年起就一直学日语。他希望去日本留学。<ul>
<li>1.John has been learning Japanese since last year. He expects to study in Japan in the future.</li>
</ul>
</li>
<li>2.Lulu的车子抛锚时，她已经持续开了8个小时了。<ul>
<li>2.By the time her car broke down, Lulu had been driving for 8 hours.</li>
</ul>
</li>
<li>3.到今年年底，王老师教英语将有10年了。<ul>
<li>3.Mr. Wang will have been teaching English for 10 years by the end of this year.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="过去将来时"><a href="#过去将来时" class="headerlink" title="过去将来时"></a>过去将来时</h2><ul>
<li>通常多用于叙述性故事中，或间接引语中<ul>
<li>A few hours earlier, someone had told the police that thieves <code>would try</code> to steal the diamonds. 数小时之前，有人向警方报告，说有人企图偷走这些钻石。(一般态)</li>
<li>Then he smiled and told me I <code>would receive</code> an extra thousand pounds a year! 然后他微笑了一下告诉我说，我每年将得到1000英镑的额外收入。(一般态)</li>
<li>He said that it <code>would be</code> possible to build a platform in the centre of the Channel. 他说，可以在隧道中央建造一座平台。(一般态)</li>
<li>She said she <code>would be setting off</code> on the 10 o’clock train. 她说她将乘10点钟的火车走。(进行态)</li>
<li>I guessed that Helen <code>would have told</code> her something. 我猜海伦会告诉她一些情况的。(完成态)</li>
<li>He told me that by the end of the year he <code>would have been living</code> there for thirty years. 他告诉我到今年末他已经住在那儿30年了。(完成进行态)</li>
</ul>
</li>
<li>造句练习<ul>
<li>1.在信中她说她明年将到英国来。<ul>
<li>1.In her letter, she said that she would come to England next year.</li>
</ul>
</li>
<li>2.他问我明天上午10点我将干什么。<ul>
<li>2.He asked me what I should be doing at 10 a.m. the next day</li>
</ul>
</li>
<li>3.他告诉我们他会在8点以前干完工作。<ul>
<li>3.He told us he would have finished the work by 8 o’clock.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="3-英文造句的被动语态"><a href="#3-英文造句的被动语态" class="headerlink" title="3.英文造句的被动语态"></a>3.英文造句的被动语态</h1><h2 id="及物动词和不及物动词"><a href="#及物动词和不及物动词" class="headerlink" title="及物动词和不及物动词"></a>及物动词和不及物动词</h2><ul>
<li>只有及物动词才有被动语态，不及物动词没有被动语态</li>
<li>及物动词后面可以加宾语<ul>
<li>主动语态: I eat meat.我吃肉</li>
<li>被动语态: the meat is eaten by me.</li>
</ul>
</li>
<li>不及物动词后面不可以加宾语，没有被动语态<ul>
<li>主动语态: I appear.我出现了</li>
</ul>
</li>
</ul>
<h2 id="主动语态变成被动语态的方式"><a href="#主动语态变成被动语态的方式" class="headerlink" title="主动语态变成被动语态的方式"></a>主动语态变成被动语态的方式</h2><ul>
<li>1.be动词（根据16中时态变化，与原句时态一致）+过去分词，原句的宾语作主句，而原句的主语，在被动语态中省略，或者前面加上介词by作状语</li>
<li>2.所谓被动语态，其实是一种特殊的主系表句型：过去分词作表语</li>
<li>举例<ul>
<li>I was beaten, 我被打了。(主语+be动词+动词的过去分词)</li>
<li>主动语态: Somebody beat me. 主谓宾结构</li>
<li>被动语态: I was beaten by somebody. 这里的by somebody可以省略。</li>
</ul>
</li>
</ul>
<h2 id="被动语态的时态变化"><a href="#被动语态的时态变化" class="headerlink" title="被动语态的时态变化"></a>被动语态的时态变化</h2><ul>
<li>一般态<ul>
<li>一般现在时<ul>
<li>Our clavichord is kept in the living-room.我们的这架古钢琴存放在起居室里。(这句话里边，可以认为clavichord是主语，is是系动词，kept是表语)</li>
</ul>
</li>
<li>一般过去时<ul>
<li>The instrument was bought by my grandfather many years ago.这件乐器是我祖父在很多年以前买的。(这句话里边，可以认为instrument是主语，was是系动词，bought是表语)</li>
</ul>
</li>
<li>一般将来时<ul>
<li>The Olympic Games will be held in our country in four years’ time. 4年以后，奥林匹克运动会将在我们国家举行。(这句话里边，可以认为Games是主语)</li>
</ul>
</li>
<li>被动语态句中出现情态动词时，用法同will<ul>
<li>The work must be finished in one way or another. 这件事必须设法做好。in one way or another是无论如何的意思</li>
<li>This passage may be given several interpretations.这段文字可以有不同的解释。</li>
</ul>
</li>
</ul>
</li>
<li>进行态: be动词+being+过去分词，be动词时态和原句保持一致<ul>
<li>现在进行时<ul>
<li>It is being repaired by a friend of my father’s.父亲的一个朋友正在修理它。(这句话里边，可以认为It是主语，is being是系动词，repaired是表语)</li>
<li>主动语态: A friend of my father’s is repairing it.</li>
<li>I am a doctor (常规状态).</li>
<li>I am being a doctor. (过去和未来不确定，仅表示现在)</li>
</ul>
</li>
<li>过去进行时<ul>
<li>I was being tested for a driving licence for the third time.(过去进行时)我第3次接受驾驶执照考试。(这句话里边，可以认为I是主语，was being是系动词，tested是表语)</li>
<li>主动语态: Somebody was testing me for a driving licence for the third time.</li>
</ul>
</li>
<li>将来进行时<ul>
<li>He will be being examined when we get there.当我们到那儿时他将正被检查。(这句话里边，可以认为He是主语，will be being是系动词，examined是表语)</li>
<li>主动语态: Somebody will be examming him when we get there</li>
</ul>
</li>
<li>完成态: have/has/had been +动词过去分词<ul>
<li>现在完成时<ul>
<li>The fantastic modern buildings have been designed by Kurt Gunter.这些巨大的现代化建筑是由库尔特.冈特设计的。(这句话里边，可以认为buildings是主语，have been是系动词，designed是表语)</li>
<li>主动语态: Kurt Gunter has designed the fantastic modern buildings</li>
</ul>
</li>
<li>过去完成时<ul>
<li>I had been asked to drive in heavy traffic and had done so successfully.按照要求在车辆拥挤的路上驾驶，我圆满地完成了。(这句话里边，可以认为I是主语，had been是系动词，asked是 表语)</li>
<li>主动语态: Somebody had asked me to drive in heavy traffic</li>
<li>Bluebird, the car he was driving, had been specially built for him.他驾驶的“蓝鸟”牌汽车是专门为他制造的。</li>
<li>主动语态: Somebody had specially built Bluebird, the car he was driving for him</li>
</ul>
</li>
<li>将来完成时<ul>
<li>Your character will have been completed by the time your life comes to an end.当生命走到尽头的时候，你的人格才变得完全。(这句话里边，可以认为character是主语， will have been是系动词，completed是表语)</li>
</ul>
</li>
</ul>
</li>
<li>完成进行态很少用于被动语句</li>
<li>造句练习<ul>
<li>1.欧元在大部分欧洲国家都被使用。<ul>
<li>1.The euro is used in most European countries.</li>
</ul>
</li>
<li>2.这些电脑是在台湾制造的。<ul>
<li>2.These computers were manufactured in Taiwan.</li>
</ul>
</li>
<li>3.2012年的奥运会将在伦敦举行。<ul>
<li>3.The 2012 Olympic Games will be held in London.</li>
</ul>
</li>
<li>4.一名应聘者正被我们的人事经理面试着<ul>
<li>4.An applicant is being interviewed by our personnel manager.</li>
</ul>
</li>
<li>5.那栋旧大楼已被拆除。(tear down)<ul>
<li>5.The old building has been torn down.</li>
</ul>
</li>
<li>6.我们办公室的房间都是每天打扫的。<ul>
<li>6.Our office rooms are cleaned up every day.</li>
</ul>
</li>
<li>7.汤姆昨天被一只狗咬到，所幸无大碍。<ul>
<li>7.Tom was bitten by a dog yesterday. Fortunately, it was nothing serious.</li>
</ul>
</li>
<li>8.因为经济不景气(the economic recession),大约5000名员工将被裁员(lay off)。<ul>
<li>8.Because of the economic recession, about 5,000 employees will be laid off.</li>
</ul>
</li>
<li>9.六个人被困在矿井里已有17个小时了。<ul>
<li>9.Six men have been trapped in a mine for seventeen hours.</li>
</ul>
</li>
<li>10.这场地震结束的时候有多少建筑被毁坏了?<ul>
<li>10.How many buildings had been destroyed when the earthquake ended?</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="使用被动语态的情况"><a href="#使用被动语态的情况" class="headerlink" title="使用被动语态的情况"></a>使用被动语态的情况</h2><ul>
<li>1.为了突出受动者（主动语态中的宾语）<ul>
<li>A hero is distinguished in difficult circumstances.困境之中显英雄。</li>
<li>A liar is not believed when he tells the truth.撒谎的人讲真理也没人相信。</li>
</ul>
</li>
<li>2.施动者（主动语态的主语）不明确或不必指明时<ul>
<li>Then in 1989, twenty-six years after the crash, the plane was accidentally rediscovered in an aerial survey of the island. (没有提到到底是谁发现的) 于是，到了1989年，飞机失事26年后， 在对小岛的一次航空勘查中那架飞机被意外地发现了。</li>
<li>Once a year, a race is held for old cars.旧式汽车的比赛每年举行一次。(没有提到举办者是谁)</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>英语</category>
      </categories>
      <tags>
        <tag>英语</tag>
        <tag>语法</tag>
      </tags>
  </entry>
  <entry>
    <title>恶魔奶爸语法7-9课</title>
    <url>/gramma7-9/</url>
    <content><![CDATA[<h1 id="7-把一个句子连接到另一个句子上，变身“大副词”"><a href="#7-把一个句子连接到另一个句子上，变身“大副词”" class="headerlink" title="7.把一个句子连接到另一个句子上，变身“大副词”"></a>7.把一个句子连接到另一个句子上，变身“大副词”</h1><h2 id="时间状语从句：一个句子在另外一个句子里面充当时间状语"><a href="#时间状语从句：一个句子在另外一个句子里面充当时间状语" class="headerlink" title="时间状语从句：一个句子在另外一个句子里面充当时间状语"></a>时间状语从句：一个句子在另外一个句子里面充当时间状语</h2><ul>
<li>当…的时候：<ul>
<li>when…/as…：从句多用一般态，可接短暂动词，也可接延续动词<ul>
<li><code>When</code> he began to play a tune, we had our first glimpse of the snake. 当他开始吹奏一支曲子时，我们才第一次看到那条蛇。</li>
<li>I looked down and nearly fell off the ladder <code>when</code> I saw a policeman. 当我看清是一个警察时，差一点儿从梯子上掉下去。</li>
<li><code>As</code> the thieves were trying to get away in their car, Roy drove his bus into the back of it. 当那两个小偷企图乘车逃跑时，罗伊驾驶他的公共汽车撞在了那辆车的后尾上。</li>
<li><code>As</code> she walked away, I followed her out of the fair. 8当她走开时，我也跟着她出了集市</li>
</ul>
</li>
<li>while…：强调动作进行，从句多用进行态，只能接延续动词<ul>
<li><code>While</code> he was eating, I asked him to lend me twenty pounds. 当他吃饭时，我提出向他借20英镑。</li>
<li><code>While</code> the battered car was moving away, Roy stopped his bus and telephoned the police. 当那辆被撞坏的车开走后，罗伊停下车，给警察挂了电话。</li>
</ul>
</li>
<li>when有时候也有“就在此时”的意思，用以说明前一个分句的时间。这是，when引导的从句必须放在主句后面。<ul>
<li>I had nearly reached the town, <code>when</code> the young man suddenly said, very slowly, ‘Do you speak English?’ 就要到达那个镇时，那青年突然开了口，慢慢地说道: “你会讲英语吗?”</li>
<li>I was almost there <code>when</code> a sarcastic voice below said, ‘I don’t think the windows need cleaning at this time of the night.’ 快要爬到窗口时，下面一个人用讽刺的口吻说:“ 我看不必在夜里这个时候擦窗子吧。”</li>
</ul>
</li>
</ul>
</li>
<li>如果时间状语从句表示将来，一般将来时要改为一般现在时<ul>
<li>I will be a teacher when I grow up. 我长大的时候，要做一个老师。(虽然 “长大”发生在将来，但因为是时间状语从句，所以用一般现在时)</li>
<li>whenever无论何时，每当，是when的强调形式<ul>
<li>Whenever you have an aim, you must sacrifice something of freedom to attain it.每当有了目标，你必须牺牲一定的自由去达到目标</li>
<li>Forgive others whenever you can.得饶人处且饶人。</li>
</ul>
</li>
</ul>
</li>
<li>while既可以用作副词连词，也可以作并列连词<ul>
<li>1.表示“当…时”，while视为副词连词，引导状语从句，此时两个句子通常时态不同。<ul>
<li><code>While</code> two detectives were keeping guard at the door, two others opened the parcel.两个侦探在门口站岗期间，另外两个侦探打开了包裹。(时态不同)</li>
<li>A robot-arm will grab the telescope and hold it <code>while</code> the astronauts make the necessary repairs.当宇航员进行必要的修复工作时，“奋进”号上的一只机器手将抓住望远镜并托住它。(时态不同)</li>
</ul>
</li>
<li>2.表示“而…”，while视为并列连词，连接两个分句，此时两个句子时态相同<ul>
<li>When the plane arrived, some of the detectives were waiting inside the main building <code>while</code> others were waiting on the airfield.当飞机到达时，一些侦探等候在主楼内，另一些侦探则守候在停机坪上。</li>
</ul>
</li>
</ul>
</li>
<li>before/after，通常接短暂动词，但可也接延续动词<ul>
<li><code>After</code> I had left a small village in the south of France, I drove on to the next town. 在离开法国南部的一个小村庄后，我继续驶往下一个城镇。</li>
<li><code>After</code> he has retired, he will devote himself to gardening. 他退休后，将致力于园艺。</li>
<li><code>Before</code> he retired, Frank was the head of very large business company, but as a boy he used to work in a small shop. 在退休前，弗兰克是一家非常大的商业公司的经理，但他小时候却在一家小铺里做工。</li>
</ul>
</li>
<li>before用以说明主句的时间很长，翻译为“才”。用以说明主句的时间很短，翻译为“就”。这时，before引导的从句必须放在主句后面<ul>
<li>Nearly a week passed <code>before</code> the girl was able to explain what had happened to her. 几乎过了一个星期，那姑娘才能讲述自己的遭遇。</li>
</ul>
</li>
<li>直到：until/till，从句只能接短暂动词，主句肯定用延续动词，主句否定用短暂动词<ul>
<li>The young man did <code>not</code> wake up <code>until</code> the bed had struck the ground. 那年轻人直到床撞到地上才醒了过来。(not..util… 翻译为直到….才…)</li>
<li>He waited until the volcano became quiet and he was able to return two days later.他等到火山平静下来,两天以后又返回去。</li>
</ul>
</li>
<li>一…就…：as soon as/ the moment(只能接短暂动词)<ul>
<li><code>As soon as</code> he had got into the car, I said good morning to him in French and he replied in the same language.他一上车，我就用法语向他问早上好，他也同样用法语回答我。</li>
<li><code>As soon as</code> this was done, they cooked a meal over an open fire. 这件事刚刚做完，他们就在篝火上烧起了饭。</li>
<li><code>The moment</code> you leave this tent, you will get a big surprise. 您一走出这个帐篷，就会大吃一惊。</li>
</ul>
</li>
<li>刚…就…：no sooner…than…（主句动作已完成），hardly/scarcely…when/before…(主句动作差点完成)，主句用过去完成时，从句用一般过去时，且只能接短暂动词<ul>
<li>He had no sooner returned than he bought a house and went to live there. 他刚一回到英国便买下了一幢房子住了进去。</li>
<li>He had hardly had time to settle down when he sold the house and left the country. 还没等安顿下来就卖掉了房子，离开了这个国家。</li>
<li>I had scarcely fallen asleep before the noise from neighbor woke me up. 我刚一睡着，邻居发出的噪音就把我吵醒了。</li>
</ul>
</li>
<li>自从…：since/ever since(可以接短暂动词，也可接延续动词)，since后面不可以接完成时的，只能接一般态的短暂动词<ul>
<li>He has just bought a new house in the city, but ever since he moved in, he has had trouble with cars and their owner.他刚在城里买下一所新房子，但自从搬进去后，就和汽车及车主们发生了磨擦。</li>
<li>We haven’t seen each other since we graduated.自从毕业后我们彼此就没有见过面。</li>
</ul>
</li>
<li>造句练习<ul>
<li>1.当我走进这座大楼的时候，看见一位拿着公文包的女士(while)。<ul>
<li>1.I saw a lady with a briefcase while I was walking into the building.</li>
</ul>
</li>
<li>2.当你长大，你就会知道父母有多伟大。<ul>
<li>2.When you grow up, you will know how great your parents are.</li>
</ul>
</li>
<li>3.每当你发现你和多数人站在同一边时，就是改革的时候了。<ul>
<li>3.Whenever you find that you are on the side of the majority, it is the time to reform.</li>
</ul>
</li>
<li>4.玛丽打开礼物后，便开始写感谢函(thank-you notes)了。<ul>
<li>4.After she opened her gifts, Mary started writing thank-you notes.</li>
</ul>
</li>
<li>5.雨一停，天空中就出现了一道彩虹。<ul>
<li>5.As soon as the rain stooped, a rainbow appeared in the sky.</li>
</ul>
</li>
<li>6.比赛才刚刚开始，两个队就打了起来。(no sooner.. .than)<ul>
<li>6.The game had no sooner started than the two teams began to fight.</li>
</ul>
</li>
<li><ol start="7">
<li>Lulu刚用她的新电脑，电脑就坏了。(hardly..when)<ul>
<li>7.Lulu had hardly used her new computer when it broke.</li>
</ul>
</li>
</ol>
</li>
<li>8.我们会待在海边直到天黑。<ul>
<li>8.We are going to stay at the beach until it gets dark.</li>
</ul>
</li>
<li>9.已经过了三个月，大卫才提到他生病了。<ul>
<li>9.It had been three months before David mentioned he was sick.</li>
</ul>
</li>
<li>10.我在电影院门口等Lisa，不久以后她就到了。<ul>
<li>10.We waited for Lisa in front of the cinema and it was not long before she arrived.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="地点状语从句：一个句子在另外一个句子里面充当地点状语"><a href="#地点状语从句：一个句子在另外一个句子里面充当地点状语" class="headerlink" title="地点状语从句：一个句子在另外一个句子里面充当地点状语"></a>地点状语从句：一个句子在另外一个句子里面充当地点状语</h2><ul>
<li>地点状语从句的连词是where，但是要注意，where引导的地点状语从句，不仅可以表示地点，还可以表示抽象意义“在…形势之下”<ul>
<li>Where there is a will, there is a way.有志者，事竟成。</li>
<li>Where there is a smoke, there is fire.无风不起浪 </li>
<li>A driver should slow down where there are schools. 在有学校的地方， 司机应缓行。</li>
<li>Where the cost of government is high, resources for development are corresponding low.凡是政府管理费用高的地方，用于发展国家经济的资金就会相应地减少。</li>
<li>Where others ran away in fear, the soldier bravely fought against the enemy.在其他人惊慌逃跑的情况下，这名士兵英勇地抗击敌军。</li>
</ul>
</li>
<li>造句练习<ul>
<li>1.有生命就有希望。<ul>
<li>1.Where there is life, there is hope.</li>
</ul>
</li>
<li>2.在我成长的地方，人们在马路上都是靠右行驶。<ul>
<li>2.Where I grew up, people drive on the right side of the road.</li>
</ul>
</li>
<li>3.医生建议我住在空气更新鲜的地方。<ul>
<li>3.The doctor advised me to live where the air is fresher.</li>
</ul>
</li>
<li>4.在你有足够信心的前提下，你将会成功。<ul>
<li>4.Where you have enough confidence, you will succeed.</li>
</ul>
</li>
<li>5.无论你去哪里，无论你做什么，我将一直在这儿等你。<ul>
<li>5.Wherever you go, whatever you do, I will be right here waiting for you.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="原因状语从句：一个句子在另外一个句子里面充当原因状语"><a href="#原因状语从句：一个句子在另外一个句子里面充当原因状语" class="headerlink" title="原因状语从句：一个句子在另外一个句子里面充当原因状语"></a>原因状语从句：一个句子在另外一个句子里面充当原因状语</h2><ul>
<li>because, as, since, for, in that均可引导原因状语从句</li>
<li>because语气最强（强调从句），只有它能回答why的提问，也只有because才能被强调词only, just, perhaps来修饰</li>
<li>for/in that语气最弱（强调主句），所以只能放在主句后面。for表示推断的理由，故多用于主句后面</li>
<li>注:汉译英的时候，“既然”翻译为since,“由于”翻译为as<ul>
<li>Teenagers are damaging their health <code>because</code> they play computer games too much. 因为青少年们玩电脑游戏太多，他们的健康正在受损。</li>
<li><code>Perhaps because</code> Mom missed so much time with her own kids, she made it up with her grandchildren. 或许我妈妈错过了太多与她自己的孩子在一起的时间，因此她在孙辈中找到补偿。</li>
<li><code>As</code> a great many people will be visiting the country, the government will be building new hotels, an immense stadium, and a new Olympic-standard swimming pool. 由于将有大批的人到我们国家来，所以政府准备建造一些新的饭店、一个大型体育场和一个新的奥运会标准游泳池</li>
<li>I will seek to balance career and family <code>since</code> both are important to me. 由于事业和家庭对我都重要，我要努力在两者之间取得平衡。</li>
<li>He had had a long and uncomfortable trip, <code>for</code> he had been confined to the wooden box for over ten hours. 他经历了一次漫长而又难受的旅程，因为他在那木箱里闷了18个多小时。</li>
<li>He didn’t attend the negotiation <code>in that</code> he was ill. 他因为有病，没有参加谈判</li>
</ul>
</li>
<li>because和because of的区别：because of是介词短语，后面只能接名词，不能接句子。类似的介词短语还有due to, in view of, thanks to, owning to<ul>
<li><code>Because of</code> this, he has not been able to get his own car into his garage even once.为此，他甚至一次也没能把自己的车开进车库。</li>
<li><code>Owning to</code> the heavy rain, there have been many mudslides in the hill lately.因为大雨，最近山区发生多起泥石流。</li>
<li><code>Thanks to</code> great public transportation, few people in the city need to own cars.因为有很好的公交系统，这个城市很少有人需要自己买车。</li>
</ul>
</li>
<li>造句练习<ul>
<li>1.我们将取消音乐会，因为音乐家出了意外，现在人在医院里。<ul>
<li>1.We will cancel the concert because the musician had an accident and is in the hospital.</li>
</ul>
</li>
<li>2.由于下周一是法定假日，所有的政府机关都将休息。<ul>
<li>2.As next Monday is a national holiday, all government offices will be closed.</li>
</ul>
</li>
<li>3.既然你是英语专业的，我猜想你能帮助我学习这个句子。<ul>
<li>3.Since you are an English major, I guess you can help me study this sentence.</li>
</ul>
</li>
<li>4.这个问题的答案我很久都理解不透(eludeme),也许是因为问题太简单了。<ul>
<li>4.The answer to this question eluded me for a long time, perhaps because it was so simple.</li>
</ul>
</li>
<li>5.昨晚下雨了，因为今天早上地面是湿的。<ul>
<li>5.It rained last night, for the ground is wet this morning.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="结果状语从句：就是中文里边说的”如此……-以至于……”。连接结果状语从句的连词有-so-that…-，-such-that…，-so-that"><a href="#结果状语从句：就是中文里边说的”如此……-以至于……”。连接结果状语从句的连词有-so-that…-，-such-that…，-so-that" class="headerlink" title="结果状语从句：就是中文里边说的”如此…….以至于……”。连接结果状语从句的连词有: so..that…..， such..that…， so that"></a>结果状语从句：就是中文里边说的”如此…….以至于……”。连接结果状语从句的连词有: so..that…..， such..that…， so that</h2><ul>
<li>so…that…: so后面要接形容词或副词，或相当于形容词的分词<ul>
<li>Mrs. Sterling got so angry that she ran after them.斯特林夫人非常气愤，向着他们追了过去。</li>
<li>My friend, Hugh, has always been fat, but things got so bad recently that he decided to go on a diet.我的朋友休一直很胖，但是近来情况变得越发糟糕，以致他决定节食。</li>
<li>He did the work so badly that I had to do it all over again myself. 他干的太差劲了，我只好亲自重做</li>
<li>本句型的so可用enough取代，但是enough要后置<ul>
<li>She is old enough that she can get married = She is so old that she can get married.她已达到可结婚的年龄。</li>
<li>In the new country he became absorbed in making a new life for the two of us, so that he gradually ceased to grieve. 在这个新的国家里，父亲专心致志地为我们俩开创一种新的生活，慢慢地不伤心了。</li>
</ul>
</li>
</ul>
</li>
<li>such…that…：such后面要接名词<ul>
<li>The men got <code>such</code> a fright <code>that</code> they dropped the bag and ran away.这两个人吓了一跳，扔下提包逃跑了。</li>
</ul>
</li>
<li>so是so that…的省略形式，so既可以是副词，也可以是连词。so引导的句子，不仅可以用逗号连接，也可以单独成句<ul>
<li>My brother has never been abroad before, so he is finding this trip very exciting. 我弟弟以前从未出过国，因此，他觉得这次旅行非常激动人心。</li>
<li>To make matters worse, the room is rather small, so I have temporarily put my books on the floor. 更糟糕的是，房间还非常小，所以我暂时把书放在了地板上。</li>
</ul>
</li>
<li>so作副词，其引导的句子，也可以和前面的句子分开。<ul>
<li>The children were at school, my husband was at work and the house was quiet. So I decided to make some meat pies. 孩子们在上学，我丈夫在上班，家里清静得很。于是我决定做些肉馅饼。</li>
</ul>
</li>
<li>造句练习<ul>
<li>1.湖面上的雾太浓，所以我们不能看到对岸。<ul>
<li>1.The fog on the lake was very thick, so we couldn’t see the other side.</li>
</ul>
</li>
<li>2.玛丽很贴心，以至于大家都很喜欢她。<ul>
<li>2.Mary is so sweet that everyone loves her.</li>
</ul>
</li>
<li>3.他们是很糟糕的厨师以至于没人去他们的餐厅。<ul>
<li>3.They are such terrible cooks that no one came to their restaurant.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="目的状语从句"><a href="#目的状语从句" class="headerlink" title="目的状语从句"></a>目的状语从句</h2><ul>
<li>一般翻译为“以便于”，常用连词有so that, in order that, that, 主句和从句一般没有逗号隔开，在目的状语从句中，常含有情态动词<ul>
<li>He worked hard at his lessons so that he could gain high grades in the exams.他努力学习功课，争取考试能获得好成绩。（目的状语从句）</li>
<li>He worked hard at his lessons, so that he could gain high grades in the exams.他努力学习，结果考试获得了好成绩。(结果状语从句)</li>
<li>This time he was barking <code>so that</code> someone would let him out! 这次它叫着让人把它放出去!</li>
<li>This time, he managed to climb into the mouth of Kituro <code>so that</code> he could take photographs and measure temperatures. 这次他设法爬进了基图罗火山口，以便能拍摄照片和测试温度。</li>
<li>They had taken special precautions <code>so that</code> no one should recognize them. 他们做了特别的预防措施以防别人认出他们。</li>
<li>I am saving money <code>in order that</code> I can buy a house.我正在攒钱，以便我能买一所房子。</li>
</ul>
</li>
<li>造句练习<ul>
<li>1.这位电影明星伪装自己，以便在人群中不被认出来。<ul>
<li>1.The movie star disguised himself so that he wouldn’t be recognized in the crowd.</li>
</ul>
</li>
<li>2.我们应该早起以便能看到日出。<ul>
<li>2.We should wake up early in the morning in order that we can see the sun rise.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="让步状语从句"><a href="#让步状语从句" class="headerlink" title="让步状语从句"></a>让步状语从句</h2><ul>
<li>表示“虽然。。。但是。。。”，副词连词有：though, although, even though, even if。但和中文不同，主语前不可再加but，但可用yet/still</li>
<li>though, although, even though是对事实的让步，翻译为“虽然，尽管”</li>
<li>even if是对假设的让步，翻译为“即使，哪怕是”<ul>
<li><code>Though</code> she hesitated for a moment, she finally went in and asked to see a dress that was in the window. 她虽然犹豫了片刻，但终于还是走进了商店，要求把陈列在橱窗里的一件衣服拿给她看。</li>
<li><code>Although</code> the bed was smashed to pieces, the man was miraculously unhurt. 尽管床摔成了碎片，但年轻人却奇迹地没有受伤。</li>
<li><code>Even though</code> it was still summer, it rained continually and it was often bitterly cold. 即使那时仍为夏季，但雨总是下个不停，而且常常冷得厉害。</li>
<li>The villagers have told him that they will not accept the pub <code>even if</code> he gives it away. 村里的人已经告诉他，即使他把小酒店白送人，他们也不要。</li>
</ul>
</li>
<li>while/whereas也可以引导让步状语从句，相当于though或although<ul>
<li><code>While</code> winning is not everything, trying to win is everything.尽管获胜并不重要，但是为了获胜而努力却很重要。</li>
<li><code>Whereas</code> you cannot turn back the clock, you can take control of your life.虽然你不能使时钟倒转，但却可以掌控自己的生活。</li>
</ul>
</li>
<li>no matter wh-(how, what, who, which, when, where)或者however, whatever..也可引导让步状语从句<ul>
<li><code>No matter how</code> busy you are, he always insists on coming with you. 不管你多忙，他总是坚持要跟你去。(No matter how=however)</li>
<li><code>No matter what</code> you do, do with your might. 无论你做什么，要尽力。(No matter what=whatever)</li>
<li><code>No matter who</code> he is, he must obey the law.无论他是谁，都必须遵守法律。(No matter who=whoever)</li>
<li><code>No matter which</code> people criticize you, don’t let them take your focus off your dream.无论什么人批评你，都不要让他们破坏你的梦想! (No matter which=whichever)</li>
<li><code>No matter where</code> you live, you would find it difficult not to laugh at, say, Charlie Chaplin’s early films.比如说，不管你生活在哪里，你看查理.卓别林的早期电影很难不发笑。</li>
<li><code>Whatever</code> may happen, you must keep calm.不论什么事发生，你必须保持冷静。</li>
<li>The business would be a success, <code>whoever</code> owned it.不论什么人经营，这生意都会成功。</li>
</ul>
</li>
<li>whether也可以引导让步状语从句，表示“无论…”常和or或or not一起使用<ul>
<li><code>Whether</code> we realize it or not, each of us has the strong desire to success.不管我们是否意识到，我们都有成功的愿望。</li>
<li><code>Whether</code> we win or lose, we should respect the election result.无论是输还是赢，我们应该尊重选举结果。</li>
<li><code>Whether or not</code> he will stay, I really don’t care.他要走还是要留，我真的不关心。</li>
</ul>
</li>
<li>造句练习<ul>
<li>1.虽然他是我兄弟，但我们长得不像。<ul>
<li>1.Though he is my brother, we don’t look alike.</li>
</ul>
</li>
<li>2.尽管我父亲已经到了退休年龄，却打算继续工作。<ul>
<li>2.My father plans to carry on working even though he is old enough to retire .</li>
</ul>
</li>
<li>3.尽全力去奋斗，不管是否喜欢。<ul>
<li>3.Try your best to fight, whether you enjoy it or not.</li>
</ul>
</li>
<li>4.无论是你做还是他做，这个工作今天都得做完。<ul>
<li>4.Whether you or he do it, the work must be finished today<h2 id="方式状语从句"><a href="#方式状语从句" class="headerlink" title="方式状语从句"></a>方式状语从句</h2></li>
</ul>
</li>
</ul>
</li>
<li>表示动作的方式，意思是“就像…一样，以…样的方式”，引导词有as, as if, as though, the way<ul>
<li>When in Rome, do <code>as</code> the Romans do. 入乡随俗。</li>
<li>The space shuttle, <code>as</code> we know it, is still imperfect. 航天飞机就像我们知道的一样仍然不完美。</li>
<li>He acted <code>as if</code> he had never lived in England before. 他的举动就好像他从未在英国生活过一样。</li>
<li>To achieve great things we must live <code>as though</code> we were never going to die. 做大事就要有永生的气概!</li>
<li>You should do it <code>the way</code> you were taught. 按照教你的那样去做</li>
</ul>
</li>
<li>美式英语可用like代替as if, as though，但是书面语中少用<ul>
<li>He studies English very hard, like he did Chinese some years ago. 他非常用功地学英语，就像多年前学中文一样。</li>
</ul>
</li>
<li>造句练习<ul>
<li>1.你应该像规划假期一样规划你的退休生活。<ul>
<li>1.You should plan your retirement as you plan your vacation.</li>
</ul>
</li>
<li>2.请照我这样，读这个单词<ul>
<li>2.Please pronounce the word the way I do</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="8-定语从句不一定是真定语，而是并列句的马甲"><a href="#8-定语从句不一定是真定语，而是并列句的马甲" class="headerlink" title="8.定语从句不一定是真定语，而是并列句的马甲"></a>8.定语从句不一定是真定语，而是并列句的马甲</h1><h2 id="定语从句是什么"><a href="#定语从句是什么" class="headerlink" title="定语从句是什么"></a>定语从句是什么</h2><p>一个句子，在另一个句子里边，作定语。</p>
<h2 id="定语从句的其实是两个并列句的合并"><a href="#定语从句的其实是两个并列句的合并" class="headerlink" title="定语从句的其实是两个并列句的合并"></a>定语从句的其实是两个并列句的合并</h2><ul>
<li>Captain Fawcett’s first passenger was a doctor <code>who</code> flew from Birmingham to a lonely village in the Welsh mountains.</li>
<li>这句话里边，who指的是主句提到的the doctor，那么，如果按照传统语法来翻译就是: Fawcett机长的第一个乘客是一个从伯明翰飞到南威尔士一个偏僻村子去的医生。</li>
<li>Captain Fawcett’s first passenger was a doctor and <code>the doctor</code> flew from Birmingham to a lonely village in the Welsh mountains.</li>
<li>因为后面分句的the doctor，其实就是主句里边的doctor，所以，后面那个句子的the doctor就可以改成who，然后去掉and，就变成定语从句了。</li>
</ul>
<h2 id="定语从句的连接词，叫关系词，分为两大类"><a href="#定语从句的连接词，叫关系词，分为两大类" class="headerlink" title="定语从句的连接词，叫关系词，分为两大类"></a>定语从句的连接词，叫关系词，分为两大类</h2><ul>
<li>1.代词类关系词<ul>
<li>(1)关系代词</li>
<li>(2)关系代词所有格</li>
<li>(3)复合关系代词</li>
</ul>
</li>
<li>2.副词类关系词<ul>
<li>(1)关系副词</li>
</ul>
</li>
</ul>
<h2 id="关系代词"><a href="#关系代词" class="headerlink" title="关系代词"></a>关系代词</h2><ul>
<li>概述<ul>
<li>替代前面的先行词，在定语从句中作主语，宾语，表语。</li>
<li>代替人时，坐主语用主格who，作宾语用宾格whom</li>
<li>代替物，或代替整个句子，无论作主语还是宾语，均用which</li>
</ul>
</li>
<li>限定性定语从句：先行词为一般名词，关系代词引导的定语从句<ul>
<li>Captain Fawcett’s first passenger was a doctor <code>who</code> flew from Birmingham to a lonely village in the Welsh mountains.(who作主格，代替doctor) 弗西特机长的第一名乘客是位医生，他从伯明翰飞往威尔士山区一个偏僻的村庄。</li>
<li>He is a man <code>whom</code> we should respect.他是一个我们应该尊重的人。(whom做宾语，代替man)注:在美国英语中，whom作宾语时，也可用who代替。把whom we should respect.直接翻译成定语“我们应该尊重的”比较好</li>
<li>In a few years the small workshop had become a large factory <code>which</code> employed 728 people.(which作主语，代替factory)几年之后，小铺子已经发展成了一个雇有728人的大工厂。把which employed 728 people.直接翻译成定语“雇有728人的“比较好</li>
<li>Forest fire often caused by cigarette ends <code>which</code> people carelessly throw away.(which作宾语，代替cigarette ends)森林火灾时常由人们随手扔掉的香烟头引起</li>
<li>In 1948, he went to Lake Kivu to observe a new volcano <code>which</code> he later named Kituro.(which作宾语，代替volcano, 而定语从句里边的Kituro是宾语补语)1948年他去了基伍湖，对一座后来被他命名为基图罗的新火山进行观察</li>
</ul>
</li>
<li>作介词的宾语时，可以将介词移动到关系词之前，一般正式的书面语，是把介词放在关系代词前面<ul>
<li>Peter is a man <code>whom</code> I enjoy working <code>with</code>.</li>
<li>Peter is a man <code>with whom</code> I enjoy working.</li>
<li>The city <code>in which</code> I live is very large.</li>
<li>The city <code>which</code> I live <code>in</code> is very large.</li>
</ul>
</li>
<li>非限定性定语从句：若定语从句只对先行词进行补充说明，则关系词前面可加上逗号</li>
<li>先行词为一般名词，但其前面已经有限定词或形容词修饰时，其后既可用限定性定语从句，也可用非限定性定语从句<ul>
<li>He waved desperately to his companion, <code>who</code> had been water-skiing for the last fifteen minutes.他绝望地向他的伙伴挥手，他的伙伴在过去的15分钟里一直在滑水</li>
</ul>
</li>
<li>先行词为专有名词（人名或地名）及独一性名词（如father, mother…）时，因为本身就具有特殊性，其后关系代词引导的定语从句，必须是非限定性定语从句<ul>
<li>Einstein, <code>who</code> was a great scientist, created the theory of relativity. 爱因斯坦这位伟大的科学家发明了相对论。</li>
<li>Beijing, <code>which</code> is the capital of China, has developed into an international city.北京，中国的首都，已经成为了一个国际大都市。</li>
<li>Among them will be Debbie’s mother, <code>who</code> swam the Channel herself when she was a girl.他们当中还会有黛比的母亲，她本人还是个女孩时，也曾横渡过英吉利海峡!</li>
</ul>
</li>
<li>先行词为整个主句时，定语从句也多是非限定性定语从句<ul>
<li>Jimmy is a naughty boy, <code>which</code> everyone knows. 吉米是一个顽皮的孩子，这点大家都知道</li>
</ul>
</li>
<li>that也可作关系代词，取代who, whom, which, 但that前不能有逗号，也不能有介词<ul>
<li>This is the sort of thing <code>that</code> Jeremy loves. 这正是杰里米喜欢做的事情。</li>
<li>A game <code>that</code> is very popular with these young swimmers is the underwater tricycle race.这些幼小的游泳运动员非常喜爱的一种游戏是水下三轮车比赛。</li>
</ul>
</li>
<li>只能用that的情况：<ul>
<li>1.先行词同时出现“人”和“物”时<ul>
<li>The scientist and his inventions <code>that</code> the article deals with are quite familiar to us.这篇文章里说的那位科学家和他的发明，我们都比较熟悉。</li>
</ul>
</li>
<li>2.先行词是不定代词（something, anything, nothing, everything）时<ul>
<li>I would much rather receive something <code>that</code> made me laugh.我更愿意接受能让我高兴的东西</li>
<li>A variable is something <code>that</code> can be changed and controlled.变量是能够被改变和控制的东西。(美国加州3年级科学课本)</li>
</ul>
</li>
<li>3.先行词被绝对性形容词修饰时（如序数词，形容词的最高级，the very, the only, all, every, no等修饰时）<ul>
<li>Of course, the Hubble is above the earth’s atmosphere, so it will soon be sending us <code>the clearest pictures that</code> we have ever seen.当然，哈勃位于地球的大气层之外，因此，它很快就会给我们传送我们所见到过的、有关行星和远距离星系的最清晰的照片。</li>
<li><code>All the students that</code> are studying in our class is hardworking.尽管有上述种种说法，但游客们还是照常摘树叶和把他们的名字刻在树干上。</li>
</ul>
</li>
<li>4.句中有两个相同关系代词引导的定语从句时，为避免重复，其中一个用that<ul>
<li>He works hard, <code>which</code> is a fact <code>that</code> is known to us.他很用功，这时我们都知道的事实。</li>
<li>My best friend was devastated by the letter <code>which</code> she received <code>that</code> rejected her application to university.[that和which也可互换]我最好的朋友被那封她收到的拒绝她入大学申请的信打击了。</li>
<li>There was no trace of fingerprints, but the inspector found a dirty red bundle <code>that</code> contained jewellery <code>which</code> the old lady said was not hers.巡官没有发现指纹，却发现了一个装有珠宝的、肮脏的红包袱。老妇人说那不是她的。</li>
</ul>
</li>
<li>5.限定性定语从句中，若关系代词作及物动词的宾语，该关系代词可省略。若作介词的宾语，则将介词放在词尾，再省略关系代词<ul>
<li>It is one of the ugliest faces I have ever seen.(定语从句前省略了作宾语的关系代词that) 这是我见过的最丑陋的头像之一。</li>
<li>That was all she remembered.(定语从句前省略了作宾语的关系代词that) 她所记得的就是这些。</li>
<li>The picture it sent us were very disappointing because its main mirror was faulty!(定语从句前省略了作直接宾语的关系代词that或which)它传送给我们的图像很令人失望，因为它的主要镜子有误差。</li>
<li>Peter is a man I enjoy working with.(定语从句前省略了whom)彼得是一个我喜欢和他共事的人。</li>
</ul>
</li>
</ul>
</li>
<li>造句练习<ul>
<li>1.双语人士(bilingual) 就是能说两种语言一样好的人。<ul>
<li>1.A bilingual is a person who can speak two languages equally well.</li>
</ul>
</li>
<li>2.不要和自己了解不充分的人交朋友。<ul>
<li>2.Don’t make friends with those whom(who) you do not know well.</li>
</ul>
</li>
<li>3.要参加比赛的人必须在本周五之前报名(signup)。<ul>
<li>3.People who want to attend the competition must sign up by this Friday.</li>
</ul>
</li>
<li>4.Lulu买了那件她想要的价值不菲的裙子。<ul>
<li>4.Lulu bought that expensive skirt which she wanted.</li>
</ul>
</li>
<li>5.我把我银行账户里边的最后一美元花掉了。<ul>
<li>5.I spent the last dollar that I had left in my bank account.</li>
</ul>
</li>
<li>6.我喜欢我的学校，它以优良的设施闻名。<ul>
<li>6.I like my school, which is famous for its excellent facilities.</li>
</ul>
</li>
<li>7.我在聚会上遇到很多小学同学，其中一些我都认不出来了。<ul>
<li>7.I met many elementary schoolmates at the party, some of whom I didn’t recognize.</li>
</ul>
</li>
<li>8.彼得是个非常优秀的工程师，这点我们都知道。<ul>
<li>8.Peter is a very excellent engineer, which we all know.</li>
</ul>
</li>
<li>9.这位是我的女朋友，她英语说得非常流利。<ul>
<li>9.This is my girlfriend, who can speak fluent English.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="关系代词所有格"><a href="#关系代词所有格" class="headerlink" title="关系代词所有格"></a>关系代词所有格</h2><ul>
<li>由代词所有格his, her, their, my, your, its变化二来，关系代词所有格和后面的名词，共同作定语从句的主句，宾语</li>
<li>无论代替人还是代替物，关系代词所有格均可用whose</li>
<li>修饰物，也可用of which</li>
<li>of前面是代词的时候，不用whose，用of whom<ul>
<li>Many people <code>whose</code> homes are in town want to live in the country.(whose代替人)很多家在城里的人都想住在乡下。</li>
<li>Be a man <code>whose</code> word is as good as your bond.(whose代替人)做一个说话可靠的人。</li>
<li>Success is a journey <code>whose</code> initial step is paved with an inner stirring.(whose代替物)成功是以此旅程，第一步是由内心的热情铺就的。</li>
<li>也可改为：</li>
<li>Success is a journey <code>of which</code> the initial step is paved with an inner stirring.</li>
<li>Success is a journey, the initial step <code>of which</code> is paved with an inner stirring.</li>
</ul>
</li>
<li>名词/代词+of+whom/which这种结构，属于非限定性定语从句，表示从属关系<ul>
<li>Light is the fastest thing in the world, <code>the speed of which</code> is 300.000 kilometers per second.(这里的先行词是speed是名词，所以可改成whose speed)光是世界上最快的东西，它的速度是每秒30万公里。</li>
<li>The old man has three sons, <code>one of whom</code> is a doctor.(这里的先行词one是代词，所以不能改成whose one..)这个男人有三个儿子，其中一个是医生。</li>
<li>There are 300 college students in the small hall, <code>most of whom</code> are freshmen.(先行词most是代词，所以不能改成whose most…)这个小厅里边有300个大学生，他们中的大多数是大一学生。</li>
</ul>
</li>
<li>造句练习<ul>
<li>1.这是玛丽，她的爸爸是我们学校的校长。<ul>
<li>1.This is Mary, whose father is the headmaster of our school.</li>
</ul>
</li>
<li>2.我们住在一栋老房子里，它的屋顶可能随时会崩塌(collapse)。<ul>
<li>2.We live in an old house whose roof may collapse anytime.</li>
</ul>
</li>
<li>3.这就是那台硬盘中病毒的电脑。<ul>
<li>3.This is the computer whose hard disk is infected with a virus </li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="复合关系代词"><a href="#复合关系代词" class="headerlink" title="复合关系代词"></a>复合关系代词</h2><ul>
<li>复合关系代词what，是先行词和关系代词融为一体，形成的关系代词，相当于the thing that。所以复合关系代词引导的定语从句，前面绝对没有先行词<ul>
<li><code>What</code> John said may be true. = The thing that John said may be true. = <code>What</code> was said by john may be true.(也可用被动语态)约翰说的可能是真的。</li>
<li>He was astonished at what he found.看到的情景使他吃惊。</li>
<li>what也可由all that取代<ul>
<li>Now <code>all that</code> was needed were the parents, but they were absent.现在，我们需要我们的父母，但是他们却不在。</li>
<li><code>All that</code> Billy told us a year ago has become true.Billy一年前告诉我们的事情成真了</li>
</ul>
</li>
</ul>
</li>
<li>造句练习<ul>
<li>1.我没有听到你刚才说的，能再说一遍吗?<ul>
<li>1.I didn’t hear what you just said. Could you say that again?</li>
</ul>
</li>
<li>2.我知道你的意思，但是我不同意。<ul>
<li>2.I know what you mean but I can’t agree with you.</li>
</ul>
</li>
</ul>
</li>
<li>其它不常用复合关系代词：<ul>
<li>1.代替人：<ul>
<li>whoever = anybody who(凡是…的人)</li>
<li>whomever = anybody whom(凡是…的人)</li>
</ul>
</li>
<li>2.代替物：<ul>
<li>whatever = anything which(…的任何东西)</li>
</ul>
</li>
<li>3.代替人或物：<ul>
<li>whichever = any one which/who(三者以上同类的任何一个)</li>
<li>= either which/who（二者同类的任何一个）</li>
</ul>
</li>
</ul>
</li>
<li>代词whatever是what的强调形式，相当于anything which<ul>
<li>She would do <code>whatever</code> she wanted to. = She would do <code>anything which</code> she wanted to.她想要做什么就做什么。</li>
</ul>
</li>
<li>代词whoever有时也可视为复合关系代词，相当于anybody who<ul>
<li><code>Whoever</code> plays with fire gets burnt. = <code>Anybody who</code> plays with fire gets burnt.玩火者必自焚。</li>
<li>I’ll teach English to <code>whoever</code> wants to learn it. = I’ll teach English to <code>anybody who</code> wants to learn it.谁想学英文，我就教他。</li>
</ul>
</li>
</ul>
<h2 id="副词类关系词"><a href="#副词类关系词" class="headerlink" title="副词类关系词"></a>副词类关系词</h2><ul>
<li>一共有3种，均由“介词+关系代词which”变化而来<ul>
<li>1.where = in which, on which, at which 代替表地方的名词</li>
<li>2.when = in which, on which, at which 代替表时间的名称</li>
<li>3.why = for which 代替the reason</li>
</ul>
</li>
<li>在限定性定语从句中，where不能省略，when和why可以省略<ul>
<li>Mrs. Brabante is talking to the manager of the local factory <code>where</code> the crop is processed.(where=in the factory=in which，在从句里边作地点状语)布拉班特太太现在正和负责通心粉加工的当地加工厂的经理交谈。</li>
<li>There will be moments in life <code>when</code> you are confronted with new options.(when = in these moments = in which在从句里边作时间状语)人生中总有会面对新选择的时候。</li>
<li>Unsuccessful people can always find reasons <code>why</code> they are not doing well.(why = for these reasons = for which, 在从句中作原因状语。而且这个句子中，不仅可以省略why。还可以保留why，省略reasons，此时变成宾语从句Unsuccessful people can always find <code>why</code> they are not doing well.)不成功的人总能找到自己表现不好的理由。</li>
</ul>
</li>
<li>the way后面的定语从句<ul>
<li>先行词是名词the way的时候，后面的关系副词是in which或者that，而且可省略<ul>
<li>The assistant who served her did not like the way she was dressed.(the way后面省略了in which/that)接待她的售货员不落欢她的那刚打扮。</li>
<li>I liked the way she organized the meeting.(the way后面省略了in which/that)我喜欢她组织会议的方法</li>
<li>I hate the way in which he stares at me.我讨厌他那样盯着我</li>
<li>The only way that they can preserve their history is to recount it as sagas.他们保存历史的唯一办法是将历史当作传说讲述。</li>
</ul>
</li>
<li>上面句型中的the way(in which/that)可被how取代，变成宾语从句，意思不变。但用得不多<ul>
<li>The assistant who served her did not like how she was dressed.</li>
<li>I liked how she organized the meeting.</li>
<li>I hate how he stares at me.</li>
</ul>
</li>
<li>the way也可作副词连词引导方式状语从句<ul>
<li>I admire the way you speak to your students.（定语从句）</li>
<li>You should do it the way you were taught.(方式状语从句)</li>
</ul>
</li>
</ul>
</li>
<li>where, when代替的先行词作be动词的表语时，可省略先行词，保留关系副词<ul>
<li>This is (the place) where he was born.这是他出生的地方。</li>
<li>That is (the day) when he will come.那就是他要来的日子。</li>
</ul>
</li>
<li>某些表示时间的名词短语，后面接着没有引导词的句子，其实就是省略了关系副词when。by the time, at the time, next time, every time, the first time, the day…<ul>
<li><code>Every time</code> he wanted to come into the garden he would bark until someone opened the gate.</li>
<li><code>By the time</code> you read this, the Hubble’s eagle eye will have sent us thousands and thousands of wonderful pictures.</li>
</ul>
</li>
<li>造句练习<ul>
<li>1.上午11点是考试结束时间，那时所有学生都必须放下笔(put down)。<ul>
<li>1.Eleven a.m. is the time when the exam will be over and all students must put their pens down.</li>
</ul>
</li>
<li>2.我想知道你今天上午，上学迟到的原因。<ul>
<li>2.I want to know the reason why you were late to school this morning.</li>
</ul>
</li>
<li>3.月球上有一个地方，是Neil Armstrong所踏出的第一 步。<ul>
<li>3.There is a spot on the moon where Neil Armstrong took his first step.</li>
</ul>
</li>
<li>4.这是他处理问题的方法。<ul>
<li>4.This is the way he handled problems. / This is how he handled problems.</li>
</ul>
</li>
<li>5.我们有时把荒岛想象成某种阳光终日普照的天堂。<ul>
<li>5.We sometimes imagine a desert island to be a sort of paradise where the sun always shines.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="9-英语长句子的简化方法"><a href="#9-英语长句子的简化方法" class="headerlink" title="9.英语长句子的简化方法"></a>9.英语长句子的简化方法</h1><h2 id="并列句的转化"><a href="#并列句的转化" class="headerlink" title="并列句的转化"></a>并列句的转化</h2><ul>
<li>分词短语的构成和功能<ul>
<li>分词，就是指动词的另外两种形式，一种是现在分词，另一种是过去分词</li>
</ul>
</li>
<li>并列句实质上就是两个简单句放在一起,并无主次之分<ul>
<li>请看下面两个句子:</li>
<li>We are sitting by the sea.我们坐在海边。</li>
<li>We can see the beautiful sunrise. 我们可以看到美丽的日出。</li>
<li>上述两个句子，如果放在一起， 形成并列句，那就是:</li>
<li>We are sitting by the sea and we can see the beautiful sunrise.</li>
<li>注意：连词and绝对不能换成逗号，这点要牢记，和我们汉语的标点符号是不同的。因为英语中一个句号只能有一个主语</li>
<li>We are sitting by the sea, we can see the beautiful sunrise. (X)</li>
</ul>
</li>
<li>句子中的简化方法<ul>
<li>要强调哪个句子，就把哪个句子作为主句，另外一个不重要的，简化为分词短语</li>
<li>前面句子不重要：<code>Sitting by the sea</code>, we can see the beautiful sunrise.</li>
<li>后面句子不重要：We are sitting by the sea <code>seeing the beautiful sunrise</code>.</li>
<li>并列句变成的分词短语，称为“伴随状语”，如果分词短语放在主句前面，一定要加上逗号，如果分词短语放在主句后面，逗号可要可不要</li>
</ul>
</li>
<li>分词短语：其实就是简化的句子<ul>
<li>两句主语相同时，被化简句子的主语要删除<ul>
<li>He glanced at her scornfully and he told her that the dress was sold.他轻蔑地看了她一眼后，便告诉她那件衣服已经卖出去了。</li>
<li>这是一个并列句，两个分词的主语都是he，所以可以将其中任何一个分句，化简为分词短语</li>
<li>1.Glancing at her scornfully, he told her that the dress was sold.</li>
<li>2.He glanced at her scornfully telling her that the dress was sold.</li>
</ul>
</li>
<li>两句主语不同的时候，被化简句子的主语要保留<ul>
<li>We tried three new meals and the tastiest meal was the Thai dish. 我们试过3种新菜品，最好吃的是泰国菜。</li>
<li>这个并列句第一个分句的主语是We, 第二个分句的主语是the tastiest meal。这时两个分句的主语不同，故必须保留下来</li>
<li>1.We trying three new meals, the tastiest meal was the Thai dish.</li>
<li>2.We tried three new meals, the tastiest meal being the Thai dish.</li>
</ul>
</li>
</ul>
</li>
<li>并列句化简为分词短语的经典例句<ul>
<li><code>Following in his father&#39;s footsteps many years later</code>, Donald, also set up a world record. 很多年之后，马尔科姆爵士的儿子唐纳德踏着父亲的足迹，也创造了一项世界纪录。(相当于Donald <code>followed in his father&#39;s footsteps many years later,</code>…)</li>
<li>Working rapidly in the darkness, he soon changed into the dead man’s clothes.他在黑暗中忙活了一阵儿，很快就换上了死者的衣服。(相当于He worked rapidly in the darkness…)</li>
<li>The Channel Tunnel was officially opened on March 7, 1994, finally connecting Britain to the European continent.英法海底隧道于1994年3月7日正式开通，将英国与欧洲大陆连到了一起。</li>
<li>When it grew dark, she turned a suitcase into a bed and put the children inside it, covering them with all the clothes she could find. 天黑下来的时候，她把提箱当作小床，把两个孩子放了进去，又把所有能找到的衣服都盖在了孩子们身上。</li>
<li>Thousands of lanterns slowly <code>drift</code> out to sea guiding the dead on their return journey to the other world.成千上万只灯笼慢慢漂向大海，指引着亡灵返回另一个世界。(相当于drift out to sea and guide the dead on..)</li>
<li>This is a moving spectacle, for crowds of people <code>stand</code> on the shore watching the lanterns drifting away until they can be seen no more.这是一个感人的场面，人们成群地伫立在海岸上，注视着灯笼远去，直到再也看不见为止。(相当于stand on the shore and watch the lanterns…)</li>
</ul>
</li>
<li>若要化简的分句的动词是be动词（主系表句型，或被动语态），化简为分词being，而且可以将being省略<ul>
<li><code>Sensitive to criticism</code>, the bull forgot all about the matador and charged at the drunk.对批评很敏感，这头公牛忘了斗牛士，冲向这个酒鬼。(相当于 The bull <code>was</code> sensitive to criticism,…)</li>
<li>Now, <code>dressed in a blue</code> uniform and with a rifle over his shoulder, the prisoner marched boldly up and down in front of the camp.现在他身穿蓝军装，肩扛步枪，在军营门前大胆地来回走看。(相当于The prisoner <code>was</code> dressed in a blue uniform…)</li>
<li><code>Being a pop fan</code>, she likes Jay Chou most.作为一个流行乐迷，周杰伦是她最喜欢的明星。</li>
</ul>
</li>
<li>注意事项<ul>
<li>进行时态be+现在分词的情况，这个时候的be动词不是系动词，而是助动词，不能简化成being</li>
<li>比如He was playing basketball and he had a good time.这个时候前面分句的动词是play, 而不是was。所以只能改成Playing basketball, he had a good time.</li>
</ul>
</li>
<li>造句练习(分别用并列句和分词短语造句)<ul>
<li>1.日本发生强烈地震，造成重大伤亡(heavy losses)。<ul>
<li>1.A strong earthquake took place in Japan and caused heavy losses.</li>
<li>A strong earthquake took place in Japan causing heavy losses.</li>
</ul>
</li>
<li>2.然后他跳进车里，以最快的速度把车开走了(drive off)。<ul>
<li>2.Then, he jumped into the car and drove off as quickly as he could.</li>
<li>Then, jumping into the car, he drove off as quickly as he could.</li>
</ul>
</li>
<li>3.这位女演员很开心能演这个角色，于是答应主演这部电影。<ul>
<li>3.The actress was happy to play the role and accepted the offer to star in the film. </li>
<li>(Being) happy to play the role, the actress accepted the offer to star in the film.</li>
</ul>
</li>
<li>4.然后，她拿着画板走进我的房间，同时唱着流行歌曲。<ul>
<li>4.Then she marched into my room with her drawing board, singing a popular song.</li>
<li>Then she marched into my room with her drawing board and sang a popular song.</li>
</ul>
</li>
<li>5.我环视了一下身旁，惊奇地发现车里就只剩我一个乘客了<ul>
<li>5.I looked round and realized with a shock that I was the only passenger left on the bus.</li>
<li>Looking round, I realized with a shock that I was the only passenger left on the bus.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="状语从句的化简"><a href="#状语从句的化简" class="headerlink" title="状语从句的化简"></a>状语从句的化简</h2><ul>
<li>在时间、条件、原因、结果、目的、让步、方式等状语从句中，其主语与主句的主语相同时，可化简为现在分词短语（being可省略）<ul>
<li><code>Hearing the joke</code>, we burst out laughing.听到这个笑话，我们大笑起来。(相当于时间状语从句When we heard the joke, we bust out laughing.)</li>
<li><code>Not realizing who she was</code>, the assistant was eager to serve her this time.那个售货员没有认出她是谁，这一回接待她的态度非常殷勤。(相当于Because the assistant didn’t realize who she was, …)注，否定分词结构，not要放在分词前面</li>
<li><code>Tired of sleeping on</code> the floor, a young man in Teheran saved up for years to buy a real bed.德黑兰的一个人年轻人由于对睡地板感到厌倦，于是积蓄多年买了一张真正的床。(Tired前面省略了being，化简之前为Because he was tired of…)</li>
<li><code>Not wanting</code> to frighten the poor man, Mrs. Richards quickly hid in the small storeroom under the stairs.理查兹夫人不想吓到这个可怜的人，便赶紧躲到了楼梯下的小储藏室里。(相当于Because Mrs. Richards didn’t want to frighten the poor man, …)</li>
<li>It rained for two weeks on end, completely <code>ruining our holiday</code>.我们假期的最后两个星期都在下雨，把我们的假期全毁了。(相当于结果状语从句so that it completely ruined our holiday)</li>
<li>She tried to explain the situation, <code>saying &#39;It&#39;s only me&#39;</code>, but it was too late.她试图解释现在的情况，于是说“是我，别怕”，但是太迟了。(相当于结果状语从句… so that she said…)</li>
<li>The Titanic turned just in time, narrowly <code>missing the immense wall</code> of ice which rose over 100 feet out of the water beside her.“泰坦尼克”拐弯很及时，紧贴着高出海面100英尺的巨大的冰墙擦过去。(相当于结果状语从句so that it missed the immense wall…)</li>
<li>Her first impulse was to go round all the rooms <code>looking for the thieves</code>.她的第冲动是走遍所有房间， 去寻找小偷。</li>
<li>Your time is limited, so don’t waste it <code>living someone else&#39;s</code> life. Don’t let the noise of others’ opinions drown out your own inner voice. 你的时间有限,所以不要浪费时间去过别人的生活。不要让别人的意见淹没了你内心的声音。(乔布斯名言)(相当于目的状语从…o that you can live someone else’s life.)</li>
<li>I bound the base of the tree with sticky tape, <code>making it impossible for the ants to reach the aphides</code>. 我用一条胶带把桃树底部包上，不让蚂蚁接近蚜虫。( 相当于目的状语从句…so that I could make it impossible for the ants to reach the aphides.)</li>
<li>I crossed the street to avoid meeting him, but he saw me and came <code>running</code> towards me. 我穿过马路以便避开他，但他看到我并朝我跑过来。(相当于方式状语从句the way he ran towards me)</li>
<li>He and his staff began throwing furniture out of the window. Chairs and tables went <code>flying</code> into the arcade. 他与店员动手向窗外投掷家具，椅子和桌子飞落到拱廊街上。(相当于方式状语从句the way they flew into the arcade)</li>
<li>He had a very sad look on his face. He walked <code>looking only at the ground</code>.他的脸色看起来非常悲伤。他走路时只看着地面。( 相当于方式状语从句，the way he looked only at the ground)</li>
<li>Every morning, he left home <code>dressed in a smart black suit</code>. 每天早晨，他穿上一身漂亮的黑色西装离家上班(相当于方式状语从句，the way he was dressed in a smart black suit.)</li>
<li>She enjoyed herself <code>making the assistant bring almost everything in the window</code> before finally buying the dress she had first asked for. 她开心地迫使那位售货员把橱窗里几乎所有的东西都拿了出来，最后才买下了她最先要看的那一件。(相当 于方式状语从句，the way she made the assistant…)</li>
<li>Mocked at by everybody, he had my sympathy. 尽管大家嘲笑他，但是我很同情他。(相当于让步状语从句Though he was mocked at by everybody, ..)</li>
</ul>
</li>
<li>when, after, before, while, for, once, if, unless, though这些副词连词引导的状语从句化简成分词短语时，可以保留这些副词连词(before和after不能省略)<ul>
<li>They have all been put to shame by a boy who, <code>while playing truant</code>, travelled 1,600 miles. 而有那么一个小男孩，他在逃学期间旅行了1,600英里，从而使上述所有逃学的孩子们都相形见绌了。(相当于时间状语从句while he played truant, …)</li>
<li>Even the bull seemed to feel sorry for him, for it looked on sympathetically until the drunk was out of the way <code>before</code> once more <code>turning its attention to the matador</code>. 好像连牛也在为他感到遗憾，因为它一直同情地看着醉汉，直到他的背影消逝，才重新将注意力转向斗牛士。(相当于时间状语从句before it once more turned its attention to the matador.)</li>
<li>He was sent to prison <code>for failing</code> to pay his debts and died in poverty in 1836. 他因无力还债而被捕入狱，最后于1836年在贫困中死去。(相当于原因状语从句for he failed to pay his debts…)</li>
<li>It is important that I do not despair <code>when faced with difficulties</code>.重要的是，当我面对困难的时候我不会绝望。(相当于时间状语从句…when I am faced with difficulties.)</li>
<li><code>Though a little suspicious this time</code>, the policeman gave him the same answer.虽然那位警察这次有点疑心，但还是对他作了同样的回答。(相当于让步状语从句Though the policeman was a little suspicious, …</li>
</ul>
</li>
<li>造句练习: (分别用状语从句和分词短语造句)<ul>
<li>1.我没事做，所以感到很无聊。<ul>
<li>1.Because I have nothing to do, I felt bored.</li>
<li>Having nothing to do, I felt bored.</li>
</ul>
</li>
<li>2.你尚未满18岁，不能在便利店购买烟和酒。<ul>
<li>2.Because you are not eighteen years old yet, you can’t buy cigarettes or wine at a convenience store.</li>
<li>Not (being) eighteen years old yet, you can’t buy cigarettes or wine at a convenience store.</li>
</ul>
</li>
<li>3.因为不满意工资，很多工人罢工了。<ul>
<li>3.Because they are not satisfied with their wages, many workers went on strike.</li>
<li>Not (being) satisfied with their wages, many workers went on strike.</li>
</ul>
</li>
<li>4.除非受到邀请，否则你不可以参加明晚的聚会。<ul>
<li>4.Unless you are invited, you may not attend the party tomorrow night.</li>
<li>Unless (being) invited, you may not attend the party tomorrow night.</li>
</ul>
</li>
<li>5.虽然我们都知道真相，却保持沉默。<ul>
<li>5.Although we all know the truth, we remain silent.</li>
<li>Although knowing the truth, we all remain silent.</li>
</ul>
</li>
<li>6.那位渔民意识到这不是一条普通的鱼，于是千方百计不让它受到丝毫伤害。<ul>
<li>6.Because the fisherman realized that this was no ordinary fish, he made every effort not to damage it in any way.</li>
<li>Realizing that this was no ordinary fish, the fisherman made every effort not to damage it in any way.</li>
</ul>
</li>
<li>7.当地的屠户Sam Benton在把存款送往邮局的途中把钱包丢了。<ul>
<li>7.Sam Benton, the local butcher, had lost his wallet while he was taking his savings to the post-office.</li>
<li>Sam Benton, the local butcher, had lost his wallet while taking his savings to the post-office.</li>
</ul>
</li>
<li>8.尽管查尔斯不懂汉语，但是还是能够和我们交流。<ul>
<li>8.Though he didn’t understand Chinese, Charles was able to communicate with us.</li>
<li>Though not understanding Chinese, Charles was able to communicate with us.</li>
</ul>
</li>
<li>9.这部电影深刻解释了东西方文化的差异，结果引起了美国观众的强烈反响。<ul>
<li>9.The film exposes cultural differences between the East and the West, so that it aroused tremendous response in American audiences.</li>
<li>The film exposes cultural differences between the East and the West, arousing tremendous response in American audiences.</li>
</ul>
</li>
<li>10.听到这个消息时，他们都高兴得跳了起来。<ul>
<li>10.When they heard the news, they all jumped with joy.</li>
<li>Hearing the news, they all jumped with joy.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="定语从句的化简"><a href="#定语从句的化简" class="headerlink" title="定语从句的化简"></a>定语从句的化简</h2><ul>
<li>定语从句中，关系代词作主语时，可化简为现在分词短语。法则是：删除关系代词，其后动词变成现在分词<ul>
<li>Some children were playing games on the bank and there were some people <code>rowing on the river</code>.河岸上有些孩子正在玩耍，河面上有些人正在划船。(相当于定语从句，…who rowed on the river.)</li>
<li>Built in 1885, it was the oldest car taking part.该车造于1885年，是参赛车中最老的一辆。(相当于定语从句，…which took part)</li>
<li>I had all the usual symptoms of someone giving up smoking: a bad temper and an enormous appetite. 我具备了戒烟者通常表现出来的所有症状:脾气暴躁和食欲旺盛。(相当于定语从句，.. who give upsmoking..)</li>
<li>On a recent blog, Mr. Belinda wrote about VOA’s rules <code>demanding accuracy and objectivity</code>. 最近的一篇博客中，贝林达先生写了关于VOA要求客观性和准确性的规则。(相当于定语从句，… which demand..)</li>
</ul>
</li>
<li>如果定语从句是被动语态，或者主系表句型，be动词变成being后，可省略<ul>
<li>The ‘taxi’ is a small Swiss aeroplane <code>called a &#39;Pilatus Porter&#39;</code>. 这辆“出租汽车”是一架小型瑞士飞机，叫“皮勒特斯.波特“号。(called前省略了being, 如果用定语从句，则是…which is called a …)</li>
<li>Looking around, I realized with a shock that I was the only passenger left on the bus. 我环视了一下身旁，惊奇地发现车里就只剩我一个乘客了。(left前省略了being, 如果用定语从句，则是…who was left on the bus.)</li>
<li>Like his father, he was driving a car called Bluebird. 同他父亲一样，他也驾驶着一辆名 叫“蓝鸟”的汽车。</li>
<li>After reading an article entitled ‘Cigarette Smoking and Your Health’ I lit a cigarette to calm my nerves. 读完一篇题为《吸烟与健康》的文章之后，我点上了一枝香烟，来镇定一下自已紧张的神经。</li>
<li>I know an actor suitable for the part. 我认识一个适合扮演这个角色的演员。( 如果用定语从句，则是..who is suitable for the part.)</li>
</ul>
</li>
<li>造句练习 : (分别用定语从句和分词短语造句)<ul>
<li>1.乔治打开一个装着所有运动器材的大箱子。<ul>
<li>1.George opened a big box which contained all of his sports equipment.</li>
<li>George opened a big box containing all of his sports equipment.</li>
</ul>
</li>
<li>2.房主把贵重物品放在(keep)墙里边藏着的一个保险箱里。<ul>
<li>2.The owner of the house keeps his valuables in a safe which is hidden in the wall.</li>
<li>The owner of the house keeps his valuables in a safe hidden in the wall.</li>
</ul>
</li>
<li>3.那边那位正在同约翰说话的高个子男人是我的爸爸。<ul>
<li>3.The tall man who is talking to John over there is my father.</li>
<li>The tall man talking to John over there is my father.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="分词短语的逻辑主语"><a href="#分词短语的逻辑主语" class="headerlink" title="分词短语的逻辑主语"></a>分词短语的逻辑主语</h2><ul>
<li>分词的主语和句子的主语不相同时，分词的主语必须保留！此时所形成的分词结构，称为分词的独立主格结构<ul>
<li><code>Nobody having</code> any more to say, the meeting was closed. 谁都无话可说，会议就结束了。(句子的主语是the meeting, 分词having的主语是nobody)</li>
<li>The village seemed deserted, the only sign of life being an ugly-looking black goat tied to a tree on a short length of rope in a field nearby. 村里似乎无人居住，唯一的生命迹象是附近田里一只面目可憎的黑山羊，用一截短绳拴在一棵树上。(句子的主语是The village, 分词being的主语是sign)</li>
<li>Because our 3D television installed, the whole family went into the living room. 因为我们的3D电视安装好了，全家人都进了客厅。(installed前面省略了being)</li>
</ul>
</li>
<li>独立主格结构也可由with引导，用于表示伴随状况、补充说明、具体举例等，或者表示原因<ul>
<li>It is possible that upon such an occasion a battle ensued, with the sharks being driven away or killed.双方可能随之发生搏斗，搏斗结果是海豚赶走或咬死鲨鱼。</li>
<li>A car roared past, with smoke pouring from the exhaust.一辆小汽车呼啸而过，排气管冒出一团团黑烟。</li>
<li>The silence was suddenly broken when a large car, <code>with its headlights on</code> and <code>its horn blaring</code>, roared down the arcade.宁静突然被打破，一辆大轿车亮着前灯，响着喇叭，呼啸着冲进了拱廊街。</li>
</ul>
</li>
<li>独立主格结构中分词为being 的时候，可以省略<ul>
<li>Last year, we were travelling across the Channel and Jane put a piece of paper <code>with her name and address on it</code> into a bottle. 去年，当我们横渡英吉利海峡时，简把写有她姓名和住址的一张纸条装进了一只瓶子。(her name and address后面省略了分词being，整个独立主格结构作定语修饰paper)</li>
<li>In the struggle, the strap broke and, with the bag in their possession, both men started running through the trees. 在争抢中，手提包的带断了，包落入这两个人手里，他们拔腿跑进了树林。(the bag后面省略了分词being, 整个独立主格结构作原因状语</li>
<li>She returned to the shop the following morning dressed in a fur coat, <code>with a handbag in one hand and a long umbrella in the other</code>. 第二天上午，她又来到这家商店，穿了一件裘皮大衣，一只手拎着一只手提包，另一只手拿着一把长柄伞。 (handbag和umbrella后面均省略了分词being,整个独立主格结构作伴随状语)</li>
<li>I sat down on one of those modern chairs with holes in it and waited. 我坐在一个新式的满是网眼儿的椅子上，等待着。(holes后面省略了分词being, 整个独立主格结构作定语，修饰chairs)</li>
<li>At that moment, a large black car with four officers inside it, stopped at the camp gates. 正在此时，一 辆黑色大轿车在军营门口停了下来。里面坐了4个军官。</li>
</ul>
</li>
<li>并列句简化为独立主格的时候，和普通分词短语一样，重要的分句作为主句，次要的作为独立主格<ul>
<li>比如：He came in and carried a book.</li>
<li>简化为分词短语：He came in carrying a book</li>
<li>也可以简化为独立主格：He came in with a book (being) in his hand.</li>
</ul>
</li>
<li>造句练习: (分别用从句和分词短语造句)<ul>
<li>1.由于房间很小，我们得站得非常靠近。<ul>
<li>1.Because the room is so small, we have to stand very close together.</li>
<li>The room being so small, we have to stand very close together.</li>
</ul>
</li>
<li>2.我们昨天吃了三顿饭，最好吃的是泰国料理。<ul>
<li>2.We had three meals yesterday and the tastiest was the Thai dish.</li>
<li>We had three meals yesterday, the tastiest being the Thai dish.</li>
</ul>
</li>
<li>3.这个男孩经常逃学，他爸爸很生气。<ul>
<li>3.The boy often play truant from school and his father get angry.</li>
<li>The boy often playing truant from school, his father gets angry.</li>
</ul>
</li>
<li>4.宁静突然被打破，一个凶恶的家伙(tough guy)瞪着眼睛拿着枪，闯进了(break into)银行。<ul>
<li>4.The silence was suddenly broken, when a tough guy whose eyes glared and who took a gun, broke into the bank.</li>
<li>The silence was suddenly broken, when a tough guy, with his eyes glaring and gun in his hand, broke into the bank.</li>
</ul>
</li>
</ul>
</li>
<li>形成固定用法的几个独立主格结构（前面的主语we省略了）<ul>
<li>Frankly speaking, ..：坦白说<ul>
<li>Frankly speaking, it is difficult for me to understand what he is saying. 坦率地说，理解他正在说的事情是很困难的。</li>
</ul>
</li>
<li>Broadly speaking…：泛泛地说<ul>
<li>Broadly speaking, human beings may be divided into three classes. 泛泛地说，人可以分为3类。</li>
</ul>
</li>
<li>Judging from…：有…看来<ul>
<li>Judging from her accent, she must be from the North. 从她的口音判断，她一定是北方人。</li>
</ul>
</li>
<li>Speaking of…：说道…<ul>
<li>Speaking of his lover, his eyes sparkled. 谈到他的情人时，他的双眼闪烁着光芒。</li>
</ul>
</li>
<li>Considering…：考虑到…<ul>
<li>Considering her age, the girl’s letter is very well put together. 就她的年龄而论，她的信可以说是写得很好的。</li>
</ul>
</li>
</ul>
</li>
<li>注意<ul>
<li>不管简化前的句子是什么时态，简化为分词短语时都是一样的V-ing形式。也就是说：不管简化前的句子是什么“时”，简化之后，通通不考虑其“时”，而只考虑其“态”。所以分词短语只有两种“态”：一般态和完成态。另外，定语从句简化为分词短语之后，绝对不能用完成态，所以绝对没有分词的完成态作定语的情况</li>
<li>以动词do为例</li>
<li><img src="http://anki190912.xuexihaike.com/20201107163642.png?imageView2/2/h/100"></li>
<li>1.Singing a song, he sat down. 唱歌的时候，他就坐下了</li>
<li>2.Having sung a song, he sat down. 唱完歌后，他坐下了</li>
<li>第一句话是分词的一般态，表示“唱歌”这个动作（延续动作）和“坐下”这个动作同时发生。第二句话是分词的完成态，表示“唱歌”这个动作先发生</li>
</ul>
</li>
<li>构成分词短语的动词，不管延续还是非延续动词，简化成完成态以后都是having done。分词是没有<code>进行态</code>和<code>完成进行态</code>的。<ul>
<li><code>Having watered the garden</code>, he began to mow the lawn. 浇完花园以后，他开始修剪草坪。</li>
<li><code>Not having</code> done his homework, the boy went outside to play. 虽然这个男孩没有写完作业，他还是跑出去玩。</li>
<li><code>Having been bitten twice</code>, the postman refused to deliver our letters unless we chained our dog up. 被狗咬了两次以后，这个邮递员拒绝给我们送信，除非我们把狗锁起来。</li>
</ul>
</li>
<li>造句练习: (分别用从句和分词短语造句)<ul>
<li>1.已经失败了3次，他不想再尝试了。<ul>
<li>1.Because he has failed three times, he didn’t want to try again.</li>
<li>Having failed three times, he didn’t want to try again.</li>
</ul>
</li>
<li>2.因为在飓风中失去了他的货物，这个船长在船到达港口以后面临破产(bankruptcy)。<ul>
<li>2.Because he had lost his cargo in a hurricane, the captain faced bankruptcy after his vessel reached port.</li>
<li>Having lost his cargo in a hurricane, the captain faced bankruptcy after his vessel reached port.</li>
</ul>
</li>
<li>3.接到关于地震的警告，他把小孩留在了学校。<ul>
<li>3.He had been warned about the earthquake, he left his child in school.</li>
<li>Having been warned about the earthquake, he left his child at school.</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>英语</category>
      </categories>
      <tags>
        <tag>英语</tag>
        <tag>语法</tag>
      </tags>
  </entry>
</search>
